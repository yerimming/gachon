{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yerimming/gachon/blob/main/CV_AL_test11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   optimizer로 RAdam 사용\n",
        "2.   lr = 0.001\n",
        "3.   CosineAnnealingLR 스케줄러 사용\n",
        "\n"
      ],
      "metadata": {
        "id": "JBBnibyCbQ_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr4ox9es1m_Z",
        "outputId": "39cd921b-6afd-4ef2-850d-6c4f43de17f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/LiyuanLucasLiu/RAdam.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a36Uzf7yL9l",
        "outputId": "e2ac8cd1-1539-4cfb-c9fc-478be4e8908c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/LiyuanLucasLiu/RAdam.git\n",
            "  Cloning https://github.com/LiyuanLucasLiu/RAdam.git to /tmp/pip-req-build-gewoqy_j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/LiyuanLucasLiu/RAdam.git /tmp/pip-req-build-gewoqy_j\n",
            "  Resolved https://github.com/LiyuanLucasLiu/RAdam.git to commit d9fd30a337894c4003768561d45e8730dbd41333\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from RAdam==0.0.1) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->RAdam==0.0.1) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->RAdam==0.0.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->RAdam==0.0.1) (1.3.0)\n",
            "Building wheels for collected packages: RAdam\n",
            "  Building wheel for RAdam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for RAdam: filename=RAdam-0.0.1-py3-none-any.whl size=7098 sha256=469beee26f13f58f57e95bb751bf9f205ee7ec30d562dd24322fd4cebf11f191\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-elvs9p8x/wheels/27/dd/f4/a154a2dd1d807820314f09ba2fa30f13f96a0d2830e8bab05e\n",
            "Successfully built RAdam\n",
            "Installing collected packages: RAdam\n",
            "Successfully installed RAdam-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOc0tT3-nv73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8084b9a9-5409-4fba-e8fc-491c4ea3d3ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# radam 사용\n",
        "from radam import RAdam\n",
        "\n",
        "# 스케줄러 사용\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/CUB_200_2011_repackage_class50/datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/CUB_200_2011_repackage_class50/datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/CUB_200_2011_repackage_class50/datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/CUB_200_2011_repackage_class50/datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = re.sub(r'\\([^)]*\\)', '', label)\n",
        "    label = int(label)\n",
        "    return (img, label)"
      ],
      "metadata": {
        "id": "KaFgjkFp8tzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Preprocessing ###\n",
        "\n",
        "transforms_train = transforms.Compose([transforms.Resize((448,448)),\n",
        "                                       transforms.ToTensor()])\n",
        "transforms_valtest = transforms.Compose([transforms.Resize((448,448)),\n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_set = CUB2011(mode='train',\n",
        "                    transform=transforms_train)\n",
        "# transforms_train을 transforms_valtest로 변경\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_valtest)\n",
        "test_set = CUB2011(mode='test',\n",
        "                  transform=transforms_valtest)\n",
        "\n",
        "print('Num of each dataset: ',len(train_set),len(val_set),len(test_set))\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "test_loader = DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")\n",
        "\n",
        "### Model / Optimizer ###\n",
        "EPOCH = 30\n",
        "lr = 0.001\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "### Tranfer Learning ###\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features,50)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = optim.RAdam(model.parameters(),lr=lr)\n",
        "\n",
        "# 스케줄러 초기화 (주기와 최소/최대 학습률 설정)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0.001)\n",
        "\n",
        "print(\"Created a learning model and optimizer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vx5jj22neg",
        "outputId": "25cbaa70-4172-47ab-a84d-ac6b7b5121c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset:  2362 296 298\n",
            "Loaded dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 134MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a learning model and optimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model,train_loader,optimizer,epoch):\n",
        "  model.train()\n",
        "  for i,(image,target) in enumerate(train_loader):\n",
        "    image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "    output = model(image)\n",
        "    optimizer.zero_grad()\n",
        "    # loss func을 어떤 것을 사용할 것인지?\n",
        "    train_loss = F.cross_entropy(output,target).to(DEVICE)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 스케줄러 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    if i%10 ==0:\n",
        "      print(\n",
        "          f'Train Epoch: {epoch} [{i}/{len(train_loader)}]\\tloss: {train_loss.item():6f}')\n",
        "\n",
        "  return train_loss\n",
        "\n",
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for i,(image,target) in enumerate(val_loader):\n",
        "      image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "      output = model(image)\n",
        "\n",
        "      eval_loss += F.cross_entropy(output,target, reduction='sum').item()\n",
        "      pred = output.max(1,keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  eval_loss /= len(val_loader.dataset)\n",
        "  eval_accuracy = 100*correct / len(val_loader.dataset)\n",
        "  return eval_loss,eval_accuracy"
      ],
      "metadata": {
        "id": "apDhVk6C2r7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "  train_loss = train(model,train_loader,optimizer,epoch)\n",
        "  val_loss,val_accuracy = evaluate(model,val_loader)\n",
        "\n",
        "  # Save best model\n",
        "  if val_accuracy > best:\n",
        "    best = val_accuracy\n",
        "    torch.save(model.state_dict(),\"./best_model.pth\")\n",
        "\n",
        "  print(f\"[{epoch}]Validation Loss: {val_loss:.4f},Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "# Test result\n",
        "test_loss,test_accuracy = evaluate(model,test_loader)\n",
        "print(f'[FINAL] Test Loss: {test_loss:.4f},Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "end = time.time()\n",
        "elasped_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \",best)\n",
        "print(\n",
        "    f\"Elasped Time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")\n",
        "print(\n",
        "    f\"time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNhSTX452wyd",
        "outputId": "2cb95141-0ad7-41c9-d2e3-69aed2298690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/74]\tloss: 4.250554\n",
            "Train Epoch: 0 [10/74]\tloss: 3.975892\n",
            "Train Epoch: 0 [20/74]\tloss: 3.678182\n",
            "Train Epoch: 0 [30/74]\tloss: 3.448159\n",
            "Train Epoch: 0 [40/74]\tloss: 3.230551\n",
            "Train Epoch: 0 [50/74]\tloss: 2.912849\n",
            "Train Epoch: 0 [60/74]\tloss: 2.630556\n",
            "Train Epoch: 0 [70/74]\tloss: 2.397383\n",
            "[0]Validation Loss: 2.0124,Accuracy: 58.4459%\n",
            "Train Epoch: 1 [0/74]\tloss: 1.745643\n",
            "Train Epoch: 1 [10/74]\tloss: 1.737375\n",
            "Train Epoch: 1 [20/74]\tloss: 1.390408\n",
            "Train Epoch: 1 [30/74]\tloss: 1.491669\n",
            "Train Epoch: 1 [40/74]\tloss: 1.095841\n",
            "Train Epoch: 1 [50/74]\tloss: 1.358899\n",
            "Train Epoch: 1 [60/74]\tloss: 1.288335\n",
            "Train Epoch: 1 [70/74]\tloss: 1.007959\n",
            "[1]Validation Loss: 1.0802,Accuracy: 82.7703%\n",
            "Train Epoch: 2 [0/74]\tloss: 0.607178\n",
            "Train Epoch: 2 [10/74]\tloss: 0.491411\n",
            "Train Epoch: 2 [20/74]\tloss: 0.372278\n",
            "Train Epoch: 2 [30/74]\tloss: 0.528962\n",
            "Train Epoch: 2 [40/74]\tloss: 0.286827\n",
            "Train Epoch: 2 [50/74]\tloss: 0.450170\n",
            "Train Epoch: 2 [60/74]\tloss: 0.619320\n",
            "Train Epoch: 2 [70/74]\tloss: 0.409097\n",
            "[2]Validation Loss: 1.2977,Accuracy: 75.3378%\n",
            "Train Epoch: 3 [0/74]\tloss: 0.245791\n",
            "Train Epoch: 3 [10/74]\tloss: 0.208199\n",
            "Train Epoch: 3 [20/74]\tloss: 0.160308\n",
            "Train Epoch: 3 [30/74]\tloss: 0.136963\n",
            "Train Epoch: 3 [40/74]\tloss: 0.102622\n",
            "Train Epoch: 3 [50/74]\tloss: 0.083869\n",
            "Train Epoch: 3 [60/74]\tloss: 0.118998\n",
            "Train Epoch: 3 [70/74]\tloss: 0.079031\n",
            "[3]Validation Loss: 0.7224,Accuracy: 84.1216%\n",
            "Train Epoch: 4 [0/74]\tloss: 0.059247\n",
            "Train Epoch: 4 [10/74]\tloss: 0.049195\n",
            "Train Epoch: 4 [20/74]\tloss: 0.067754\n",
            "Train Epoch: 4 [30/74]\tloss: 0.037328\n",
            "Train Epoch: 4 [40/74]\tloss: 0.040158\n",
            "Train Epoch: 4 [50/74]\tloss: 0.035319\n",
            "Train Epoch: 4 [60/74]\tloss: 0.023972\n",
            "Train Epoch: 4 [70/74]\tloss: 0.029963\n",
            "[4]Validation Loss: 0.5188,Accuracy: 91.2162%\n",
            "Train Epoch: 5 [0/74]\tloss: 0.023947\n",
            "Train Epoch: 5 [10/74]\tloss: 0.021869\n",
            "Train Epoch: 5 [20/74]\tloss: 0.019543\n",
            "Train Epoch: 5 [30/74]\tloss: 0.020157\n",
            "Train Epoch: 5 [40/74]\tloss: 0.019948\n",
            "Train Epoch: 5 [50/74]\tloss: 0.017571\n",
            "Train Epoch: 5 [60/74]\tloss: 0.021466\n",
            "Train Epoch: 5 [70/74]\tloss: 0.013868\n",
            "[5]Validation Loss: 0.4972,Accuracy: 89.5270%\n",
            "Train Epoch: 6 [0/74]\tloss: 0.014841\n",
            "Train Epoch: 6 [10/74]\tloss: 0.012376\n",
            "Train Epoch: 6 [20/74]\tloss: 0.011532\n",
            "Train Epoch: 6 [30/74]\tloss: 0.012358\n",
            "Train Epoch: 6 [40/74]\tloss: 0.009464\n",
            "Train Epoch: 6 [50/74]\tloss: 0.008464\n",
            "Train Epoch: 6 [60/74]\tloss: 0.012476\n",
            "Train Epoch: 6 [70/74]\tloss: 0.009108\n",
            "[6]Validation Loss: 0.4221,Accuracy: 91.8919%\n",
            "Train Epoch: 7 [0/74]\tloss: 0.007639\n",
            "Train Epoch: 7 [10/74]\tloss: 0.010060\n",
            "Train Epoch: 7 [20/74]\tloss: 0.005924\n",
            "Train Epoch: 7 [30/74]\tloss: 0.007730\n",
            "Train Epoch: 7 [40/74]\tloss: 0.006942\n",
            "Train Epoch: 7 [50/74]\tloss: 0.010605\n",
            "Train Epoch: 7 [60/74]\tloss: 0.005600\n",
            "Train Epoch: 7 [70/74]\tloss: 0.004825\n",
            "[7]Validation Loss: 0.4227,Accuracy: 92.2297%\n",
            "Train Epoch: 8 [0/74]\tloss: 0.006097\n",
            "Train Epoch: 8 [10/74]\tloss: 0.005739\n",
            "Train Epoch: 8 [20/74]\tloss: 0.004613\n",
            "Train Epoch: 8 [30/74]\tloss: 0.005073\n",
            "Train Epoch: 8 [40/74]\tloss: 0.004885\n",
            "Train Epoch: 8 [50/74]\tloss: 0.004412\n",
            "Train Epoch: 8 [60/74]\tloss: 0.005547\n",
            "Train Epoch: 8 [70/74]\tloss: 0.004088\n",
            "[8]Validation Loss: 0.4128,Accuracy: 90.8784%\n",
            "Train Epoch: 9 [0/74]\tloss: 0.004164\n",
            "Train Epoch: 9 [10/74]\tloss: 0.004359\n",
            "Train Epoch: 9 [20/74]\tloss: 0.003843\n",
            "Train Epoch: 9 [30/74]\tloss: 0.005395\n",
            "Train Epoch: 9 [40/74]\tloss: 0.003922\n",
            "Train Epoch: 9 [50/74]\tloss: 0.006868\n",
            "Train Epoch: 9 [60/74]\tloss: 0.004285\n",
            "Train Epoch: 9 [70/74]\tloss: 0.005834\n",
            "[9]Validation Loss: 0.3960,Accuracy: 92.2297%\n",
            "Train Epoch: 10 [0/74]\tloss: 0.004455\n",
            "Train Epoch: 10 [10/74]\tloss: 0.002457\n",
            "Train Epoch: 10 [20/74]\tloss: 0.003222\n",
            "Train Epoch: 10 [30/74]\tloss: 0.006140\n",
            "Train Epoch: 10 [40/74]\tloss: 0.002281\n",
            "Train Epoch: 10 [50/74]\tloss: 0.003053\n",
            "Train Epoch: 10 [60/74]\tloss: 0.004557\n",
            "Train Epoch: 10 [70/74]\tloss: 0.002800\n",
            "[10]Validation Loss: 0.4134,Accuracy: 91.2162%\n",
            "Train Epoch: 11 [0/74]\tloss: 0.002283\n",
            "Train Epoch: 11 [10/74]\tloss: 0.002761\n",
            "Train Epoch: 11 [20/74]\tloss: 0.003575\n",
            "Train Epoch: 11 [30/74]\tloss: 0.002604\n",
            "Train Epoch: 11 [40/74]\tloss: 0.002967\n",
            "Train Epoch: 11 [50/74]\tloss: 0.003094\n",
            "Train Epoch: 11 [60/74]\tloss: 0.003803\n",
            "Train Epoch: 11 [70/74]\tloss: 0.003012\n",
            "[11]Validation Loss: 0.4340,Accuracy: 91.2162%\n",
            "Train Epoch: 12 [0/74]\tloss: 0.002481\n",
            "Train Epoch: 12 [10/74]\tloss: 0.001986\n",
            "Train Epoch: 12 [20/74]\tloss: 0.002648\n",
            "Train Epoch: 12 [30/74]\tloss: 0.002191\n",
            "Train Epoch: 12 [40/74]\tloss: 0.002805\n",
            "Train Epoch: 12 [50/74]\tloss: 0.002900\n",
            "Train Epoch: 12 [60/74]\tloss: 0.003058\n",
            "Train Epoch: 12 [70/74]\tloss: 0.002705\n",
            "[12]Validation Loss: 0.3968,Accuracy: 91.2162%\n",
            "Train Epoch: 13 [0/74]\tloss: 0.001774\n",
            "Train Epoch: 13 [10/74]\tloss: 0.003462\n",
            "Train Epoch: 13 [20/74]\tloss: 0.002053\n",
            "Train Epoch: 13 [30/74]\tloss: 0.002042\n",
            "Train Epoch: 13 [40/74]\tloss: 0.002301\n",
            "Train Epoch: 13 [50/74]\tloss: 0.001396\n",
            "Train Epoch: 13 [60/74]\tloss: 0.002110\n",
            "Train Epoch: 13 [70/74]\tloss: 0.001769\n",
            "[13]Validation Loss: 0.4061,Accuracy: 91.2162%\n",
            "Train Epoch: 14 [0/74]\tloss: 0.002172\n",
            "Train Epoch: 14 [10/74]\tloss: 0.001972\n",
            "Train Epoch: 14 [20/74]\tloss: 0.002052\n",
            "Train Epoch: 14 [30/74]\tloss: 0.001824\n",
            "Train Epoch: 14 [40/74]\tloss: 0.001325\n",
            "Train Epoch: 14 [50/74]\tloss: 0.001953\n",
            "Train Epoch: 14 [60/74]\tloss: 0.001406\n",
            "Train Epoch: 14 [70/74]\tloss: 0.001434\n",
            "[14]Validation Loss: 0.3948,Accuracy: 91.5541%\n",
            "Train Epoch: 15 [0/74]\tloss: 0.001146\n",
            "Train Epoch: 15 [10/74]\tloss: 0.001077\n",
            "Train Epoch: 15 [20/74]\tloss: 0.001179\n",
            "Train Epoch: 15 [30/74]\tloss: 0.001359\n",
            "Train Epoch: 15 [40/74]\tloss: 0.000984\n",
            "Train Epoch: 15 [50/74]\tloss: 0.001670\n",
            "Train Epoch: 15 [60/74]\tloss: 0.001861\n",
            "Train Epoch: 15 [70/74]\tloss: 0.001324\n",
            "[15]Validation Loss: 0.3888,Accuracy: 92.5676%\n",
            "Train Epoch: 16 [0/74]\tloss: 0.001161\n",
            "Train Epoch: 16 [10/74]\tloss: 0.001663\n",
            "Train Epoch: 16 [20/74]\tloss: 0.001276\n",
            "Train Epoch: 16 [30/74]\tloss: 0.001308\n",
            "Train Epoch: 16 [40/74]\tloss: 0.001715\n",
            "Train Epoch: 16 [50/74]\tloss: 0.001172\n",
            "Train Epoch: 16 [60/74]\tloss: 0.001336\n",
            "Train Epoch: 16 [70/74]\tloss: 0.001685\n",
            "[16]Validation Loss: 0.3959,Accuracy: 91.5541%\n",
            "Train Epoch: 17 [0/74]\tloss: 0.001277\n",
            "Train Epoch: 17 [10/74]\tloss: 0.000952\n",
            "Train Epoch: 17 [20/74]\tloss: 0.001017\n",
            "Train Epoch: 17 [30/74]\tloss: 0.001826\n",
            "Train Epoch: 17 [40/74]\tloss: 0.001226\n",
            "Train Epoch: 17 [50/74]\tloss: 0.001308\n",
            "Train Epoch: 17 [60/74]\tloss: 0.001214\n",
            "Train Epoch: 17 [70/74]\tloss: 0.000863\n",
            "[17]Validation Loss: 0.3827,Accuracy: 92.2297%\n",
            "Train Epoch: 18 [0/74]\tloss: 0.000636\n",
            "Train Epoch: 18 [10/74]\tloss: 0.000764\n",
            "Train Epoch: 18 [20/74]\tloss: 0.000921\n",
            "Train Epoch: 18 [30/74]\tloss: 0.000732\n",
            "Train Epoch: 18 [40/74]\tloss: 0.001069\n",
            "Train Epoch: 18 [50/74]\tloss: 0.000841\n",
            "Train Epoch: 18 [60/74]\tloss: 0.000938\n",
            "Train Epoch: 18 [70/74]\tloss: 0.000900\n",
            "[18]Validation Loss: 0.3804,Accuracy: 91.8919%\n",
            "Train Epoch: 19 [0/74]\tloss: 0.000725\n",
            "Train Epoch: 19 [10/74]\tloss: 0.000698\n",
            "Train Epoch: 19 [20/74]\tloss: 0.000862\n",
            "Train Epoch: 19 [30/74]\tloss: 0.000651\n",
            "Train Epoch: 19 [40/74]\tloss: 0.000898\n",
            "Train Epoch: 19 [50/74]\tloss: 0.000534\n",
            "Train Epoch: 19 [60/74]\tloss: 0.000673\n",
            "Train Epoch: 19 [70/74]\tloss: 0.000817\n",
            "[19]Validation Loss: 0.3785,Accuracy: 91.2162%\n",
            "Train Epoch: 20 [0/74]\tloss: 0.000497\n",
            "Train Epoch: 20 [10/74]\tloss: 0.000667\n",
            "Train Epoch: 20 [20/74]\tloss: 0.000570\n",
            "Train Epoch: 20 [30/74]\tloss: 0.001012\n",
            "Train Epoch: 20 [40/74]\tloss: 0.000709\n",
            "Train Epoch: 20 [50/74]\tloss: 0.000713\n",
            "Train Epoch: 20 [60/74]\tloss: 0.000540\n",
            "Train Epoch: 20 [70/74]\tloss: 0.000754\n",
            "[20]Validation Loss: 0.3883,Accuracy: 91.8919%\n",
            "Train Epoch: 21 [0/74]\tloss: 0.000755\n",
            "Train Epoch: 21 [10/74]\tloss: 0.000610\n",
            "Train Epoch: 21 [20/74]\tloss: 0.000496\n",
            "Train Epoch: 21 [30/74]\tloss: 0.000714\n",
            "Train Epoch: 21 [40/74]\tloss: 0.000533\n",
            "Train Epoch: 21 [50/74]\tloss: 0.000686\n",
            "Train Epoch: 21 [60/74]\tloss: 0.000613\n",
            "Train Epoch: 21 [70/74]\tloss: 0.000836\n",
            "[21]Validation Loss: 0.3863,Accuracy: 90.2027%\n",
            "Train Epoch: 22 [0/74]\tloss: 0.000687\n",
            "Train Epoch: 22 [10/74]\tloss: 0.000565\n",
            "Train Epoch: 22 [20/74]\tloss: 0.000807\n",
            "Train Epoch: 22 [30/74]\tloss: 0.000789\n",
            "Train Epoch: 22 [40/74]\tloss: 0.000683\n",
            "Train Epoch: 22 [50/74]\tloss: 0.000446\n",
            "Train Epoch: 22 [60/74]\tloss: 0.000532\n",
            "Train Epoch: 22 [70/74]\tloss: 0.000514\n",
            "[22]Validation Loss: 0.3891,Accuracy: 90.2027%\n",
            "Train Epoch: 23 [0/74]\tloss: 0.000570\n",
            "Train Epoch: 23 [10/74]\tloss: 0.000342\n",
            "Train Epoch: 23 [20/74]\tloss: 0.000431\n",
            "Train Epoch: 23 [30/74]\tloss: 0.000575\n",
            "Train Epoch: 23 [40/74]\tloss: 0.000430\n",
            "Train Epoch: 23 [50/74]\tloss: 0.000671\n",
            "Train Epoch: 23 [60/74]\tloss: 0.000458\n",
            "Train Epoch: 23 [70/74]\tloss: 0.000565\n",
            "[23]Validation Loss: 0.3852,Accuracy: 90.2027%\n",
            "Train Epoch: 24 [0/74]\tloss: 0.000609\n",
            "Train Epoch: 24 [10/74]\tloss: 0.000767\n",
            "Train Epoch: 24 [20/74]\tloss: 0.000890\n",
            "Train Epoch: 24 [30/74]\tloss: 0.000464\n",
            "Train Epoch: 24 [40/74]\tloss: 0.000652\n",
            "Train Epoch: 24 [50/74]\tloss: 0.000553\n",
            "Train Epoch: 24 [60/74]\tloss: 0.000309\n",
            "Train Epoch: 24 [70/74]\tloss: 0.000453\n",
            "[24]Validation Loss: 0.3865,Accuracy: 91.8919%\n",
            "Train Epoch: 25 [0/74]\tloss: 0.000355\n",
            "Train Epoch: 25 [10/74]\tloss: 0.000370\n",
            "Train Epoch: 25 [20/74]\tloss: 0.000598\n",
            "Train Epoch: 25 [30/74]\tloss: 0.000416\n",
            "Train Epoch: 25 [40/74]\tloss: 0.000443\n",
            "Train Epoch: 25 [50/74]\tloss: 0.000318\n",
            "Train Epoch: 25 [60/74]\tloss: 0.000628\n",
            "Train Epoch: 25 [70/74]\tloss: 0.000579\n",
            "[25]Validation Loss: 0.3945,Accuracy: 89.8649%\n",
            "Train Epoch: 26 [0/74]\tloss: 0.000563\n",
            "Train Epoch: 26 [10/74]\tloss: 0.000425\n",
            "Train Epoch: 26 [20/74]\tloss: 0.000312\n",
            "Train Epoch: 26 [30/74]\tloss: 0.000642\n",
            "Train Epoch: 26 [40/74]\tloss: 0.000705\n",
            "Train Epoch: 26 [50/74]\tloss: 0.000401\n",
            "Train Epoch: 26 [60/74]\tloss: 0.000538\n",
            "Train Epoch: 26 [70/74]\tloss: 0.000458\n",
            "[26]Validation Loss: 0.3784,Accuracy: 91.5541%\n",
            "Train Epoch: 27 [0/74]\tloss: 0.000290\n",
            "Train Epoch: 27 [10/74]\tloss: 0.000381\n",
            "Train Epoch: 27 [20/74]\tloss: 0.000407\n",
            "Train Epoch: 27 [30/74]\tloss: 0.000373\n",
            "Train Epoch: 27 [40/74]\tloss: 0.000455\n",
            "Train Epoch: 27 [50/74]\tloss: 0.000327\n",
            "Train Epoch: 27 [60/74]\tloss: 0.000579\n",
            "Train Epoch: 27 [70/74]\tloss: 0.000263\n",
            "[27]Validation Loss: 0.3820,Accuracy: 90.8784%\n",
            "Train Epoch: 28 [0/74]\tloss: 0.000382\n",
            "Train Epoch: 28 [10/74]\tloss: 0.000274\n",
            "Train Epoch: 28 [20/74]\tloss: 0.000384\n",
            "Train Epoch: 28 [30/74]\tloss: 0.000183\n",
            "Train Epoch: 28 [40/74]\tloss: 0.000575\n",
            "Train Epoch: 28 [50/74]\tloss: 0.000248\n",
            "Train Epoch: 28 [60/74]\tloss: 0.000415\n",
            "Train Epoch: 28 [70/74]\tloss: 0.000254\n",
            "[28]Validation Loss: 0.3746,Accuracy: 91.2162%\n",
            "Train Epoch: 29 [0/74]\tloss: 0.000272\n",
            "Train Epoch: 29 [10/74]\tloss: 0.000180\n",
            "Train Epoch: 29 [20/74]\tloss: 0.000269\n",
            "Train Epoch: 29 [30/74]\tloss: 0.000219\n",
            "Train Epoch: 29 [40/74]\tloss: 0.000439\n",
            "Train Epoch: 29 [50/74]\tloss: 0.000294\n",
            "Train Epoch: 29 [60/74]\tloss: 0.000528\n",
            "Train Epoch: 29 [70/74]\tloss: 0.000264\n",
            "[29]Validation Loss: 0.3879,Accuracy: 91.2162%\n",
            "[FINAL] Test Loss: 0.3727,Accuracy: 93.6242%\n",
            "Best Accuracy:  92.56756756756756\n",
            "Elasped Time: 0h, 20m, 50s\n",
            "time: 0h, 20m, 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Display\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "model_builder = keras.applications.xception.Xception\n",
        "img_size = (299, 299)\n",
        "preprocess_input = keras.applications.xception.preprocess_input\n",
        "decode_predictions = keras.applications.xception.decode_predictions\n",
        "\n",
        "last_conv_layer_name = \"block14_sepconv2_act\"\n",
        "\n",
        "# The local path to our target image\n",
        "import random\n",
        "\n",
        "# 테스트 데이터셋에서 무작위로 이미지 선택\n",
        "random_index = random.randint(0, len(test_set) - 1)\n",
        "img_path = test_set.image_folder[random_index]\n",
        "img_path = os.path.join('/content/drive/MyDrive/datasets/test', image_path)\n",
        "display(Image(img_path))\n",
        "\n",
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.utils.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.utils.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = keras.models.Model(\n",
        "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "    #귀여워..."
      ],
      "metadata": {
        "id": "iTUnYJsSESyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "\n",
        "# Make model\n",
        "model = model_builder(weights=\"imagenet\")\n",
        "\n",
        "# Remove last layer's softmax\n",
        "model.layers[-1].activation = None\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = model.predict(img_array)\n",
        "print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cloaq8UuEV6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.utils.load_img(img_path)\n",
        "    img = keras.utils.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))\n",
        "\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ],
      "metadata": {
        "id": "DNVm5d5lEZLF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}