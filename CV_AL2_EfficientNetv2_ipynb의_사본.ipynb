{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yerimming/gachon/blob/main/CV_AL2_EfficientNetv2_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   AdamP optimizer 사용\n",
        "*   Label Smoothing\n",
        "*   EfficientNet 모델 사용\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5IWv29cr4xxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "HTzysnz787ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0a74fb-fe77-47a2-e49f-7f35c571cd5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ByrrPmg87uL",
        "outputId": "3fb831dd-9c88-4ac2-f520-beac19a851b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=d5aadf6cde565d89a79ec2ca11328acfbeb190918ae56633179ae7236964ba33\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install adamp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFamupBzpmhQ",
        "outputId": "9f91b873-b8bf-4b0e-9ba5-6e13faf8cd5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adamp\n",
            "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5982 sha256=f774672cd92018446aa72d4c5a629e89b885218e2d560e512dc1fa86fa401f8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOc0tT3-nv73",
        "outputId": "e2da6529-2d65-4af6-9346-d3e5f481e6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image,ImageEnhance\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "from torch.utils.data import ConcatDataset\n",
        "from collections import Counter\n",
        "\n",
        "from adamp import AdamP\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KaFgjkFp8tzI"
      },
      "outputs": [],
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('/content/drive/MyDrive/CUB_200_2011_repackage_class50 (1)/datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('/content/drive/MyDrive/CUB_200_2011_repackage_class50 (1)/datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('/content/drive/MyDrive/CUB_200_2011_repackage_class50 (1)/datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('/content/drive/MyDrive/CUB_200_2011_repackage_class50 (1)/datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = int(label)\n",
        "    return (img, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cQGrjNlsWdCh"
      },
      "outputs": [],
      "source": [
        "# Geomentric transform + Visual corruptions\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0, std=1, p=0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            img_array = np.array(img)\n",
        "            noise = np.random.normal(self.mean, self.std, img_array.shape)\n",
        "            noisy_image = np.clip(img_array + noise, 0, 255)  # Clip values to the range [0, 255]\n",
        "            return Image.fromarray(noisy_image.astype(np.uint8))\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std}, p={self.p})'\n",
        "\n",
        "\n",
        "class AdjustContrast(object):\n",
        "    def __init__(self, factor=1.0):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, img):\n",
        "        enhancer = ImageEnhance.Contrast(img)\n",
        "        img = enhancer.enhance(self.factor)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(factor={self.factor})'\n",
        "\n",
        "class AdjustBrightness(object):\n",
        "    def __init__(self, factor=1.0):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, img):\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "        img = enhancer.enhance(self.factor)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(factor={self.factor})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vx5jj22neg",
        "outputId": "57c82451-2fa6-4ff5-dcad-704d614ad000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset:  4720 296 298\n",
            "Loaded dataloader\n"
          ]
        }
      ],
      "source": [
        "### Data Preprocessing & Data Augmentation ###\n",
        "transforms_train_origin = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    transforms.ToTensor(),])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((448,448)),\n",
        "    transforms.ToTensor(),])\n",
        "\n",
        "# Geomentric transform + Visual corruptions\n",
        "transforms_train_g_v = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    #transforms.RandomResizedCrop(448),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    AddGaussianNoise(mean=0, std=25, p=0.5),  # 가우시안 노이즈를 추가합니다.\n",
        "    AdjustContrast(factor=2.0),  # 대비를 조절합니다.\n",
        "    AdjustBrightness(factor=1.5),  # 밝기를 조절합니다.\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_set_origin = CUB2011(mode='train',\n",
        "                    transform=transforms_train_origin)\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_test)\n",
        "test_set = CUB2011(mode='test',\n",
        "                  transform=transforms_test)\n",
        "\n",
        "train_set_augmented2 = CUB2011(mode='train',transform=transforms_train_g_v) # 2)\n",
        "\n",
        "train_loader = DataLoader(train_set_origin,batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "# 다 합친거\n",
        "train_set_combined = ConcatDataset([train_set_origin,train_set_augmented2])\n",
        "\n",
        "print('Num of each dataset: ',len(train_set_combined),len(val_set),len(test_set))\n",
        "\n",
        "# Dataloader class는 bath기반의 딥러닝모델 학습을 위해서 mini batch를 만들어주는 역할을 한다\n",
        "# dataloader를 통해 dataset의 전체 데이터가 batch size로 나뉘게 된다\n",
        "train_loader = DataLoader(train_set_combined, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "test_loader = DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apDhVk6C2r7R",
        "outputId": "68714a46-ecd9-4799-a458-5e921d23a050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/hankyul2/EfficientNetV2-pytorch/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNetV2(\n",
            "  (stem): ConvBNAct(\n",
            "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): SiLU()\n",
            "  )\n",
            "  (blocks): Sequential(\n",
            "    (0): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (1): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (2): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (3): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (4): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (5): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (6): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (7): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (8): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (9): MBConv(\n",
            "      (block): Sequential(\n",
            "        (fused): ConvBNAct(\n",
            "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (fused_point_wise): ConvBNAct(\n",
            "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (10): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (11): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (12): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (13): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (14): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (15): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (16): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
            "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (17): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (18): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (19): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (20): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (21): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (22): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (23): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (24): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (25): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
            "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (26): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (27): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (28): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (29): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (30): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (31): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (32): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (33): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (34): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (35): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (36): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (37): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (38): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "    (39): MBConv(\n",
            "      (block): Sequential(\n",
            "        (linear_bottleneck): ConvBNAct(\n",
            "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (depth_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
            "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): SiLU()\n",
            "        )\n",
            "        (se): SEUnit(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "          (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act1): SiLU(inplace=True)\n",
            "          (act2): Sigmoid()\n",
            "        )\n",
            "        (point_wise): ConvBNAct(\n",
            "          (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (stochastic_path): StochasticDepth()\n",
            "    )\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (bottleneck): ConvBNAct(\n",
            "      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): SiLU()\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "    (dropout): Dropout(p=0.1, inplace=True)\n",
            "    (classifier): Linear(in_features=1280, out_features=50, bias=True)\n",
            "  )\n",
            ")\n",
            "Created a learning model and optimizer\n"
          ]
        }
      ],
      "source": [
        "### Model / Optimizer ###\n",
        "EPOCH = 30\n",
        "lr = 0.0001\n",
        "\n",
        "model = torch.hub.load('hankyul2/EfficientNetV2-pytorch', 'efficientnet_v2_s', pretrained=True, nclass=50)\n",
        "print(model)\n",
        "\n",
        "### Tranfer Learning ###\n",
        "'''\n",
        "num_features = model.classifier.in_features\n",
        "model.fc = nn.Linear(num_features,50)\n",
        "'''\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = AdamP(model.parameters(), lr=lr)\n",
        "\n",
        "print(\"Created a learning model and optimizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s0gxuQUUZHu_"
      },
      "outputs": [],
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model,train_loader,optimizer,epoch):\n",
        "  model.train()\n",
        "  criterion = nn.CrossEntropyLoss(label_smoothing=0.11)\n",
        "  for i,(image,target) in enumerate(train_loader):\n",
        "    image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "    output = model(image)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = criterion(output,target)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%10 ==0:\n",
        "      print(\n",
        "          f'Train Epoch: {epoch} [{i}/{len(train_loader)}]\\tloss: {train_loss.item():6f}')\n",
        "\n",
        "  return train_loss\n",
        "\n",
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for i,(image,target) in enumerate(val_loader):\n",
        "      image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "      output = model(image)\n",
        "\n",
        "      eval_loss += F.cross_entropy(output,target, reduction='sum').item()\n",
        "      pred = output.max(1,keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  eval_loss /= len(val_loader.dataset)\n",
        "  eval_accuracy = 100*correct / len(val_loader.dataset)\n",
        "  return eval_loss,eval_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNhSTX452wyd",
        "outputId": "6530dbf8-5dbb-4b73-8a14-97a8e06c1c3e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/590]\tloss: 3.891995\n",
            "Train Epoch: 0 [10/590]\tloss: 3.892955\n",
            "Train Epoch: 0 [20/590]\tloss: 3.850639\n",
            "Train Epoch: 0 [30/590]\tloss: 3.900104\n",
            "Train Epoch: 0 [40/590]\tloss: 3.856041\n",
            "Train Epoch: 0 [50/590]\tloss: 3.832072\n",
            "Train Epoch: 0 [60/590]\tloss: 3.795185\n",
            "Train Epoch: 0 [70/590]\tloss: 3.760329\n",
            "Train Epoch: 0 [80/590]\tloss: 3.740914\n",
            "Train Epoch: 0 [90/590]\tloss: 3.658416\n",
            "Train Epoch: 0 [100/590]\tloss: 3.611802\n",
            "Train Epoch: 0 [110/590]\tloss: 3.694633\n",
            "Train Epoch: 0 [120/590]\tloss: 3.602067\n",
            "Train Epoch: 0 [130/590]\tloss: 3.429890\n",
            "Train Epoch: 0 [140/590]\tloss: 3.450746\n",
            "Train Epoch: 0 [150/590]\tloss: 3.300880\n",
            "Train Epoch: 0 [160/590]\tloss: 3.439993\n",
            "Train Epoch: 0 [170/590]\tloss: 3.506832\n",
            "Train Epoch: 0 [180/590]\tloss: 3.251022\n",
            "Train Epoch: 0 [190/590]\tloss: 3.293782\n",
            "Train Epoch: 0 [200/590]\tloss: 3.110986\n",
            "Train Epoch: 0 [210/590]\tloss: 3.391029\n",
            "Train Epoch: 0 [220/590]\tloss: 3.221599\n",
            "Train Epoch: 0 [230/590]\tloss: 3.157736\n",
            "Train Epoch: 0 [240/590]\tloss: 3.218532\n",
            "Train Epoch: 0 [250/590]\tloss: 2.541145\n",
            "Train Epoch: 0 [260/590]\tloss: 2.702226\n",
            "Train Epoch: 0 [270/590]\tloss: 2.649475\n",
            "Train Epoch: 0 [280/590]\tloss: 2.746290\n",
            "Train Epoch: 0 [290/590]\tloss: 3.114654\n",
            "Train Epoch: 0 [300/590]\tloss: 2.781013\n",
            "Train Epoch: 0 [310/590]\tloss: 2.356118\n",
            "Train Epoch: 0 [320/590]\tloss: 2.625834\n",
            "Train Epoch: 0 [330/590]\tloss: 2.763816\n",
            "Train Epoch: 0 [340/590]\tloss: 2.256802\n",
            "Train Epoch: 0 [350/590]\tloss: 2.274338\n",
            "Train Epoch: 0 [360/590]\tloss: 2.427845\n",
            "Train Epoch: 0 [370/590]\tloss: 2.313641\n",
            "Train Epoch: 0 [380/590]\tloss: 2.393438\n",
            "Train Epoch: 0 [390/590]\tloss: 2.555593\n",
            "Train Epoch: 0 [400/590]\tloss: 2.641777\n",
            "Train Epoch: 0 [410/590]\tloss: 2.154272\n",
            "Train Epoch: 0 [420/590]\tloss: 2.343365\n",
            "Train Epoch: 0 [430/590]\tloss: 2.037608\n",
            "Train Epoch: 0 [440/590]\tloss: 2.444677\n",
            "Train Epoch: 0 [450/590]\tloss: 2.260352\n",
            "Train Epoch: 0 [460/590]\tloss: 1.947948\n",
            "Train Epoch: 0 [470/590]\tloss: 2.387821\n",
            "Train Epoch: 0 [480/590]\tloss: 2.037474\n",
            "Train Epoch: 0 [490/590]\tloss: 2.143744\n",
            "Train Epoch: 0 [500/590]\tloss: 1.705348\n",
            "Train Epoch: 0 [510/590]\tloss: 1.874808\n",
            "Train Epoch: 0 [520/590]\tloss: 2.084930\n",
            "Train Epoch: 0 [530/590]\tloss: 1.779496\n",
            "Train Epoch: 0 [540/590]\tloss: 1.963957\n",
            "Train Epoch: 0 [550/590]\tloss: 1.756317\n",
            "Train Epoch: 0 [560/590]\tloss: 1.717823\n",
            "Train Epoch: 0 [570/590]\tloss: 1.779562\n",
            "Train Epoch: 0 [580/590]\tloss: 2.164827\n",
            "[0]Validation Loss: 0.7322,Accuracy: 87.1622%\n",
            "Train Epoch: 1 [0/590]\tloss: 1.608257\n",
            "Train Epoch: 1 [10/590]\tloss: 1.955785\n",
            "Train Epoch: 1 [20/590]\tloss: 1.491473\n",
            "Train Epoch: 1 [30/590]\tloss: 1.664991\n",
            "Train Epoch: 1 [40/590]\tloss: 1.824184\n",
            "Train Epoch: 1 [50/590]\tloss: 1.775194\n",
            "Train Epoch: 1 [60/590]\tloss: 1.268654\n",
            "Train Epoch: 1 [70/590]\tloss: 1.590727\n",
            "Train Epoch: 1 [80/590]\tloss: 1.491928\n",
            "Train Epoch: 1 [90/590]\tloss: 1.427199\n",
            "Train Epoch: 1 [100/590]\tloss: 1.581952\n",
            "Train Epoch: 1 [110/590]\tloss: 1.683861\n",
            "Train Epoch: 1 [120/590]\tloss: 1.736643\n",
            "Train Epoch: 1 [130/590]\tloss: 1.276118\n",
            "Train Epoch: 1 [140/590]\tloss: 1.306494\n",
            "Train Epoch: 1 [150/590]\tloss: 1.596257\n",
            "Train Epoch: 1 [160/590]\tloss: 1.090259\n",
            "Train Epoch: 1 [170/590]\tloss: 1.891960\n",
            "Train Epoch: 1 [180/590]\tloss: 1.373425\n",
            "Train Epoch: 1 [190/590]\tloss: 1.507832\n",
            "Train Epoch: 1 [200/590]\tloss: 1.473276\n",
            "Train Epoch: 1 [210/590]\tloss: 1.424164\n",
            "Train Epoch: 1 [220/590]\tloss: 1.363092\n",
            "Train Epoch: 1 [230/590]\tloss: 1.230596\n",
            "Train Epoch: 1 [240/590]\tloss: 1.181582\n",
            "Train Epoch: 1 [250/590]\tloss: 2.194413\n",
            "Train Epoch: 1 [260/590]\tloss: 1.380703\n",
            "Train Epoch: 1 [270/590]\tloss: 1.291576\n",
            "Train Epoch: 1 [280/590]\tloss: 1.437395\n",
            "Train Epoch: 1 [290/590]\tloss: 1.068735\n",
            "Train Epoch: 1 [300/590]\tloss: 1.375439\n",
            "Train Epoch: 1 [310/590]\tloss: 1.356359\n",
            "Train Epoch: 1 [320/590]\tloss: 1.634003\n",
            "Train Epoch: 1 [330/590]\tloss: 1.294254\n",
            "Train Epoch: 1 [340/590]\tloss: 1.523885\n",
            "Train Epoch: 1 [350/590]\tloss: 2.050961\n",
            "Train Epoch: 1 [360/590]\tloss: 1.348432\n",
            "Train Epoch: 1 [370/590]\tloss: 1.312385\n",
            "Train Epoch: 1 [380/590]\tloss: 1.382134\n",
            "Train Epoch: 1 [390/590]\tloss: 1.269519\n",
            "Train Epoch: 1 [400/590]\tloss: 1.032783\n",
            "Train Epoch: 1 [410/590]\tloss: 1.117137\n",
            "Train Epoch: 1 [420/590]\tloss: 1.090976\n",
            "Train Epoch: 1 [430/590]\tloss: 1.373377\n",
            "Train Epoch: 1 [440/590]\tloss: 1.114349\n",
            "Train Epoch: 1 [450/590]\tloss: 1.268213\n",
            "Train Epoch: 1 [460/590]\tloss: 1.183278\n",
            "Train Epoch: 1 [470/590]\tloss: 1.330348\n",
            "Train Epoch: 1 [480/590]\tloss: 1.332857\n",
            "Train Epoch: 1 [490/590]\tloss: 1.276003\n",
            "Train Epoch: 1 [500/590]\tloss: 1.618950\n",
            "Train Epoch: 1 [510/590]\tloss: 1.154977\n",
            "Train Epoch: 1 [520/590]\tloss: 1.005016\n",
            "Train Epoch: 1 [530/590]\tloss: 1.106265\n",
            "Train Epoch: 1 [540/590]\tloss: 0.934597\n",
            "Train Epoch: 1 [550/590]\tloss: 1.033923\n",
            "Train Epoch: 1 [560/590]\tloss: 1.187484\n",
            "Train Epoch: 1 [570/590]\tloss: 1.857080\n",
            "Train Epoch: 1 [580/590]\tloss: 0.936215\n",
            "[1]Validation Loss: 0.3135,Accuracy: 92.5676%\n",
            "Train Epoch: 2 [0/590]\tloss: 1.053695\n",
            "Train Epoch: 2 [10/590]\tloss: 1.353184\n",
            "Train Epoch: 2 [20/590]\tloss: 0.958321\n",
            "Train Epoch: 2 [30/590]\tloss: 1.135478\n",
            "Train Epoch: 2 [40/590]\tloss: 1.005557\n",
            "Train Epoch: 2 [50/590]\tloss: 0.908882\n",
            "Train Epoch: 2 [60/590]\tloss: 0.995244\n",
            "Train Epoch: 2 [70/590]\tloss: 1.031215\n",
            "Train Epoch: 2 [80/590]\tloss: 1.145832\n",
            "Train Epoch: 2 [90/590]\tloss: 1.140993\n",
            "Train Epoch: 2 [100/590]\tloss: 1.562886\n",
            "Train Epoch: 2 [110/590]\tloss: 0.978835\n",
            "Train Epoch: 2 [120/590]\tloss: 1.269302\n",
            "Train Epoch: 2 [130/590]\tloss: 0.970471\n",
            "Train Epoch: 2 [140/590]\tloss: 0.911885\n",
            "Train Epoch: 2 [150/590]\tloss: 0.950663\n",
            "Train Epoch: 2 [160/590]\tloss: 1.160357\n",
            "Train Epoch: 2 [170/590]\tloss: 1.101262\n",
            "Train Epoch: 2 [180/590]\tloss: 1.186462\n",
            "Train Epoch: 2 [190/590]\tloss: 1.017541\n",
            "Train Epoch: 2 [200/590]\tloss: 1.034570\n",
            "Train Epoch: 2 [210/590]\tloss: 0.841145\n",
            "Train Epoch: 2 [220/590]\tloss: 0.962141\n",
            "Train Epoch: 2 [230/590]\tloss: 1.475415\n",
            "Train Epoch: 2 [240/590]\tloss: 1.139968\n",
            "Train Epoch: 2 [250/590]\tloss: 1.018928\n",
            "Train Epoch: 2 [260/590]\tloss: 1.040154\n",
            "Train Epoch: 2 [270/590]\tloss: 1.159742\n",
            "Train Epoch: 2 [280/590]\tloss: 0.973076\n",
            "Train Epoch: 2 [290/590]\tloss: 0.997370\n",
            "Train Epoch: 2 [300/590]\tloss: 1.249717\n",
            "Train Epoch: 2 [310/590]\tloss: 1.272600\n",
            "Train Epoch: 2 [320/590]\tloss: 1.082105\n",
            "Train Epoch: 2 [330/590]\tloss: 0.930086\n",
            "Train Epoch: 2 [340/590]\tloss: 1.186228\n",
            "Train Epoch: 2 [350/590]\tloss: 1.233813\n",
            "Train Epoch: 2 [360/590]\tloss: 1.499237\n",
            "Train Epoch: 2 [370/590]\tloss: 0.987997\n",
            "Train Epoch: 2 [380/590]\tloss: 1.371946\n",
            "Train Epoch: 2 [390/590]\tloss: 1.273421\n",
            "Train Epoch: 2 [400/590]\tloss: 1.346852\n",
            "Train Epoch: 2 [410/590]\tloss: 1.002609\n",
            "Train Epoch: 2 [420/590]\tloss: 1.046103\n",
            "Train Epoch: 2 [430/590]\tloss: 0.932717\n",
            "Train Epoch: 2 [440/590]\tloss: 0.977191\n",
            "Train Epoch: 2 [450/590]\tloss: 1.093797\n",
            "Train Epoch: 2 [460/590]\tloss: 1.046824\n",
            "Train Epoch: 2 [470/590]\tloss: 0.889419\n",
            "Train Epoch: 2 [480/590]\tloss: 1.225914\n",
            "Train Epoch: 2 [490/590]\tloss: 0.868661\n",
            "Train Epoch: 2 [500/590]\tloss: 0.894531\n",
            "Train Epoch: 2 [510/590]\tloss: 0.955847\n",
            "Train Epoch: 2 [520/590]\tloss: 0.966749\n",
            "Train Epoch: 2 [530/590]\tloss: 0.977561\n",
            "Train Epoch: 2 [540/590]\tloss: 1.041348\n",
            "Train Epoch: 2 [550/590]\tloss: 0.847122\n",
            "Train Epoch: 2 [560/590]\tloss: 1.407311\n",
            "Train Epoch: 2 [570/590]\tloss: 0.947570\n",
            "Train Epoch: 2 [580/590]\tloss: 0.990835\n",
            "[2]Validation Loss: 0.2878,Accuracy: 93.2432%\n",
            "Train Epoch: 3 [0/590]\tloss: 1.163389\n",
            "Train Epoch: 3 [10/590]\tloss: 1.137041\n",
            "Train Epoch: 3 [20/590]\tloss: 1.036900\n",
            "Train Epoch: 3 [30/590]\tloss: 1.159925\n",
            "Train Epoch: 3 [40/590]\tloss: 1.000378\n",
            "Train Epoch: 3 [50/590]\tloss: 1.030406\n",
            "Train Epoch: 3 [60/590]\tloss: 1.144753\n",
            "Train Epoch: 3 [70/590]\tloss: 0.868169\n",
            "Train Epoch: 3 [80/590]\tloss: 0.911191\n",
            "Train Epoch: 3 [90/590]\tloss: 0.848406\n",
            "Train Epoch: 3 [100/590]\tloss: 1.021137\n",
            "Train Epoch: 3 [110/590]\tloss: 0.857460\n",
            "Train Epoch: 3 [120/590]\tloss: 0.865526\n",
            "Train Epoch: 3 [130/590]\tloss: 0.838999\n",
            "Train Epoch: 3 [140/590]\tloss: 0.909019\n",
            "Train Epoch: 3 [150/590]\tloss: 1.562001\n",
            "Train Epoch: 3 [160/590]\tloss: 0.847802\n",
            "Train Epoch: 3 [170/590]\tloss: 0.906007\n",
            "Train Epoch: 3 [180/590]\tloss: 0.945907\n",
            "Train Epoch: 3 [190/590]\tloss: 1.045033\n",
            "Train Epoch: 3 [200/590]\tloss: 0.930562\n",
            "Train Epoch: 3 [210/590]\tloss: 1.032272\n",
            "Train Epoch: 3 [220/590]\tloss: 1.088061\n",
            "Train Epoch: 3 [230/590]\tloss: 0.943724\n",
            "Train Epoch: 3 [240/590]\tloss: 0.904204\n",
            "Train Epoch: 3 [250/590]\tloss: 0.851012\n",
            "Train Epoch: 3 [260/590]\tloss: 0.838172\n",
            "Train Epoch: 3 [270/590]\tloss: 0.911215\n",
            "Train Epoch: 3 [280/590]\tloss: 1.069316\n",
            "Train Epoch: 3 [290/590]\tloss: 1.057407\n",
            "Train Epoch: 3 [300/590]\tloss: 0.846335\n",
            "Train Epoch: 3 [310/590]\tloss: 1.038128\n",
            "Train Epoch: 3 [320/590]\tloss: 0.834326\n",
            "Train Epoch: 3 [330/590]\tloss: 0.905983\n",
            "Train Epoch: 3 [340/590]\tloss: 0.901463\n",
            "Train Epoch: 3 [350/590]\tloss: 0.968985\n",
            "Train Epoch: 3 [360/590]\tloss: 0.880902\n",
            "Train Epoch: 3 [370/590]\tloss: 0.841652\n",
            "Train Epoch: 3 [380/590]\tloss: 0.851246\n",
            "Train Epoch: 3 [390/590]\tloss: 1.022326\n",
            "Train Epoch: 3 [400/590]\tloss: 0.829322\n",
            "Train Epoch: 3 [410/590]\tloss: 0.823699\n",
            "Train Epoch: 3 [420/590]\tloss: 1.338018\n",
            "Train Epoch: 3 [430/590]\tloss: 0.832833\n",
            "Train Epoch: 3 [440/590]\tloss: 1.200806\n",
            "Train Epoch: 3 [450/590]\tloss: 1.384033\n",
            "Train Epoch: 3 [460/590]\tloss: 0.818655\n",
            "Train Epoch: 3 [470/590]\tloss: 1.044478\n",
            "Train Epoch: 3 [480/590]\tloss: 0.848698\n",
            "Train Epoch: 3 [490/590]\tloss: 1.370104\n",
            "Train Epoch: 3 [500/590]\tloss: 1.212662\n",
            "Train Epoch: 3 [510/590]\tloss: 0.900321\n",
            "Train Epoch: 3 [520/590]\tloss: 0.889655\n",
            "Train Epoch: 3 [530/590]\tloss: 0.829264\n",
            "Train Epoch: 3 [540/590]\tloss: 0.987463\n",
            "Train Epoch: 3 [550/590]\tloss: 0.917139\n",
            "Train Epoch: 3 [560/590]\tloss: 0.823683\n",
            "Train Epoch: 3 [570/590]\tloss: 0.952466\n",
            "Train Epoch: 3 [580/590]\tloss: 0.840624\n",
            "[3]Validation Loss: 0.2400,Accuracy: 93.9189%\n",
            "Train Epoch: 4 [0/590]\tloss: 0.847492\n",
            "Train Epoch: 4 [10/590]\tloss: 0.945087\n",
            "Train Epoch: 4 [20/590]\tloss: 0.843193\n",
            "Train Epoch: 4 [30/590]\tloss: 0.870307\n",
            "Train Epoch: 4 [40/590]\tloss: 0.875026\n",
            "Train Epoch: 4 [50/590]\tloss: 0.837800\n",
            "Train Epoch: 4 [60/590]\tloss: 0.907082\n",
            "Train Epoch: 4 [70/590]\tloss: 0.845468\n",
            "Train Epoch: 4 [80/590]\tloss: 0.927724\n",
            "Train Epoch: 4 [90/590]\tloss: 0.950987\n",
            "Train Epoch: 4 [100/590]\tloss: 0.823243\n",
            "Train Epoch: 4 [110/590]\tloss: 0.810146\n",
            "Train Epoch: 4 [120/590]\tloss: 0.914116\n",
            "Train Epoch: 4 [130/590]\tloss: 0.902012\n",
            "Train Epoch: 4 [140/590]\tloss: 0.850105\n",
            "Train Epoch: 4 [150/590]\tloss: 0.863385\n",
            "Train Epoch: 4 [160/590]\tloss: 1.060139\n",
            "Train Epoch: 4 [170/590]\tloss: 0.990014\n",
            "Train Epoch: 4 [180/590]\tloss: 0.961532\n",
            "Train Epoch: 4 [190/590]\tloss: 0.863836\n",
            "Train Epoch: 4 [200/590]\tloss: 0.839906\n",
            "Train Epoch: 4 [210/590]\tloss: 0.975935\n",
            "Train Epoch: 4 [220/590]\tloss: 0.829632\n",
            "Train Epoch: 4 [230/590]\tloss: 1.097918\n",
            "Train Epoch: 4 [240/590]\tloss: 0.835822\n",
            "Train Epoch: 4 [250/590]\tloss: 0.837044\n",
            "Train Epoch: 4 [260/590]\tloss: 0.857005\n",
            "Train Epoch: 4 [270/590]\tloss: 0.979329\n",
            "Train Epoch: 4 [280/590]\tloss: 0.938421\n",
            "Train Epoch: 4 [290/590]\tloss: 0.867487\n",
            "Train Epoch: 4 [300/590]\tloss: 0.849092\n",
            "Train Epoch: 4 [310/590]\tloss: 0.829165\n",
            "Train Epoch: 4 [320/590]\tloss: 0.993362\n",
            "Train Epoch: 4 [330/590]\tloss: 0.815333\n",
            "Train Epoch: 4 [340/590]\tloss: 0.870501\n",
            "Train Epoch: 4 [350/590]\tloss: 0.962968\n",
            "Train Epoch: 4 [360/590]\tloss: 0.825599\n",
            "Train Epoch: 4 [370/590]\tloss: 1.127037\n",
            "Train Epoch: 4 [380/590]\tloss: 0.824313\n",
            "Train Epoch: 4 [390/590]\tloss: 0.885651\n",
            "Train Epoch: 4 [400/590]\tloss: 0.956426\n",
            "Train Epoch: 4 [410/590]\tloss: 0.831630\n",
            "Train Epoch: 4 [420/590]\tloss: 1.037019\n",
            "Train Epoch: 4 [430/590]\tloss: 0.896137\n",
            "Train Epoch: 4 [440/590]\tloss: 0.881805\n",
            "Train Epoch: 4 [450/590]\tloss: 0.830591\n",
            "Train Epoch: 4 [460/590]\tloss: 0.917353\n",
            "Train Epoch: 4 [470/590]\tloss: 1.031330\n",
            "Train Epoch: 4 [480/590]\tloss: 0.819331\n",
            "Train Epoch: 4 [490/590]\tloss: 0.859857\n",
            "Train Epoch: 4 [500/590]\tloss: 0.903414\n",
            "Train Epoch: 4 [510/590]\tloss: 1.051893\n",
            "Train Epoch: 4 [520/590]\tloss: 0.872187\n",
            "Train Epoch: 4 [530/590]\tloss: 0.832602\n",
            "Train Epoch: 4 [540/590]\tloss: 0.836480\n",
            "Train Epoch: 4 [550/590]\tloss: 0.867787\n",
            "Train Epoch: 4 [560/590]\tloss: 0.847643\n",
            "Train Epoch: 4 [570/590]\tloss: 0.820677\n",
            "Train Epoch: 4 [580/590]\tloss: 0.879453\n",
            "[4]Validation Loss: 0.2535,Accuracy: 93.9189%\n",
            "Train Epoch: 5 [0/590]\tloss: 0.819961\n",
            "Train Epoch: 5 [10/590]\tloss: 0.910538\n",
            "Train Epoch: 5 [20/590]\tloss: 0.943313\n",
            "Train Epoch: 5 [30/590]\tloss: 0.825470\n",
            "Train Epoch: 5 [40/590]\tloss: 0.842729\n",
            "Train Epoch: 5 [50/590]\tloss: 0.941273\n",
            "Train Epoch: 5 [60/590]\tloss: 0.840035\n",
            "Train Epoch: 5 [70/590]\tloss: 0.852035\n",
            "Train Epoch: 5 [80/590]\tloss: 1.075392\n",
            "Train Epoch: 5 [90/590]\tloss: 0.888307\n",
            "Train Epoch: 5 [100/590]\tloss: 0.808784\n",
            "Train Epoch: 5 [110/590]\tloss: 0.945444\n",
            "Train Epoch: 5 [120/590]\tloss: 0.923138\n",
            "Train Epoch: 5 [130/590]\tloss: 0.840723\n",
            "Train Epoch: 5 [140/590]\tloss: 1.023802\n",
            "Train Epoch: 5 [150/590]\tloss: 0.832399\n",
            "Train Epoch: 5 [160/590]\tloss: 1.253813\n",
            "Train Epoch: 5 [170/590]\tloss: 0.824188\n",
            "Train Epoch: 5 [180/590]\tloss: 0.923671\n",
            "Train Epoch: 5 [190/590]\tloss: 0.881811\n",
            "Train Epoch: 5 [200/590]\tloss: 0.874125\n",
            "Train Epoch: 5 [210/590]\tloss: 0.867746\n",
            "Train Epoch: 5 [220/590]\tloss: 0.877873\n",
            "Train Epoch: 5 [230/590]\tloss: 0.931662\n",
            "Train Epoch: 5 [240/590]\tloss: 0.815843\n",
            "Train Epoch: 5 [250/590]\tloss: 0.860169\n",
            "Train Epoch: 5 [260/590]\tloss: 0.846300\n",
            "Train Epoch: 5 [270/590]\tloss: 0.822395\n",
            "Train Epoch: 5 [280/590]\tloss: 1.182536\n",
            "Train Epoch: 5 [290/590]\tloss: 0.818725\n",
            "Train Epoch: 5 [300/590]\tloss: 1.031666\n",
            "Train Epoch: 5 [310/590]\tloss: 0.807507\n",
            "Train Epoch: 5 [320/590]\tloss: 0.873507\n",
            "Train Epoch: 5 [330/590]\tloss: 0.885149\n",
            "Train Epoch: 5 [340/590]\tloss: 0.851467\n",
            "Train Epoch: 5 [350/590]\tloss: 1.552722\n",
            "Train Epoch: 5 [360/590]\tloss: 0.818862\n",
            "Train Epoch: 5 [370/590]\tloss: 0.808092\n",
            "Train Epoch: 5 [380/590]\tloss: 0.850425\n",
            "Train Epoch: 5 [390/590]\tloss: 0.800374\n",
            "Train Epoch: 5 [400/590]\tloss: 0.825636\n",
            "Train Epoch: 5 [410/590]\tloss: 0.854598\n",
            "Train Epoch: 5 [420/590]\tloss: 0.889520\n",
            "Train Epoch: 5 [430/590]\tloss: 1.149874\n",
            "Train Epoch: 5 [440/590]\tloss: 0.858646\n",
            "Train Epoch: 5 [450/590]\tloss: 0.899269\n",
            "Train Epoch: 5 [460/590]\tloss: 0.872896\n",
            "Train Epoch: 5 [470/590]\tloss: 1.042031\n",
            "Train Epoch: 5 [480/590]\tloss: 0.843063\n",
            "Train Epoch: 5 [490/590]\tloss: 0.825382\n",
            "Train Epoch: 5 [500/590]\tloss: 0.809289\n",
            "Train Epoch: 5 [510/590]\tloss: 0.824921\n",
            "Train Epoch: 5 [520/590]\tloss: 0.842078\n",
            "Train Epoch: 5 [530/590]\tloss: 0.883731\n",
            "Train Epoch: 5 [540/590]\tloss: 0.816816\n",
            "Train Epoch: 5 [550/590]\tloss: 0.876195\n",
            "Train Epoch: 5 [560/590]\tloss: 1.057448\n",
            "Train Epoch: 5 [570/590]\tloss: 0.823234\n",
            "Train Epoch: 5 [580/590]\tloss: 1.270035\n",
            "[5]Validation Loss: 0.2663,Accuracy: 93.9189%\n",
            "Train Epoch: 6 [0/590]\tloss: 0.911248\n",
            "Train Epoch: 6 [10/590]\tloss: 0.831790\n",
            "Train Epoch: 6 [20/590]\tloss: 0.810182\n",
            "Train Epoch: 6 [30/590]\tloss: 0.950293\n",
            "Train Epoch: 6 [40/590]\tloss: 0.823108\n",
            "Train Epoch: 6 [50/590]\tloss: 0.903541\n",
            "Train Epoch: 6 [60/590]\tloss: 0.849359\n",
            "Train Epoch: 6 [70/590]\tloss: 0.818391\n",
            "Train Epoch: 6 [80/590]\tloss: 0.821331\n",
            "Train Epoch: 6 [90/590]\tloss: 0.835758\n",
            "Train Epoch: 6 [100/590]\tloss: 0.981251\n",
            "Train Epoch: 6 [110/590]\tloss: 0.833737\n",
            "Train Epoch: 6 [120/590]\tloss: 0.813771\n",
            "Train Epoch: 6 [130/590]\tloss: 0.806747\n",
            "Train Epoch: 6 [140/590]\tloss: 0.801535\n",
            "Train Epoch: 6 [150/590]\tloss: 0.833936\n",
            "Train Epoch: 6 [160/590]\tloss: 0.836338\n",
            "Train Epoch: 6 [170/590]\tloss: 0.825893\n",
            "Train Epoch: 6 [180/590]\tloss: 0.823545\n",
            "Train Epoch: 6 [190/590]\tloss: 0.869200\n",
            "Train Epoch: 6 [200/590]\tloss: 0.801842\n",
            "Train Epoch: 6 [210/590]\tloss: 1.115662\n",
            "Train Epoch: 6 [220/590]\tloss: 0.865984\n",
            "Train Epoch: 6 [230/590]\tloss: 0.822561\n",
            "Train Epoch: 6 [240/590]\tloss: 0.978905\n",
            "Train Epoch: 6 [250/590]\tloss: 0.814012\n",
            "Train Epoch: 6 [260/590]\tloss: 0.810578\n",
            "Train Epoch: 6 [270/590]\tloss: 0.880284\n",
            "Train Epoch: 6 [280/590]\tloss: 0.853052\n",
            "Train Epoch: 6 [290/590]\tloss: 1.183820\n",
            "Train Epoch: 6 [300/590]\tloss: 0.801193\n",
            "Train Epoch: 6 [310/590]\tloss: 1.128716\n",
            "Train Epoch: 6 [320/590]\tloss: 0.793877\n",
            "Train Epoch: 6 [330/590]\tloss: 0.822423\n",
            "Train Epoch: 6 [340/590]\tloss: 0.862265\n",
            "Train Epoch: 6 [350/590]\tloss: 0.900875\n",
            "Train Epoch: 6 [360/590]\tloss: 1.016381\n",
            "Train Epoch: 6 [370/590]\tloss: 0.820966\n",
            "Train Epoch: 6 [380/590]\tloss: 1.052215\n",
            "Train Epoch: 6 [390/590]\tloss: 0.862753\n",
            "Train Epoch: 6 [400/590]\tloss: 0.853920\n",
            "Train Epoch: 6 [410/590]\tloss: 0.889497\n",
            "Train Epoch: 6 [420/590]\tloss: 1.219879\n",
            "Train Epoch: 6 [430/590]\tloss: 1.124105\n",
            "Train Epoch: 6 [440/590]\tloss: 0.809830\n",
            "Train Epoch: 6 [450/590]\tloss: 1.380138\n",
            "Train Epoch: 6 [460/590]\tloss: 0.805953\n",
            "Train Epoch: 6 [470/590]\tloss: 0.986699\n",
            "Train Epoch: 6 [480/590]\tloss: 0.809816\n",
            "Train Epoch: 6 [490/590]\tloss: 0.837548\n",
            "Train Epoch: 6 [500/590]\tloss: 0.968599\n",
            "Train Epoch: 6 [510/590]\tloss: 0.801937\n",
            "Train Epoch: 6 [520/590]\tloss: 0.800181\n",
            "Train Epoch: 6 [530/590]\tloss: 0.979674\n",
            "Train Epoch: 6 [540/590]\tloss: 0.934841\n",
            "Train Epoch: 6 [550/590]\tloss: 0.901082\n",
            "Train Epoch: 6 [560/590]\tloss: 0.843765\n",
            "Train Epoch: 6 [570/590]\tloss: 0.889308\n",
            "Train Epoch: 6 [580/590]\tloss: 0.989382\n",
            "[6]Validation Loss: 0.2310,Accuracy: 95.2703%\n",
            "Train Epoch: 7 [0/590]\tloss: 0.805454\n",
            "Train Epoch: 7 [10/590]\tloss: 0.812042\n",
            "Train Epoch: 7 [20/590]\tloss: 0.811027\n",
            "Train Epoch: 7 [30/590]\tloss: 0.871691\n",
            "Train Epoch: 7 [40/590]\tloss: 0.913727\n",
            "Train Epoch: 7 [50/590]\tloss: 0.799610\n",
            "Train Epoch: 7 [60/590]\tloss: 0.834791\n",
            "Train Epoch: 7 [70/590]\tloss: 0.806286\n",
            "Train Epoch: 7 [80/590]\tloss: 0.856641\n",
            "Train Epoch: 7 [90/590]\tloss: 0.814867\n",
            "Train Epoch: 7 [100/590]\tloss: 0.949961\n",
            "Train Epoch: 7 [110/590]\tloss: 0.827768\n",
            "Train Epoch: 7 [120/590]\tloss: 0.972132\n",
            "Train Epoch: 7 [130/590]\tloss: 0.804317\n",
            "Train Epoch: 7 [140/590]\tloss: 0.879511\n",
            "Train Epoch: 7 [150/590]\tloss: 0.801840\n",
            "Train Epoch: 7 [160/590]\tloss: 0.802586\n",
            "Train Epoch: 7 [170/590]\tloss: 0.850863\n",
            "Train Epoch: 7 [180/590]\tloss: 0.934129\n",
            "Train Epoch: 7 [190/590]\tloss: 0.840305\n",
            "Train Epoch: 7 [200/590]\tloss: 1.040037\n",
            "Train Epoch: 7 [210/590]\tloss: 1.236118\n",
            "Train Epoch: 7 [220/590]\tloss: 1.076597\n",
            "Train Epoch: 7 [230/590]\tloss: 0.815148\n",
            "Train Epoch: 7 [240/590]\tloss: 0.913875\n",
            "Train Epoch: 7 [250/590]\tloss: 0.980764\n",
            "Train Epoch: 7 [260/590]\tloss: 0.847354\n",
            "Train Epoch: 7 [270/590]\tloss: 0.807949\n",
            "Train Epoch: 7 [280/590]\tloss: 0.807862\n",
            "Train Epoch: 7 [290/590]\tloss: 0.804364\n",
            "Train Epoch: 7 [300/590]\tloss: 0.996018\n",
            "Train Epoch: 7 [310/590]\tloss: 0.801596\n",
            "Train Epoch: 7 [320/590]\tloss: 0.893079\n",
            "Train Epoch: 7 [330/590]\tloss: 0.821232\n",
            "Train Epoch: 7 [340/590]\tloss: 0.804807\n",
            "Train Epoch: 7 [350/590]\tloss: 0.829139\n",
            "Train Epoch: 7 [360/590]\tloss: 0.803034\n",
            "Train Epoch: 7 [370/590]\tloss: 0.916575\n",
            "Train Epoch: 7 [380/590]\tloss: 0.810838\n",
            "Train Epoch: 7 [390/590]\tloss: 0.813100\n",
            "Train Epoch: 7 [400/590]\tloss: 0.788705\n",
            "Train Epoch: 7 [410/590]\tloss: 0.890099\n",
            "Train Epoch: 7 [420/590]\tloss: 0.862100\n",
            "Train Epoch: 7 [430/590]\tloss: 0.801653\n",
            "Train Epoch: 7 [440/590]\tloss: 0.810068\n",
            "Train Epoch: 7 [450/590]\tloss: 0.914279\n",
            "Train Epoch: 7 [460/590]\tloss: 0.805849\n",
            "Train Epoch: 7 [470/590]\tloss: 0.793911\n",
            "Train Epoch: 7 [480/590]\tloss: 0.806425\n",
            "Train Epoch: 7 [490/590]\tloss: 0.825441\n",
            "Train Epoch: 7 [500/590]\tloss: 0.991539\n",
            "Train Epoch: 7 [510/590]\tloss: 0.864069\n",
            "Train Epoch: 7 [520/590]\tloss: 0.808681\n",
            "Train Epoch: 7 [530/590]\tloss: 0.826132\n",
            "Train Epoch: 7 [540/590]\tloss: 1.101379\n",
            "Train Epoch: 7 [550/590]\tloss: 0.801765\n",
            "Train Epoch: 7 [560/590]\tloss: 0.900676\n",
            "Train Epoch: 7 [570/590]\tloss: 0.808000\n",
            "Train Epoch: 7 [580/590]\tloss: 0.813584\n",
            "[7]Validation Loss: 0.2449,Accuracy: 93.9189%\n",
            "Train Epoch: 8 [0/590]\tloss: 0.820286\n",
            "Train Epoch: 8 [10/590]\tloss: 0.797808\n",
            "Train Epoch: 8 [20/590]\tloss: 0.800201\n",
            "Train Epoch: 8 [30/590]\tloss: 0.797926\n",
            "Train Epoch: 8 [40/590]\tloss: 0.829877\n",
            "Train Epoch: 8 [50/590]\tloss: 0.795682\n",
            "Train Epoch: 8 [60/590]\tloss: 0.857126\n",
            "Train Epoch: 8 [70/590]\tloss: 0.808458\n",
            "Train Epoch: 8 [80/590]\tloss: 0.800770\n",
            "Train Epoch: 8 [90/590]\tloss: 0.808543\n",
            "Train Epoch: 8 [100/590]\tloss: 0.794508\n",
            "Train Epoch: 8 [110/590]\tloss: 0.832871\n",
            "Train Epoch: 8 [120/590]\tloss: 0.805668\n",
            "Train Epoch: 8 [130/590]\tloss: 0.823385\n",
            "Train Epoch: 8 [140/590]\tloss: 0.803381\n",
            "Train Epoch: 8 [150/590]\tloss: 0.798108\n",
            "Train Epoch: 8 [160/590]\tloss: 0.811206\n",
            "Train Epoch: 8 [170/590]\tloss: 1.009015\n",
            "Train Epoch: 8 [180/590]\tloss: 0.803048\n",
            "Train Epoch: 8 [190/590]\tloss: 0.841580\n",
            "Train Epoch: 8 [200/590]\tloss: 0.803973\n",
            "Train Epoch: 8 [210/590]\tloss: 0.821812\n",
            "Train Epoch: 8 [220/590]\tloss: 0.811288\n",
            "Train Epoch: 8 [230/590]\tloss: 0.840263\n",
            "Train Epoch: 8 [240/590]\tloss: 0.808860\n",
            "Train Epoch: 8 [250/590]\tloss: 0.794956\n",
            "Train Epoch: 8 [260/590]\tloss: 0.874521\n",
            "Train Epoch: 8 [270/590]\tloss: 0.792827\n",
            "Train Epoch: 8 [280/590]\tloss: 0.849026\n",
            "Train Epoch: 8 [290/590]\tloss: 0.796521\n",
            "Train Epoch: 8 [300/590]\tloss: 0.904084\n",
            "Train Epoch: 8 [310/590]\tloss: 0.794253\n",
            "Train Epoch: 8 [320/590]\tloss: 0.864179\n",
            "Train Epoch: 8 [330/590]\tloss: 0.821809\n",
            "Train Epoch: 8 [340/590]\tloss: 0.801246\n",
            "Train Epoch: 8 [350/590]\tloss: 0.821599\n",
            "Train Epoch: 8 [360/590]\tloss: 0.858600\n",
            "Train Epoch: 8 [370/590]\tloss: 0.796061\n",
            "Train Epoch: 8 [380/590]\tloss: 0.792466\n",
            "Train Epoch: 8 [390/590]\tloss: 0.797352\n",
            "Train Epoch: 8 [400/590]\tloss: 0.810790\n",
            "Train Epoch: 8 [410/590]\tloss: 0.800205\n",
            "Train Epoch: 8 [420/590]\tloss: 0.802261\n",
            "Train Epoch: 8 [430/590]\tloss: 0.824803\n",
            "Train Epoch: 8 [440/590]\tloss: 0.809373\n",
            "Train Epoch: 8 [450/590]\tloss: 0.800901\n",
            "Train Epoch: 8 [460/590]\tloss: 0.809989\n",
            "Train Epoch: 8 [470/590]\tloss: 0.794115\n",
            "Train Epoch: 8 [480/590]\tloss: 0.834769\n",
            "Train Epoch: 8 [490/590]\tloss: 0.901137\n",
            "Train Epoch: 8 [500/590]\tloss: 0.809145\n",
            "Train Epoch: 8 [510/590]\tloss: 0.791821\n",
            "Train Epoch: 8 [520/590]\tloss: 0.821192\n",
            "Train Epoch: 8 [530/590]\tloss: 0.787623\n",
            "Train Epoch: 8 [540/590]\tloss: 0.807823\n",
            "Train Epoch: 8 [550/590]\tloss: 0.793118\n",
            "Train Epoch: 8 [560/590]\tloss: 0.797754\n",
            "Train Epoch: 8 [570/590]\tloss: 0.793986\n",
            "Train Epoch: 8 [580/590]\tloss: 0.995020\n",
            "[8]Validation Loss: 0.2278,Accuracy: 94.5946%\n",
            "Train Epoch: 9 [0/590]\tloss: 0.807568\n",
            "Train Epoch: 9 [10/590]\tloss: 1.034667\n",
            "Train Epoch: 9 [20/590]\tloss: 0.795990\n",
            "Train Epoch: 9 [30/590]\tloss: 0.833004\n",
            "Train Epoch: 9 [40/590]\tloss: 0.796030\n",
            "Train Epoch: 9 [50/590]\tloss: 0.850593\n",
            "Train Epoch: 9 [60/590]\tloss: 0.800858\n",
            "Train Epoch: 9 [70/590]\tloss: 0.791782\n",
            "Train Epoch: 9 [80/590]\tloss: 0.794566\n",
            "Train Epoch: 9 [90/590]\tloss: 0.818823\n",
            "Train Epoch: 9 [100/590]\tloss: 0.958951\n",
            "Train Epoch: 9 [110/590]\tloss: 0.786808\n",
            "Train Epoch: 9 [120/590]\tloss: 0.810136\n",
            "Train Epoch: 9 [130/590]\tloss: 0.875975\n",
            "Train Epoch: 9 [140/590]\tloss: 1.098234\n",
            "Train Epoch: 9 [150/590]\tloss: 0.797079\n",
            "Train Epoch: 9 [160/590]\tloss: 0.794097\n",
            "Train Epoch: 9 [170/590]\tloss: 1.023606\n",
            "Train Epoch: 9 [180/590]\tloss: 0.814536\n",
            "Train Epoch: 9 [190/590]\tloss: 1.010528\n",
            "Train Epoch: 9 [200/590]\tloss: 0.789664\n",
            "Train Epoch: 9 [210/590]\tloss: 0.797651\n",
            "Train Epoch: 9 [220/590]\tloss: 0.831443\n",
            "Train Epoch: 9 [230/590]\tloss: 0.811650\n",
            "Train Epoch: 9 [240/590]\tloss: 0.799831\n",
            "Train Epoch: 9 [250/590]\tloss: 0.793006\n",
            "Train Epoch: 9 [260/590]\tloss: 0.863383\n",
            "Train Epoch: 9 [270/590]\tloss: 0.833815\n",
            "Train Epoch: 9 [280/590]\tloss: 0.814662\n",
            "Train Epoch: 9 [290/590]\tloss: 0.790488\n",
            "Train Epoch: 9 [300/590]\tloss: 0.795407\n",
            "Train Epoch: 9 [310/590]\tloss: 0.793137\n",
            "Train Epoch: 9 [320/590]\tloss: 0.791579\n",
            "Train Epoch: 9 [330/590]\tloss: 0.857526\n",
            "Train Epoch: 9 [340/590]\tloss: 0.936973\n",
            "Train Epoch: 9 [350/590]\tloss: 0.984796\n",
            "Train Epoch: 9 [360/590]\tloss: 0.796570\n",
            "Train Epoch: 9 [370/590]\tloss: 0.789131\n",
            "Train Epoch: 9 [380/590]\tloss: 0.810116\n",
            "Train Epoch: 9 [390/590]\tloss: 0.798076\n",
            "Train Epoch: 9 [400/590]\tloss: 0.795596\n",
            "Train Epoch: 9 [410/590]\tloss: 0.784024\n",
            "Train Epoch: 9 [420/590]\tloss: 0.787522\n",
            "Train Epoch: 9 [430/590]\tloss: 0.842266\n",
            "Train Epoch: 9 [440/590]\tloss: 1.119733\n",
            "Train Epoch: 9 [450/590]\tloss: 0.796195\n",
            "Train Epoch: 9 [460/590]\tloss: 0.789683\n",
            "Train Epoch: 9 [470/590]\tloss: 0.831193\n",
            "Train Epoch: 9 [480/590]\tloss: 0.824180\n",
            "Train Epoch: 9 [490/590]\tloss: 0.936429\n",
            "Train Epoch: 9 [500/590]\tloss: 0.938310\n",
            "Train Epoch: 9 [510/590]\tloss: 0.928375\n",
            "Train Epoch: 9 [520/590]\tloss: 0.791852\n",
            "Train Epoch: 9 [530/590]\tloss: 0.898551\n",
            "Train Epoch: 9 [540/590]\tloss: 0.804970\n",
            "Train Epoch: 9 [550/590]\tloss: 0.851512\n",
            "Train Epoch: 9 [560/590]\tloss: 1.443649\n",
            "Train Epoch: 9 [570/590]\tloss: 0.787814\n",
            "Train Epoch: 9 [580/590]\tloss: 0.916149\n",
            "[9]Validation Loss: 0.2503,Accuracy: 95.2703%\n",
            "Train Epoch: 10 [0/590]\tloss: 0.791060\n",
            "Train Epoch: 10 [10/590]\tloss: 0.917827\n",
            "Train Epoch: 10 [20/590]\tloss: 0.787830\n",
            "Train Epoch: 10 [30/590]\tloss: 0.789987\n",
            "Train Epoch: 10 [40/590]\tloss: 0.823052\n",
            "Train Epoch: 10 [50/590]\tloss: 0.788467\n",
            "Train Epoch: 10 [60/590]\tloss: 0.965923\n",
            "Train Epoch: 10 [70/590]\tloss: 0.822111\n",
            "Train Epoch: 10 [80/590]\tloss: 0.797947\n",
            "Train Epoch: 10 [90/590]\tloss: 0.802046\n",
            "Train Epoch: 10 [100/590]\tloss: 0.792379\n",
            "Train Epoch: 10 [110/590]\tloss: 0.899637\n",
            "Train Epoch: 10 [120/590]\tloss: 0.902376\n",
            "Train Epoch: 10 [130/590]\tloss: 0.784353\n",
            "Train Epoch: 10 [140/590]\tloss: 0.786628\n",
            "Train Epoch: 10 [150/590]\tloss: 0.842246\n",
            "Train Epoch: 10 [160/590]\tloss: 0.848964\n",
            "Train Epoch: 10 [170/590]\tloss: 0.795393\n",
            "Train Epoch: 10 [180/590]\tloss: 0.836672\n",
            "Train Epoch: 10 [190/590]\tloss: 0.815750\n",
            "Train Epoch: 10 [200/590]\tloss: 0.796382\n",
            "Train Epoch: 10 [210/590]\tloss: 0.791881\n",
            "Train Epoch: 10 [220/590]\tloss: 0.834936\n",
            "Train Epoch: 10 [230/590]\tloss: 0.793496\n",
            "Train Epoch: 10 [240/590]\tloss: 0.802796\n",
            "Train Epoch: 10 [250/590]\tloss: 0.782111\n",
            "Train Epoch: 10 [260/590]\tloss: 0.794592\n",
            "Train Epoch: 10 [270/590]\tloss: 0.790490\n",
            "Train Epoch: 10 [280/590]\tloss: 0.787422\n",
            "Train Epoch: 10 [290/590]\tloss: 0.797071\n",
            "Train Epoch: 10 [300/590]\tloss: 0.790145\n",
            "Train Epoch: 10 [310/590]\tloss: 0.839784\n",
            "Train Epoch: 10 [320/590]\tloss: 0.806499\n",
            "Train Epoch: 10 [330/590]\tloss: 0.791049\n",
            "Train Epoch: 10 [340/590]\tloss: 0.798835\n",
            "Train Epoch: 10 [350/590]\tloss: 0.786531\n",
            "Train Epoch: 10 [360/590]\tloss: 1.035815\n",
            "Train Epoch: 10 [370/590]\tloss: 0.983872\n",
            "Train Epoch: 10 [380/590]\tloss: 0.796075\n",
            "Train Epoch: 10 [390/590]\tloss: 0.795047\n",
            "Train Epoch: 10 [400/590]\tloss: 1.160589\n",
            "Train Epoch: 10 [410/590]\tloss: 0.805247\n",
            "Train Epoch: 10 [420/590]\tloss: 0.782474\n",
            "Train Epoch: 10 [430/590]\tloss: 0.791358\n",
            "Train Epoch: 10 [440/590]\tloss: 0.801809\n",
            "Train Epoch: 10 [450/590]\tloss: 1.104640\n",
            "Train Epoch: 10 [460/590]\tloss: 0.798865\n",
            "Train Epoch: 10 [470/590]\tloss: 0.784682\n",
            "Train Epoch: 10 [480/590]\tloss: 0.804024\n",
            "Train Epoch: 10 [490/590]\tloss: 0.919653\n",
            "Train Epoch: 10 [500/590]\tloss: 0.978729\n",
            "Train Epoch: 10 [510/590]\tloss: 0.871131\n",
            "Train Epoch: 10 [520/590]\tloss: 1.327539\n",
            "Train Epoch: 10 [530/590]\tloss: 0.907658\n",
            "Train Epoch: 10 [540/590]\tloss: 0.780373\n",
            "Train Epoch: 10 [550/590]\tloss: 0.799325\n",
            "Train Epoch: 10 [560/590]\tloss: 0.792621\n",
            "Train Epoch: 10 [570/590]\tloss: 0.807364\n",
            "Train Epoch: 10 [580/590]\tloss: 0.784120\n",
            "[10]Validation Loss: 0.2614,Accuracy: 94.9324%\n",
            "Train Epoch: 11 [0/590]\tloss: 0.808634\n",
            "Train Epoch: 11 [10/590]\tloss: 0.828481\n",
            "Train Epoch: 11 [20/590]\tloss: 0.849881\n",
            "Train Epoch: 11 [30/590]\tloss: 0.803290\n",
            "Train Epoch: 11 [40/590]\tloss: 0.818267\n",
            "Train Epoch: 11 [50/590]\tloss: 0.972231\n",
            "Train Epoch: 11 [60/590]\tloss: 1.091594\n",
            "Train Epoch: 11 [70/590]\tloss: 0.804516\n",
            "Train Epoch: 11 [80/590]\tloss: 0.800719\n",
            "Train Epoch: 11 [90/590]\tloss: 0.801786\n",
            "Train Epoch: 11 [100/590]\tloss: 0.795902\n",
            "Train Epoch: 11 [110/590]\tloss: 0.828335\n",
            "Train Epoch: 11 [120/590]\tloss: 0.834603\n",
            "Train Epoch: 11 [130/590]\tloss: 0.805086\n",
            "Train Epoch: 11 [140/590]\tloss: 0.866005\n",
            "Train Epoch: 11 [150/590]\tloss: 0.792264\n",
            "Train Epoch: 11 [160/590]\tloss: 0.794182\n",
            "Train Epoch: 11 [170/590]\tloss: 0.791866\n",
            "Train Epoch: 11 [180/590]\tloss: 1.187395\n",
            "Train Epoch: 11 [190/590]\tloss: 0.881180\n",
            "Train Epoch: 11 [200/590]\tloss: 0.793938\n",
            "Train Epoch: 11 [210/590]\tloss: 0.795175\n",
            "Train Epoch: 11 [220/590]\tloss: 0.790691\n",
            "Train Epoch: 11 [230/590]\tloss: 0.880806\n",
            "Train Epoch: 11 [240/590]\tloss: 0.785456\n",
            "Train Epoch: 11 [250/590]\tloss: 0.791654\n",
            "Train Epoch: 11 [260/590]\tloss: 0.792031\n",
            "Train Epoch: 11 [270/590]\tloss: 0.828794\n",
            "Train Epoch: 11 [280/590]\tloss: 0.810393\n",
            "Train Epoch: 11 [290/590]\tloss: 0.805726\n",
            "Train Epoch: 11 [300/590]\tloss: 0.909171\n",
            "Train Epoch: 11 [310/590]\tloss: 0.789519\n",
            "Train Epoch: 11 [320/590]\tloss: 0.797827\n",
            "Train Epoch: 11 [330/590]\tloss: 0.801386\n",
            "Train Epoch: 11 [340/590]\tloss: 0.787368\n",
            "Train Epoch: 11 [350/590]\tloss: 0.794338\n",
            "Train Epoch: 11 [360/590]\tloss: 0.817352\n",
            "Train Epoch: 11 [370/590]\tloss: 0.787092\n",
            "Train Epoch: 11 [380/590]\tloss: 0.827315\n",
            "Train Epoch: 11 [390/590]\tloss: 0.804405\n",
            "Train Epoch: 11 [400/590]\tloss: 0.777492\n",
            "Train Epoch: 11 [410/590]\tloss: 1.154545\n",
            "Train Epoch: 11 [420/590]\tloss: 0.780491\n",
            "Train Epoch: 11 [430/590]\tloss: 1.048451\n",
            "Train Epoch: 11 [440/590]\tloss: 0.802670\n",
            "Train Epoch: 11 [450/590]\tloss: 0.804843\n",
            "Train Epoch: 11 [460/590]\tloss: 0.789228\n",
            "Train Epoch: 11 [470/590]\tloss: 0.790520\n",
            "Train Epoch: 11 [480/590]\tloss: 0.790696\n",
            "Train Epoch: 11 [490/590]\tloss: 0.798789\n",
            "Train Epoch: 11 [500/590]\tloss: 0.812950\n",
            "Train Epoch: 11 [510/590]\tloss: 0.851362\n",
            "Train Epoch: 11 [520/590]\tloss: 0.786915\n",
            "Train Epoch: 11 [530/590]\tloss: 0.782983\n",
            "Train Epoch: 11 [540/590]\tloss: 0.780903\n",
            "Train Epoch: 11 [550/590]\tloss: 0.860844\n",
            "Train Epoch: 11 [560/590]\tloss: 0.799860\n",
            "Train Epoch: 11 [570/590]\tloss: 0.790954\n",
            "Train Epoch: 11 [580/590]\tloss: 0.852955\n",
            "[11]Validation Loss: 0.2938,Accuracy: 92.5676%\n",
            "Train Epoch: 12 [0/590]\tloss: 0.799018\n",
            "Train Epoch: 12 [10/590]\tloss: 0.791145\n",
            "Train Epoch: 12 [20/590]\tloss: 0.796851\n",
            "Train Epoch: 12 [30/590]\tloss: 0.786572\n",
            "Train Epoch: 12 [40/590]\tloss: 0.823862\n",
            "Train Epoch: 12 [50/590]\tloss: 0.778638\n",
            "Train Epoch: 12 [60/590]\tloss: 0.787912\n",
            "Train Epoch: 12 [70/590]\tloss: 0.781243\n",
            "Train Epoch: 12 [80/590]\tloss: 1.052967\n",
            "Train Epoch: 12 [90/590]\tloss: 0.784015\n",
            "Train Epoch: 12 [100/590]\tloss: 0.877387\n",
            "Train Epoch: 12 [110/590]\tloss: 0.841007\n",
            "Train Epoch: 12 [120/590]\tloss: 0.797926\n",
            "Train Epoch: 12 [130/590]\tloss: 0.780860\n",
            "Train Epoch: 12 [140/590]\tloss: 0.817982\n",
            "Train Epoch: 12 [150/590]\tloss: 0.794231\n",
            "Train Epoch: 12 [160/590]\tloss: 0.791654\n",
            "Train Epoch: 12 [170/590]\tloss: 0.806574\n",
            "Train Epoch: 12 [180/590]\tloss: 0.787297\n",
            "Train Epoch: 12 [190/590]\tloss: 0.788824\n",
            "Train Epoch: 12 [200/590]\tloss: 1.112780\n",
            "Train Epoch: 12 [210/590]\tloss: 0.811473\n",
            "Train Epoch: 12 [220/590]\tloss: 0.796162\n",
            "Train Epoch: 12 [230/590]\tloss: 1.053214\n",
            "Train Epoch: 12 [240/590]\tloss: 0.821860\n",
            "Train Epoch: 12 [250/590]\tloss: 0.821637\n",
            "Train Epoch: 12 [260/590]\tloss: 0.868436\n",
            "Train Epoch: 12 [270/590]\tloss: 0.808111\n",
            "Train Epoch: 12 [280/590]\tloss: 0.781999\n",
            "Train Epoch: 12 [290/590]\tloss: 0.790636\n",
            "Train Epoch: 12 [300/590]\tloss: 0.839074\n",
            "Train Epoch: 12 [310/590]\tloss: 0.808289\n",
            "Train Epoch: 12 [320/590]\tloss: 0.782042\n",
            "Train Epoch: 12 [330/590]\tloss: 0.938973\n",
            "Train Epoch: 12 [340/590]\tloss: 0.786912\n",
            "Train Epoch: 12 [350/590]\tloss: 0.802421\n",
            "Train Epoch: 12 [360/590]\tloss: 0.781916\n",
            "Train Epoch: 12 [370/590]\tloss: 0.785399\n",
            "Train Epoch: 12 [380/590]\tloss: 0.787708\n",
            "Train Epoch: 12 [390/590]\tloss: 0.792138\n",
            "Train Epoch: 12 [400/590]\tloss: 0.965392\n",
            "Train Epoch: 12 [410/590]\tloss: 0.861729\n",
            "Train Epoch: 12 [420/590]\tloss: 0.796739\n",
            "Train Epoch: 12 [430/590]\tloss: 0.789627\n",
            "Train Epoch: 12 [440/590]\tloss: 0.788855\n",
            "Train Epoch: 12 [450/590]\tloss: 0.811038\n",
            "Train Epoch: 12 [460/590]\tloss: 0.797034\n",
            "Train Epoch: 12 [470/590]\tloss: 0.795834\n",
            "Train Epoch: 12 [480/590]\tloss: 0.896649\n",
            "Train Epoch: 12 [490/590]\tloss: 0.984291\n",
            "Train Epoch: 12 [500/590]\tloss: 0.813211\n",
            "Train Epoch: 12 [510/590]\tloss: 0.805948\n",
            "Train Epoch: 12 [520/590]\tloss: 0.788145\n",
            "Train Epoch: 12 [530/590]\tloss: 0.806843\n",
            "Train Epoch: 12 [540/590]\tloss: 0.814001\n",
            "Train Epoch: 12 [550/590]\tloss: 0.794635\n",
            "Train Epoch: 12 [560/590]\tloss: 0.804169\n",
            "Train Epoch: 12 [570/590]\tloss: 0.783797\n",
            "Train Epoch: 12 [580/590]\tloss: 0.782526\n",
            "[12]Validation Loss: 0.2105,Accuracy: 94.5946%\n",
            "Train Epoch: 13 [0/590]\tloss: 0.821645\n",
            "Train Epoch: 13 [10/590]\tloss: 0.782334\n",
            "Train Epoch: 13 [20/590]\tloss: 0.802139\n",
            "Train Epoch: 13 [30/590]\tloss: 0.789472\n",
            "Train Epoch: 13 [40/590]\tloss: 0.813542\n",
            "Train Epoch: 13 [50/590]\tloss: 0.789534\n",
            "Train Epoch: 13 [60/590]\tloss: 0.783980\n",
            "Train Epoch: 13 [70/590]\tloss: 0.774794\n",
            "Train Epoch: 13 [80/590]\tloss: 0.823992\n",
            "Train Epoch: 13 [90/590]\tloss: 0.789823\n",
            "Train Epoch: 13 [100/590]\tloss: 0.897632\n",
            "Train Epoch: 13 [110/590]\tloss: 0.787065\n",
            "Train Epoch: 13 [120/590]\tloss: 0.809529\n",
            "Train Epoch: 13 [130/590]\tloss: 0.777057\n",
            "Train Epoch: 13 [140/590]\tloss: 0.781162\n",
            "Train Epoch: 13 [150/590]\tloss: 0.798239\n",
            "Train Epoch: 13 [160/590]\tloss: 0.785473\n",
            "Train Epoch: 13 [170/590]\tloss: 0.778662\n",
            "Train Epoch: 13 [180/590]\tloss: 0.841289\n",
            "Train Epoch: 13 [190/590]\tloss: 0.794658\n",
            "Train Epoch: 13 [200/590]\tloss: 0.803371\n",
            "Train Epoch: 13 [210/590]\tloss: 0.802483\n",
            "Train Epoch: 13 [220/590]\tloss: 0.920094\n",
            "Train Epoch: 13 [230/590]\tloss: 0.786375\n",
            "Train Epoch: 13 [240/590]\tloss: 0.852660\n",
            "Train Epoch: 13 [250/590]\tloss: 0.781907\n",
            "Train Epoch: 13 [260/590]\tloss: 0.775887\n",
            "Train Epoch: 13 [270/590]\tloss: 0.784395\n",
            "Train Epoch: 13 [280/590]\tloss: 0.792837\n",
            "Train Epoch: 13 [290/590]\tloss: 1.173689\n",
            "Train Epoch: 13 [300/590]\tloss: 0.898126\n",
            "Train Epoch: 13 [310/590]\tloss: 0.802800\n",
            "Train Epoch: 13 [320/590]\tloss: 0.790206\n",
            "Train Epoch: 13 [330/590]\tloss: 0.792960\n",
            "Train Epoch: 13 [340/590]\tloss: 0.783156\n",
            "Train Epoch: 13 [350/590]\tloss: 0.787135\n",
            "Train Epoch: 13 [360/590]\tloss: 0.892330\n",
            "Train Epoch: 13 [370/590]\tloss: 0.800549\n",
            "Train Epoch: 13 [380/590]\tloss: 0.781843\n",
            "Train Epoch: 13 [390/590]\tloss: 0.801020\n",
            "Train Epoch: 13 [400/590]\tloss: 0.794279\n",
            "Train Epoch: 13 [410/590]\tloss: 0.793888\n",
            "Train Epoch: 13 [420/590]\tloss: 0.782299\n",
            "Train Epoch: 13 [430/590]\tloss: 0.780177\n",
            "Train Epoch: 13 [440/590]\tloss: 0.788486\n",
            "Train Epoch: 13 [450/590]\tloss: 0.796013\n",
            "Train Epoch: 13 [460/590]\tloss: 0.773255\n",
            "Train Epoch: 13 [470/590]\tloss: 0.793235\n",
            "Train Epoch: 13 [480/590]\tloss: 0.788547\n",
            "Train Epoch: 13 [490/590]\tloss: 0.786212\n",
            "Train Epoch: 13 [500/590]\tloss: 0.890447\n",
            "Train Epoch: 13 [510/590]\tloss: 0.803620\n",
            "Train Epoch: 13 [520/590]\tloss: 0.787614\n",
            "Train Epoch: 13 [530/590]\tloss: 0.792548\n",
            "Train Epoch: 13 [540/590]\tloss: 0.803884\n",
            "Train Epoch: 13 [550/590]\tloss: 0.781054\n",
            "Train Epoch: 13 [560/590]\tloss: 0.778528\n",
            "Train Epoch: 13 [570/590]\tloss: 0.785850\n",
            "Train Epoch: 13 [580/590]\tloss: 0.814452\n",
            "[13]Validation Loss: 0.2775,Accuracy: 93.9189%\n",
            "Train Epoch: 14 [0/590]\tloss: 0.884448\n",
            "Train Epoch: 14 [10/590]\tloss: 0.784310\n",
            "Train Epoch: 14 [20/590]\tloss: 1.015507\n",
            "Train Epoch: 14 [30/590]\tloss: 0.799807\n",
            "Train Epoch: 14 [40/590]\tloss: 0.786388\n",
            "Train Epoch: 14 [50/590]\tloss: 0.946584\n",
            "Train Epoch: 14 [60/590]\tloss: 1.515742\n",
            "Train Epoch: 14 [70/590]\tloss: 0.977692\n",
            "Train Epoch: 14 [80/590]\tloss: 0.780686\n",
            "Train Epoch: 14 [90/590]\tloss: 0.795706\n",
            "Train Epoch: 14 [100/590]\tloss: 0.921796\n",
            "Train Epoch: 14 [110/590]\tloss: 0.813830\n",
            "Train Epoch: 14 [120/590]\tloss: 0.781389\n",
            "Train Epoch: 14 [130/590]\tloss: 0.786057\n",
            "Train Epoch: 14 [140/590]\tloss: 0.990327\n",
            "Train Epoch: 14 [150/590]\tloss: 0.844915\n",
            "Train Epoch: 14 [160/590]\tloss: 0.797575\n",
            "Train Epoch: 14 [170/590]\tloss: 0.783365\n",
            "Train Epoch: 14 [180/590]\tloss: 0.804898\n",
            "Train Epoch: 14 [190/590]\tloss: 1.355884\n",
            "Train Epoch: 14 [200/590]\tloss: 0.781617\n",
            "Train Epoch: 14 [210/590]\tloss: 0.792649\n",
            "Train Epoch: 14 [220/590]\tloss: 0.783537\n",
            "Train Epoch: 14 [230/590]\tloss: 0.801320\n",
            "Train Epoch: 14 [240/590]\tloss: 1.018641\n",
            "Train Epoch: 14 [250/590]\tloss: 0.796075\n",
            "Train Epoch: 14 [260/590]\tloss: 0.787336\n",
            "Train Epoch: 14 [270/590]\tloss: 0.793402\n",
            "Train Epoch: 14 [280/590]\tloss: 0.785089\n",
            "Train Epoch: 14 [290/590]\tloss: 0.787710\n",
            "Train Epoch: 14 [300/590]\tloss: 0.862240\n",
            "Train Epoch: 14 [310/590]\tloss: 0.897936\n",
            "Train Epoch: 14 [320/590]\tloss: 0.793512\n",
            "Train Epoch: 14 [330/590]\tloss: 0.790868\n",
            "Train Epoch: 14 [340/590]\tloss: 1.040587\n",
            "Train Epoch: 14 [350/590]\tloss: 0.813279\n",
            "Train Epoch: 14 [360/590]\tloss: 0.795981\n",
            "Train Epoch: 14 [370/590]\tloss: 0.945088\n",
            "Train Epoch: 14 [380/590]\tloss: 0.785025\n",
            "Train Epoch: 14 [390/590]\tloss: 1.151366\n",
            "Train Epoch: 14 [400/590]\tloss: 0.805875\n",
            "Train Epoch: 14 [410/590]\tloss: 0.782087\n",
            "Train Epoch: 14 [420/590]\tloss: 0.788466\n",
            "Train Epoch: 14 [430/590]\tloss: 0.800109\n",
            "Train Epoch: 14 [440/590]\tloss: 0.797944\n",
            "Train Epoch: 14 [450/590]\tloss: 1.033390\n",
            "Train Epoch: 14 [460/590]\tloss: 0.777402\n",
            "Train Epoch: 14 [470/590]\tloss: 1.026967\n",
            "Train Epoch: 14 [480/590]\tloss: 0.800523\n",
            "Train Epoch: 14 [490/590]\tloss: 0.972859\n",
            "Train Epoch: 14 [500/590]\tloss: 0.903455\n",
            "Train Epoch: 14 [510/590]\tloss: 0.790496\n",
            "Train Epoch: 14 [520/590]\tloss: 0.897270\n",
            "Train Epoch: 14 [530/590]\tloss: 0.965205\n",
            "Train Epoch: 14 [540/590]\tloss: 1.006676\n",
            "Train Epoch: 14 [550/590]\tloss: 0.794753\n",
            "Train Epoch: 14 [560/590]\tloss: 0.814344\n",
            "Train Epoch: 14 [570/590]\tloss: 0.792275\n",
            "Train Epoch: 14 [580/590]\tloss: 0.803543\n",
            "[14]Validation Loss: 0.2777,Accuracy: 94.2568%\n",
            "Train Epoch: 15 [0/590]\tloss: 1.093159\n",
            "Train Epoch: 15 [10/590]\tloss: 0.782182\n",
            "Train Epoch: 15 [20/590]\tloss: 0.941914\n",
            "Train Epoch: 15 [30/590]\tloss: 0.788177\n",
            "Train Epoch: 15 [40/590]\tloss: 0.782414\n",
            "Train Epoch: 15 [50/590]\tloss: 0.786822\n",
            "Train Epoch: 15 [60/590]\tloss: 0.790001\n",
            "Train Epoch: 15 [70/590]\tloss: 0.789538\n",
            "Train Epoch: 15 [80/590]\tloss: 0.909726\n",
            "Train Epoch: 15 [90/590]\tloss: 0.780614\n",
            "Train Epoch: 15 [100/590]\tloss: 0.789587\n",
            "Train Epoch: 15 [110/590]\tloss: 0.825510\n",
            "Train Epoch: 15 [120/590]\tloss: 0.782687\n",
            "Train Epoch: 15 [130/590]\tloss: 0.786693\n",
            "Train Epoch: 15 [140/590]\tloss: 0.792877\n",
            "Train Epoch: 15 [150/590]\tloss: 0.781695\n",
            "Train Epoch: 15 [160/590]\tloss: 0.779485\n",
            "Train Epoch: 15 [170/590]\tloss: 0.790352\n",
            "Train Epoch: 15 [180/590]\tloss: 0.784436\n",
            "Train Epoch: 15 [190/590]\tloss: 0.898944\n",
            "Train Epoch: 15 [200/590]\tloss: 0.797075\n",
            "Train Epoch: 15 [210/590]\tloss: 0.832001\n",
            "Train Epoch: 15 [220/590]\tloss: 0.780145\n",
            "Train Epoch: 15 [230/590]\tloss: 0.798545\n",
            "Train Epoch: 15 [240/590]\tloss: 0.812404\n",
            "Train Epoch: 15 [250/590]\tloss: 0.803318\n",
            "Train Epoch: 15 [260/590]\tloss: 0.779282\n",
            "Train Epoch: 15 [270/590]\tloss: 0.786085\n",
            "Train Epoch: 15 [280/590]\tloss: 0.779638\n",
            "Train Epoch: 15 [290/590]\tloss: 0.788570\n",
            "Train Epoch: 15 [300/590]\tloss: 0.789569\n",
            "Train Epoch: 15 [310/590]\tloss: 0.779270\n",
            "Train Epoch: 15 [320/590]\tloss: 0.817710\n",
            "Train Epoch: 15 [330/590]\tloss: 0.780840\n",
            "Train Epoch: 15 [340/590]\tloss: 0.786645\n",
            "Train Epoch: 15 [350/590]\tloss: 0.825021\n",
            "Train Epoch: 15 [360/590]\tloss: 0.783047\n",
            "Train Epoch: 15 [370/590]\tloss: 0.777722\n",
            "Train Epoch: 15 [380/590]\tloss: 0.783307\n",
            "Train Epoch: 15 [390/590]\tloss: 0.787119\n",
            "Train Epoch: 15 [400/590]\tloss: 0.783816\n",
            "Train Epoch: 15 [410/590]\tloss: 0.893228\n",
            "Train Epoch: 15 [420/590]\tloss: 0.782649\n",
            "Train Epoch: 15 [430/590]\tloss: 0.828858\n",
            "Train Epoch: 15 [440/590]\tloss: 0.778189\n",
            "Train Epoch: 15 [450/590]\tloss: 0.828954\n",
            "Train Epoch: 15 [460/590]\tloss: 0.802619\n",
            "Train Epoch: 15 [470/590]\tloss: 0.794031\n",
            "Train Epoch: 15 [480/590]\tloss: 0.778958\n",
            "Train Epoch: 15 [490/590]\tloss: 0.819548\n",
            "Train Epoch: 15 [500/590]\tloss: 0.791954\n",
            "Train Epoch: 15 [510/590]\tloss: 0.775717\n",
            "Train Epoch: 15 [520/590]\tloss: 0.900638\n",
            "Train Epoch: 15 [530/590]\tloss: 0.815067\n",
            "Train Epoch: 15 [540/590]\tloss: 0.798981\n",
            "Train Epoch: 15 [550/590]\tloss: 0.776284\n",
            "Train Epoch: 15 [560/590]\tloss: 0.786739\n",
            "Train Epoch: 15 [570/590]\tloss: 0.831125\n",
            "Train Epoch: 15 [580/590]\tloss: 0.790401\n",
            "[15]Validation Loss: 0.3406,Accuracy: 92.9054%\n",
            "Train Epoch: 16 [0/590]\tloss: 0.772149\n",
            "Train Epoch: 16 [10/590]\tloss: 0.795797\n",
            "Train Epoch: 16 [20/590]\tloss: 0.814645\n",
            "Train Epoch: 16 [30/590]\tloss: 0.776623\n",
            "Train Epoch: 16 [40/590]\tloss: 0.808292\n",
            "Train Epoch: 16 [50/590]\tloss: 0.989378\n",
            "Train Epoch: 16 [60/590]\tloss: 0.899863\n",
            "Train Epoch: 16 [70/590]\tloss: 0.858270\n",
            "Train Epoch: 16 [80/590]\tloss: 0.792539\n",
            "Train Epoch: 16 [90/590]\tloss: 0.783995\n",
            "Train Epoch: 16 [100/590]\tloss: 0.963680\n",
            "Train Epoch: 16 [110/590]\tloss: 0.793316\n",
            "Train Epoch: 16 [120/590]\tloss: 0.788515\n",
            "Train Epoch: 16 [130/590]\tloss: 0.779484\n",
            "Train Epoch: 16 [140/590]\tloss: 0.805843\n",
            "Train Epoch: 16 [150/590]\tloss: 0.821466\n",
            "Train Epoch: 16 [160/590]\tloss: 0.778156\n",
            "Train Epoch: 16 [170/590]\tloss: 0.861747\n",
            "Train Epoch: 16 [180/590]\tloss: 0.779770\n",
            "Train Epoch: 16 [190/590]\tloss: 0.792499\n",
            "Train Epoch: 16 [200/590]\tloss: 0.782348\n",
            "Train Epoch: 16 [210/590]\tloss: 0.788394\n",
            "Train Epoch: 16 [220/590]\tloss: 0.833288\n",
            "Train Epoch: 16 [230/590]\tloss: 0.778238\n",
            "Train Epoch: 16 [240/590]\tloss: 0.780875\n",
            "Train Epoch: 16 [250/590]\tloss: 0.782864\n",
            "Train Epoch: 16 [260/590]\tloss: 0.772658\n",
            "Train Epoch: 16 [270/590]\tloss: 0.782524\n",
            "Train Epoch: 16 [280/590]\tloss: 0.773413\n",
            "Train Epoch: 16 [290/590]\tloss: 0.788467\n",
            "Train Epoch: 16 [300/590]\tloss: 1.046003\n",
            "Train Epoch: 16 [310/590]\tloss: 0.780858\n",
            "Train Epoch: 16 [320/590]\tloss: 0.770894\n",
            "Train Epoch: 16 [330/590]\tloss: 0.815351\n",
            "Train Epoch: 16 [340/590]\tloss: 0.784414\n",
            "Train Epoch: 16 [350/590]\tloss: 0.825307\n",
            "Train Epoch: 16 [360/590]\tloss: 0.780683\n",
            "Train Epoch: 16 [370/590]\tloss: 0.792564\n",
            "Train Epoch: 16 [380/590]\tloss: 0.838094\n",
            "Train Epoch: 16 [390/590]\tloss: 0.782774\n",
            "Train Epoch: 16 [400/590]\tloss: 0.802563\n",
            "Train Epoch: 16 [410/590]\tloss: 0.919935\n",
            "Train Epoch: 16 [420/590]\tloss: 0.790625\n",
            "Train Epoch: 16 [430/590]\tloss: 0.780121\n",
            "Train Epoch: 16 [440/590]\tloss: 0.775455\n",
            "Train Epoch: 16 [450/590]\tloss: 0.778064\n",
            "Train Epoch: 16 [460/590]\tloss: 0.809421\n",
            "Train Epoch: 16 [470/590]\tloss: 0.789551\n",
            "Train Epoch: 16 [480/590]\tloss: 0.775062\n",
            "Train Epoch: 16 [490/590]\tloss: 0.776743\n",
            "Train Epoch: 16 [500/590]\tloss: 0.782674\n",
            "Train Epoch: 16 [510/590]\tloss: 0.816300\n",
            "Train Epoch: 16 [520/590]\tloss: 0.794065\n",
            "Train Epoch: 16 [530/590]\tloss: 0.790840\n",
            "Train Epoch: 16 [540/590]\tloss: 0.776772\n",
            "Train Epoch: 16 [550/590]\tloss: 0.813589\n",
            "Train Epoch: 16 [560/590]\tloss: 0.865421\n",
            "Train Epoch: 16 [570/590]\tloss: 0.962622\n",
            "Train Epoch: 16 [580/590]\tloss: 0.778893\n",
            "[16]Validation Loss: 0.3035,Accuracy: 93.5811%\n",
            "Train Epoch: 17 [0/590]\tloss: 0.785010\n",
            "Train Epoch: 17 [10/590]\tloss: 0.776851\n",
            "Train Epoch: 17 [20/590]\tloss: 0.815136\n",
            "Train Epoch: 17 [30/590]\tloss: 0.894373\n",
            "Train Epoch: 17 [40/590]\tloss: 0.791183\n",
            "Train Epoch: 17 [50/590]\tloss: 0.786358\n",
            "Train Epoch: 17 [60/590]\tloss: 0.776467\n",
            "Train Epoch: 17 [70/590]\tloss: 0.785510\n",
            "Train Epoch: 17 [80/590]\tloss: 0.797385\n",
            "Train Epoch: 17 [90/590]\tloss: 0.783128\n",
            "Train Epoch: 17 [100/590]\tloss: 0.778799\n",
            "Train Epoch: 17 [110/590]\tloss: 0.775289\n",
            "Train Epoch: 17 [120/590]\tloss: 0.774965\n",
            "Train Epoch: 17 [130/590]\tloss: 0.790618\n",
            "Train Epoch: 17 [140/590]\tloss: 0.773077\n",
            "Train Epoch: 17 [150/590]\tloss: 0.779111\n",
            "Train Epoch: 17 [160/590]\tloss: 0.818307\n",
            "Train Epoch: 17 [170/590]\tloss: 0.775931\n",
            "Train Epoch: 17 [180/590]\tloss: 0.898124\n",
            "Train Epoch: 17 [190/590]\tloss: 0.957734\n",
            "Train Epoch: 17 [200/590]\tloss: 0.801167\n",
            "Train Epoch: 17 [210/590]\tloss: 0.794183\n",
            "Train Epoch: 17 [220/590]\tloss: 0.781017\n",
            "Train Epoch: 17 [230/590]\tloss: 0.796267\n",
            "Train Epoch: 17 [240/590]\tloss: 0.792048\n",
            "Train Epoch: 17 [250/590]\tloss: 0.779034\n",
            "Train Epoch: 17 [260/590]\tloss: 0.784655\n",
            "Train Epoch: 17 [270/590]\tloss: 0.930031\n",
            "Train Epoch: 17 [280/590]\tloss: 0.796902\n",
            "Train Epoch: 17 [290/590]\tloss: 0.820115\n",
            "Train Epoch: 17 [300/590]\tloss: 0.779752\n",
            "Train Epoch: 17 [310/590]\tloss: 0.910935\n",
            "Train Epoch: 17 [320/590]\tloss: 0.798085\n",
            "Train Epoch: 17 [330/590]\tloss: 0.783938\n",
            "Train Epoch: 17 [340/590]\tloss: 0.783971\n",
            "Train Epoch: 17 [350/590]\tloss: 0.783684\n",
            "Train Epoch: 17 [360/590]\tloss: 0.780093\n",
            "Train Epoch: 17 [370/590]\tloss: 0.815313\n",
            "Train Epoch: 17 [380/590]\tloss: 0.792999\n",
            "Train Epoch: 17 [390/590]\tloss: 0.783900\n",
            "Train Epoch: 17 [400/590]\tloss: 0.813173\n",
            "Train Epoch: 17 [410/590]\tloss: 0.908556\n",
            "Train Epoch: 17 [420/590]\tloss: 0.782684\n",
            "Train Epoch: 17 [430/590]\tloss: 0.788859\n",
            "Train Epoch: 17 [440/590]\tloss: 0.831847\n",
            "Train Epoch: 17 [450/590]\tloss: 0.827339\n",
            "Train Epoch: 17 [460/590]\tloss: 0.786891\n",
            "Train Epoch: 17 [470/590]\tloss: 0.951760\n",
            "Train Epoch: 17 [480/590]\tloss: 0.864282\n",
            "Train Epoch: 17 [490/590]\tloss: 0.784506\n",
            "Train Epoch: 17 [500/590]\tloss: 0.779720\n",
            "Train Epoch: 17 [510/590]\tloss: 0.782197\n",
            "Train Epoch: 17 [520/590]\tloss: 0.854238\n",
            "Train Epoch: 17 [530/590]\tloss: 0.936836\n",
            "Train Epoch: 17 [540/590]\tloss: 0.794060\n",
            "Train Epoch: 17 [550/590]\tloss: 0.830232\n",
            "Train Epoch: 17 [560/590]\tloss: 0.817155\n",
            "Train Epoch: 17 [570/590]\tloss: 0.813860\n",
            "Train Epoch: 17 [580/590]\tloss: 0.780379\n",
            "[17]Validation Loss: 0.3820,Accuracy: 91.8919%\n",
            "Train Epoch: 18 [0/590]\tloss: 0.775063\n",
            "Train Epoch: 18 [10/590]\tloss: 0.779867\n",
            "Train Epoch: 18 [20/590]\tloss: 1.014369\n",
            "Train Epoch: 18 [30/590]\tloss: 0.777854\n",
            "Train Epoch: 18 [40/590]\tloss: 0.793249\n",
            "Train Epoch: 18 [50/590]\tloss: 0.815974\n",
            "Train Epoch: 18 [60/590]\tloss: 0.843223\n",
            "Train Epoch: 18 [70/590]\tloss: 1.250078\n",
            "Train Epoch: 18 [80/590]\tloss: 0.808824\n",
            "Train Epoch: 18 [90/590]\tloss: 0.771083\n",
            "Train Epoch: 18 [100/590]\tloss: 0.778388\n",
            "Train Epoch: 18 [110/590]\tloss: 0.780226\n",
            "Train Epoch: 18 [120/590]\tloss: 0.948870\n",
            "Train Epoch: 18 [130/590]\tloss: 0.825027\n",
            "Train Epoch: 18 [140/590]\tloss: 0.776082\n",
            "Train Epoch: 18 [150/590]\tloss: 0.818144\n",
            "Train Epoch: 18 [160/590]\tloss: 0.782310\n",
            "Train Epoch: 18 [170/590]\tloss: 0.776912\n",
            "Train Epoch: 18 [180/590]\tloss: 0.771764\n",
            "Train Epoch: 18 [190/590]\tloss: 0.807458\n",
            "Train Epoch: 18 [200/590]\tloss: 0.773054\n",
            "Train Epoch: 18 [210/590]\tloss: 0.778325\n",
            "Train Epoch: 18 [220/590]\tloss: 0.771359\n",
            "Train Epoch: 18 [230/590]\tloss: 0.788177\n",
            "Train Epoch: 18 [240/590]\tloss: 0.794902\n",
            "Train Epoch: 18 [250/590]\tloss: 0.788071\n",
            "Train Epoch: 18 [260/590]\tloss: 0.779528\n",
            "Train Epoch: 18 [270/590]\tloss: 0.780274\n",
            "Train Epoch: 18 [280/590]\tloss: 0.776876\n",
            "Train Epoch: 18 [290/590]\tloss: 0.824333\n",
            "Train Epoch: 18 [300/590]\tloss: 0.808231\n",
            "Train Epoch: 18 [310/590]\tloss: 0.837611\n",
            "Train Epoch: 18 [320/590]\tloss: 0.851160\n",
            "Train Epoch: 18 [330/590]\tloss: 0.802203\n",
            "Train Epoch: 18 [340/590]\tloss: 0.833469\n",
            "Train Epoch: 18 [350/590]\tloss: 0.786450\n",
            "Train Epoch: 18 [360/590]\tloss: 0.789443\n",
            "Train Epoch: 18 [370/590]\tloss: 1.017034\n",
            "Train Epoch: 18 [380/590]\tloss: 0.777202\n",
            "Train Epoch: 18 [390/590]\tloss: 0.783747\n",
            "Train Epoch: 18 [400/590]\tloss: 0.777934\n",
            "Train Epoch: 18 [410/590]\tloss: 0.849067\n",
            "Train Epoch: 18 [420/590]\tloss: 0.805444\n",
            "Train Epoch: 18 [430/590]\tloss: 1.299852\n",
            "Train Epoch: 18 [440/590]\tloss: 0.817346\n",
            "Train Epoch: 18 [450/590]\tloss: 0.792771\n",
            "Train Epoch: 18 [460/590]\tloss: 0.780905\n",
            "Train Epoch: 18 [470/590]\tloss: 0.816859\n",
            "Train Epoch: 18 [480/590]\tloss: 0.780683\n",
            "Train Epoch: 18 [490/590]\tloss: 0.964769\n",
            "Train Epoch: 18 [500/590]\tloss: 0.780969\n",
            "Train Epoch: 18 [510/590]\tloss: 0.792052\n",
            "Train Epoch: 18 [520/590]\tloss: 0.813119\n",
            "Train Epoch: 18 [530/590]\tloss: 0.932437\n",
            "Train Epoch: 18 [540/590]\tloss: 0.790433\n",
            "Train Epoch: 18 [550/590]\tloss: 0.791730\n",
            "Train Epoch: 18 [560/590]\tloss: 0.783730\n",
            "Train Epoch: 18 [570/590]\tloss: 0.777963\n",
            "Train Epoch: 18 [580/590]\tloss: 0.823935\n",
            "[18]Validation Loss: 0.2673,Accuracy: 94.5946%\n",
            "Train Epoch: 19 [0/590]\tloss: 0.799716\n",
            "Train Epoch: 19 [10/590]\tloss: 0.785051\n",
            "Train Epoch: 19 [20/590]\tloss: 0.921024\n",
            "Train Epoch: 19 [30/590]\tloss: 0.781368\n",
            "Train Epoch: 19 [40/590]\tloss: 0.835281\n",
            "Train Epoch: 19 [50/590]\tloss: 0.819380\n",
            "Train Epoch: 19 [60/590]\tloss: 0.791673\n",
            "Train Epoch: 19 [70/590]\tloss: 0.775706\n",
            "Train Epoch: 19 [80/590]\tloss: 0.778688\n",
            "Train Epoch: 19 [90/590]\tloss: 0.992314\n",
            "Train Epoch: 19 [100/590]\tloss: 0.770220\n",
            "Train Epoch: 19 [110/590]\tloss: 0.789744\n",
            "Train Epoch: 19 [120/590]\tloss: 0.782170\n",
            "Train Epoch: 19 [130/590]\tloss: 0.773827\n",
            "Train Epoch: 19 [140/590]\tloss: 0.782125\n",
            "Train Epoch: 19 [150/590]\tloss: 0.779507\n",
            "Train Epoch: 19 [160/590]\tloss: 0.779875\n",
            "Train Epoch: 19 [170/590]\tloss: 0.820288\n",
            "Train Epoch: 19 [180/590]\tloss: 0.804733\n",
            "Train Epoch: 19 [190/590]\tloss: 0.780124\n",
            "Train Epoch: 19 [200/590]\tloss: 0.775268\n",
            "Train Epoch: 19 [210/590]\tloss: 0.809234\n",
            "Train Epoch: 19 [220/590]\tloss: 0.888491\n",
            "Train Epoch: 19 [230/590]\tloss: 0.779379\n",
            "Train Epoch: 19 [240/590]\tloss: 0.773491\n",
            "Train Epoch: 19 [250/590]\tloss: 0.920358\n",
            "Train Epoch: 19 [260/590]\tloss: 0.776393\n",
            "Train Epoch: 19 [270/590]\tloss: 0.782725\n",
            "Train Epoch: 19 [280/590]\tloss: 0.778962\n",
            "Train Epoch: 19 [290/590]\tloss: 0.773585\n",
            "Train Epoch: 19 [300/590]\tloss: 0.914104\n",
            "Train Epoch: 19 [310/590]\tloss: 0.781975\n",
            "Train Epoch: 19 [320/590]\tloss: 0.782003\n",
            "Train Epoch: 19 [330/590]\tloss: 0.795524\n",
            "Train Epoch: 19 [340/590]\tloss: 0.790756\n",
            "Train Epoch: 19 [350/590]\tloss: 0.786974\n",
            "Train Epoch: 19 [360/590]\tloss: 0.795416\n",
            "Train Epoch: 19 [370/590]\tloss: 0.784254\n",
            "Train Epoch: 19 [380/590]\tloss: 0.784166\n",
            "Train Epoch: 19 [390/590]\tloss: 0.815140\n",
            "Train Epoch: 19 [400/590]\tloss: 0.800849\n",
            "Train Epoch: 19 [410/590]\tloss: 0.783169\n",
            "Train Epoch: 19 [420/590]\tloss: 0.790532\n",
            "Train Epoch: 19 [430/590]\tloss: 0.843594\n",
            "Train Epoch: 19 [440/590]\tloss: 0.779210\n",
            "Train Epoch: 19 [450/590]\tloss: 0.777619\n",
            "Train Epoch: 19 [460/590]\tloss: 0.776938\n",
            "Train Epoch: 19 [470/590]\tloss: 0.774717\n",
            "Train Epoch: 19 [480/590]\tloss: 0.797316\n",
            "Train Epoch: 19 [490/590]\tloss: 0.920845\n",
            "Train Epoch: 19 [500/590]\tloss: 0.842936\n",
            "Train Epoch: 19 [510/590]\tloss: 0.790320\n",
            "Train Epoch: 19 [520/590]\tloss: 0.810012\n",
            "Train Epoch: 19 [530/590]\tloss: 0.783282\n",
            "Train Epoch: 19 [540/590]\tloss: 1.124917\n",
            "Train Epoch: 19 [550/590]\tloss: 0.790880\n",
            "Train Epoch: 19 [560/590]\tloss: 0.789159\n",
            "Train Epoch: 19 [570/590]\tloss: 0.791735\n",
            "Train Epoch: 19 [580/590]\tloss: 0.792213\n",
            "[19]Validation Loss: 0.2962,Accuracy: 93.5811%\n",
            "Train Epoch: 20 [0/590]\tloss: 0.787207\n",
            "Train Epoch: 20 [10/590]\tloss: 0.775566\n",
            "Train Epoch: 20 [20/590]\tloss: 0.768030\n",
            "Train Epoch: 20 [30/590]\tloss: 0.786599\n",
            "Train Epoch: 20 [40/590]\tloss: 0.937848\n",
            "Train Epoch: 20 [50/590]\tloss: 0.789081\n",
            "Train Epoch: 20 [60/590]\tloss: 0.780373\n",
            "Train Epoch: 20 [70/590]\tloss: 0.792404\n",
            "Train Epoch: 20 [80/590]\tloss: 0.780807\n",
            "Train Epoch: 20 [90/590]\tloss: 0.783003\n",
            "Train Epoch: 20 [100/590]\tloss: 0.798379\n",
            "Train Epoch: 20 [110/590]\tloss: 0.777291\n",
            "Train Epoch: 20 [120/590]\tloss: 0.814957\n",
            "Train Epoch: 20 [130/590]\tloss: 0.813812\n",
            "Train Epoch: 20 [140/590]\tloss: 0.789631\n",
            "Train Epoch: 20 [150/590]\tloss: 0.785968\n",
            "Train Epoch: 20 [160/590]\tloss: 0.781358\n",
            "Train Epoch: 20 [170/590]\tloss: 0.791130\n",
            "Train Epoch: 20 [180/590]\tloss: 0.783767\n",
            "Train Epoch: 20 [190/590]\tloss: 0.785427\n",
            "Train Epoch: 20 [200/590]\tloss: 0.815017\n",
            "Train Epoch: 20 [210/590]\tloss: 0.791547\n",
            "Train Epoch: 20 [220/590]\tloss: 0.776884\n",
            "Train Epoch: 20 [230/590]\tloss: 0.796179\n",
            "Train Epoch: 20 [240/590]\tloss: 0.773978\n",
            "Train Epoch: 20 [250/590]\tloss: 0.789120\n",
            "Train Epoch: 20 [260/590]\tloss: 0.863654\n",
            "Train Epoch: 20 [270/590]\tloss: 0.777564\n",
            "Train Epoch: 20 [280/590]\tloss: 0.779752\n",
            "Train Epoch: 20 [290/590]\tloss: 0.781140\n",
            "Train Epoch: 20 [300/590]\tloss: 0.805495\n",
            "Train Epoch: 20 [310/590]\tloss: 0.778480\n",
            "Train Epoch: 20 [320/590]\tloss: 0.775325\n",
            "Train Epoch: 20 [330/590]\tloss: 0.776784\n",
            "Train Epoch: 20 [340/590]\tloss: 0.786385\n",
            "Train Epoch: 20 [350/590]\tloss: 0.806687\n",
            "Train Epoch: 20 [360/590]\tloss: 0.814170\n",
            "Train Epoch: 20 [370/590]\tloss: 0.771054\n",
            "Train Epoch: 20 [380/590]\tloss: 0.791566\n",
            "Train Epoch: 20 [390/590]\tloss: 0.851593\n",
            "Train Epoch: 20 [400/590]\tloss: 0.778404\n",
            "Train Epoch: 20 [410/590]\tloss: 0.775165\n",
            "Train Epoch: 20 [420/590]\tloss: 0.867757\n",
            "Train Epoch: 20 [430/590]\tloss: 0.786044\n",
            "Train Epoch: 20 [440/590]\tloss: 0.972366\n",
            "Train Epoch: 20 [450/590]\tloss: 0.768922\n",
            "Train Epoch: 20 [460/590]\tloss: 0.770112\n",
            "Train Epoch: 20 [470/590]\tloss: 0.775542\n",
            "Train Epoch: 20 [480/590]\tloss: 0.948295\n",
            "Train Epoch: 20 [490/590]\tloss: 0.783224\n",
            "Train Epoch: 20 [500/590]\tloss: 0.919746\n",
            "Train Epoch: 20 [510/590]\tloss: 0.776300\n",
            "Train Epoch: 20 [520/590]\tloss: 0.778778\n",
            "Train Epoch: 20 [530/590]\tloss: 0.782539\n",
            "Train Epoch: 20 [540/590]\tloss: 0.784498\n",
            "Train Epoch: 20 [550/590]\tloss: 0.786074\n",
            "Train Epoch: 20 [560/590]\tloss: 0.774386\n",
            "Train Epoch: 20 [570/590]\tloss: 0.784947\n",
            "Train Epoch: 20 [580/590]\tloss: 0.967128\n",
            "[20]Validation Loss: 0.3566,Accuracy: 93.9189%\n",
            "Train Epoch: 21 [0/590]\tloss: 0.803798\n",
            "Train Epoch: 21 [10/590]\tloss: 0.784104\n",
            "Train Epoch: 21 [20/590]\tloss: 0.782372\n",
            "Train Epoch: 21 [30/590]\tloss: 0.780735\n",
            "Train Epoch: 21 [40/590]\tloss: 0.775099\n",
            "Train Epoch: 21 [50/590]\tloss: 0.784090\n",
            "Train Epoch: 21 [60/590]\tloss: 0.772854\n",
            "Train Epoch: 21 [70/590]\tloss: 0.798193\n",
            "Train Epoch: 21 [80/590]\tloss: 0.772436\n",
            "Train Epoch: 21 [90/590]\tloss: 0.859831\n",
            "Train Epoch: 21 [100/590]\tloss: 0.785883\n",
            "Train Epoch: 21 [110/590]\tloss: 0.790213\n",
            "Train Epoch: 21 [120/590]\tloss: 0.832557\n",
            "Train Epoch: 21 [130/590]\tloss: 0.774734\n",
            "Train Epoch: 21 [140/590]\tloss: 0.779878\n",
            "Train Epoch: 21 [150/590]\tloss: 0.781449\n",
            "Train Epoch: 21 [160/590]\tloss: 0.773041\n",
            "Train Epoch: 21 [170/590]\tloss: 0.787289\n",
            "Train Epoch: 21 [180/590]\tloss: 0.772203\n",
            "Train Epoch: 21 [190/590]\tloss: 0.779171\n",
            "Train Epoch: 21 [200/590]\tloss: 0.779970\n",
            "Train Epoch: 21 [210/590]\tloss: 0.849614\n",
            "Train Epoch: 21 [220/590]\tloss: 0.788555\n",
            "Train Epoch: 21 [230/590]\tloss: 0.792919\n",
            "Train Epoch: 21 [240/590]\tloss: 0.784750\n",
            "Train Epoch: 21 [250/590]\tloss: 0.774081\n",
            "Train Epoch: 21 [260/590]\tloss: 0.828665\n",
            "Train Epoch: 21 [270/590]\tloss: 0.771793\n",
            "Train Epoch: 21 [280/590]\tloss: 0.790474\n",
            "Train Epoch: 21 [290/590]\tloss: 0.791098\n",
            "Train Epoch: 21 [300/590]\tloss: 0.775043\n",
            "Train Epoch: 21 [310/590]\tloss: 0.770018\n",
            "Train Epoch: 21 [320/590]\tloss: 0.782718\n",
            "Train Epoch: 21 [330/590]\tloss: 0.814215\n",
            "Train Epoch: 21 [340/590]\tloss: 0.778259\n",
            "Train Epoch: 21 [350/590]\tloss: 0.814927\n",
            "Train Epoch: 21 [360/590]\tloss: 0.772886\n",
            "Train Epoch: 21 [370/590]\tloss: 0.877341\n",
            "Train Epoch: 21 [380/590]\tloss: 0.801019\n",
            "Train Epoch: 21 [390/590]\tloss: 0.776579\n",
            "Train Epoch: 21 [400/590]\tloss: 1.075253\n",
            "Train Epoch: 21 [410/590]\tloss: 0.783406\n",
            "Train Epoch: 21 [420/590]\tloss: 0.824262\n",
            "Train Epoch: 21 [430/590]\tloss: 0.790141\n",
            "Train Epoch: 21 [440/590]\tloss: 0.780000\n",
            "Train Epoch: 21 [450/590]\tloss: 0.778371\n",
            "Train Epoch: 21 [460/590]\tloss: 0.783144\n",
            "Train Epoch: 21 [470/590]\tloss: 1.393824\n",
            "Train Epoch: 21 [480/590]\tloss: 0.783044\n",
            "Train Epoch: 21 [490/590]\tloss: 0.777492\n",
            "Train Epoch: 21 [500/590]\tloss: 0.778788\n",
            "Train Epoch: 21 [510/590]\tloss: 0.774714\n",
            "Train Epoch: 21 [520/590]\tloss: 0.817429\n",
            "Train Epoch: 21 [530/590]\tloss: 0.807697\n",
            "Train Epoch: 21 [540/590]\tloss: 0.782096\n",
            "Train Epoch: 21 [550/590]\tloss: 0.780984\n",
            "Train Epoch: 21 [560/590]\tloss: 0.791793\n",
            "Train Epoch: 21 [570/590]\tloss: 0.782845\n",
            "Train Epoch: 21 [580/590]\tloss: 0.805721\n",
            "[21]Validation Loss: 0.3106,Accuracy: 94.5946%\n",
            "Train Epoch: 22 [0/590]\tloss: 1.281968\n",
            "Train Epoch: 22 [10/590]\tloss: 0.778054\n",
            "Train Epoch: 22 [20/590]\tloss: 0.781676\n",
            "Train Epoch: 22 [30/590]\tloss: 0.789495\n",
            "Train Epoch: 22 [40/590]\tloss: 0.781122\n",
            "Train Epoch: 22 [50/590]\tloss: 0.784842\n",
            "Train Epoch: 22 [60/590]\tloss: 0.794275\n",
            "Train Epoch: 22 [70/590]\tloss: 0.783011\n",
            "Train Epoch: 22 [80/590]\tloss: 0.773719\n",
            "Train Epoch: 22 [90/590]\tloss: 0.809689\n",
            "Train Epoch: 22 [100/590]\tloss: 0.775509\n",
            "Train Epoch: 22 [110/590]\tloss: 0.775681\n",
            "Train Epoch: 22 [120/590]\tloss: 0.777830\n",
            "Train Epoch: 22 [130/590]\tloss: 0.780827\n",
            "Train Epoch: 22 [140/590]\tloss: 0.773163\n",
            "Train Epoch: 22 [150/590]\tloss: 0.778525\n",
            "Train Epoch: 22 [160/590]\tloss: 0.775627\n",
            "Train Epoch: 22 [170/590]\tloss: 0.791431\n",
            "Train Epoch: 22 [180/590]\tloss: 1.006222\n",
            "Train Epoch: 22 [190/590]\tloss: 0.798881\n",
            "Train Epoch: 22 [200/590]\tloss: 0.775115\n",
            "Train Epoch: 22 [210/590]\tloss: 0.782308\n",
            "Train Epoch: 22 [220/590]\tloss: 0.780283\n",
            "Train Epoch: 22 [230/590]\tloss: 0.788085\n",
            "Train Epoch: 22 [240/590]\tloss: 0.787858\n",
            "Train Epoch: 22 [250/590]\tloss: 0.807377\n",
            "Train Epoch: 22 [260/590]\tloss: 0.781201\n",
            "Train Epoch: 22 [270/590]\tloss: 0.772012\n",
            "Train Epoch: 22 [280/590]\tloss: 0.780665\n",
            "Train Epoch: 22 [290/590]\tloss: 0.859071\n",
            "Train Epoch: 22 [300/590]\tloss: 0.794183\n",
            "Train Epoch: 22 [310/590]\tloss: 0.786857\n",
            "Train Epoch: 22 [320/590]\tloss: 0.772186\n",
            "Train Epoch: 22 [330/590]\tloss: 0.776344\n",
            "Train Epoch: 22 [340/590]\tloss: 0.777790\n",
            "Train Epoch: 22 [350/590]\tloss: 0.778824\n",
            "Train Epoch: 22 [360/590]\tloss: 0.780918\n",
            "Train Epoch: 22 [370/590]\tloss: 0.773057\n",
            "Train Epoch: 22 [380/590]\tloss: 0.771806\n",
            "Train Epoch: 22 [390/590]\tloss: 0.957159\n",
            "Train Epoch: 22 [400/590]\tloss: 0.778671\n",
            "Train Epoch: 22 [410/590]\tloss: 0.775290\n",
            "Train Epoch: 22 [420/590]\tloss: 0.783686\n",
            "Train Epoch: 22 [430/590]\tloss: 0.777393\n",
            "Train Epoch: 22 [440/590]\tloss: 0.768457\n",
            "Train Epoch: 22 [450/590]\tloss: 0.797830\n",
            "Train Epoch: 22 [460/590]\tloss: 0.794072\n",
            "Train Epoch: 22 [470/590]\tloss: 0.773436\n",
            "Train Epoch: 22 [480/590]\tloss: 0.776515\n",
            "Train Epoch: 22 [490/590]\tloss: 0.775999\n",
            "Train Epoch: 22 [500/590]\tloss: 0.775754\n",
            "Train Epoch: 22 [510/590]\tloss: 0.779032\n",
            "Train Epoch: 22 [520/590]\tloss: 0.807515\n",
            "Train Epoch: 22 [530/590]\tloss: 0.797205\n",
            "Train Epoch: 22 [540/590]\tloss: 0.772451\n",
            "Train Epoch: 22 [550/590]\tloss: 0.783420\n",
            "Train Epoch: 22 [560/590]\tloss: 0.772984\n",
            "Train Epoch: 22 [570/590]\tloss: 0.780139\n",
            "Train Epoch: 22 [580/590]\tloss: 0.865982\n",
            "[22]Validation Loss: 0.3435,Accuracy: 91.8919%\n",
            "Train Epoch: 23 [0/590]\tloss: 0.853457\n",
            "Train Epoch: 23 [10/590]\tloss: 0.777766\n",
            "Train Epoch: 23 [20/590]\tloss: 0.784143\n",
            "Train Epoch: 23 [30/590]\tloss: 0.777026\n",
            "Train Epoch: 23 [40/590]\tloss: 0.783893\n",
            "Train Epoch: 23 [50/590]\tloss: 0.769933\n",
            "Train Epoch: 23 [60/590]\tloss: 0.779503\n",
            "Train Epoch: 23 [70/590]\tloss: 0.780538\n",
            "Train Epoch: 23 [80/590]\tloss: 0.810480\n",
            "Train Epoch: 23 [90/590]\tloss: 0.775316\n",
            "Train Epoch: 23 [100/590]\tloss: 0.770502\n",
            "Train Epoch: 23 [110/590]\tloss: 0.789309\n",
            "Train Epoch: 23 [120/590]\tloss: 0.770988\n",
            "Train Epoch: 23 [130/590]\tloss: 0.776858\n",
            "Train Epoch: 23 [140/590]\tloss: 1.263208\n",
            "Train Epoch: 23 [150/590]\tloss: 0.772839\n",
            "Train Epoch: 23 [160/590]\tloss: 0.772090\n",
            "Train Epoch: 23 [170/590]\tloss: 0.780371\n",
            "Train Epoch: 23 [180/590]\tloss: 0.924259\n",
            "Train Epoch: 23 [190/590]\tloss: 0.772830\n",
            "Train Epoch: 23 [200/590]\tloss: 0.784555\n",
            "Train Epoch: 23 [210/590]\tloss: 0.777779\n",
            "Train Epoch: 23 [220/590]\tloss: 0.837013\n",
            "Train Epoch: 23 [230/590]\tloss: 0.783481\n",
            "Train Epoch: 23 [240/590]\tloss: 0.780368\n",
            "Train Epoch: 23 [250/590]\tloss: 0.813937\n",
            "Train Epoch: 23 [260/590]\tloss: 0.793292\n",
            "Train Epoch: 23 [270/590]\tloss: 0.779630\n",
            "Train Epoch: 23 [280/590]\tloss: 0.809556\n",
            "Train Epoch: 23 [290/590]\tloss: 0.776050\n",
            "Train Epoch: 23 [300/590]\tloss: 0.784952\n",
            "Train Epoch: 23 [310/590]\tloss: 0.777462\n",
            "Train Epoch: 23 [320/590]\tloss: 0.786236\n",
            "Train Epoch: 23 [330/590]\tloss: 0.771555\n",
            "Train Epoch: 23 [340/590]\tloss: 0.775023\n",
            "Train Epoch: 23 [350/590]\tloss: 0.795484\n",
            "Train Epoch: 23 [360/590]\tloss: 0.771592\n",
            "Train Epoch: 23 [370/590]\tloss: 0.836149\n",
            "Train Epoch: 23 [380/590]\tloss: 0.804870\n",
            "Train Epoch: 23 [390/590]\tloss: 0.814269\n",
            "Train Epoch: 23 [400/590]\tloss: 0.775288\n",
            "Train Epoch: 23 [410/590]\tloss: 0.785064\n",
            "Train Epoch: 23 [420/590]\tloss: 0.778808\n",
            "Train Epoch: 23 [430/590]\tloss: 0.772625\n",
            "Train Epoch: 23 [440/590]\tloss: 0.924596\n",
            "Train Epoch: 23 [450/590]\tloss: 0.772347\n",
            "Train Epoch: 23 [460/590]\tloss: 0.814809\n",
            "Train Epoch: 23 [470/590]\tloss: 0.810770\n",
            "Train Epoch: 23 [480/590]\tloss: 0.775979\n",
            "Train Epoch: 23 [490/590]\tloss: 0.772060\n",
            "Train Epoch: 23 [500/590]\tloss: 0.772756\n",
            "Train Epoch: 23 [510/590]\tloss: 0.940441\n",
            "Train Epoch: 23 [520/590]\tloss: 0.810477\n",
            "Train Epoch: 23 [530/590]\tloss: 0.840214\n",
            "Train Epoch: 23 [540/590]\tloss: 0.805540\n",
            "Train Epoch: 23 [550/590]\tloss: 0.784302\n",
            "Train Epoch: 23 [560/590]\tloss: 0.775375\n",
            "Train Epoch: 23 [570/590]\tloss: 0.802512\n",
            "Train Epoch: 23 [580/590]\tloss: 0.780761\n",
            "[23]Validation Loss: 0.3593,Accuracy: 90.8784%\n",
            "Train Epoch: 24 [0/590]\tloss: 0.777047\n",
            "Train Epoch: 24 [10/590]\tloss: 0.781438\n",
            "Train Epoch: 24 [20/590]\tloss: 0.771905\n",
            "Train Epoch: 24 [30/590]\tloss: 0.773393\n",
            "Train Epoch: 24 [40/590]\tloss: 0.790279\n",
            "Train Epoch: 24 [50/590]\tloss: 0.776962\n",
            "Train Epoch: 24 [60/590]\tloss: 0.770662\n",
            "Train Epoch: 24 [70/590]\tloss: 1.022689\n",
            "Train Epoch: 24 [80/590]\tloss: 0.773053\n",
            "Train Epoch: 24 [90/590]\tloss: 0.783728\n",
            "Train Epoch: 24 [100/590]\tloss: 0.769607\n",
            "Train Epoch: 24 [110/590]\tloss: 0.865469\n",
            "Train Epoch: 24 [120/590]\tloss: 0.782589\n",
            "Train Epoch: 24 [130/590]\tloss: 0.775233\n",
            "Train Epoch: 24 [140/590]\tloss: 0.782568\n",
            "Train Epoch: 24 [150/590]\tloss: 0.785449\n",
            "Train Epoch: 24 [160/590]\tloss: 0.776486\n",
            "Train Epoch: 24 [170/590]\tloss: 0.781155\n",
            "Train Epoch: 24 [180/590]\tloss: 0.774662\n",
            "Train Epoch: 24 [190/590]\tloss: 0.774517\n",
            "Train Epoch: 24 [200/590]\tloss: 0.773120\n",
            "Train Epoch: 24 [210/590]\tloss: 0.772825\n",
            "Train Epoch: 24 [220/590]\tloss: 1.391950\n",
            "Train Epoch: 24 [230/590]\tloss: 0.772747\n",
            "Train Epoch: 24 [240/590]\tloss: 0.828088\n",
            "Train Epoch: 24 [250/590]\tloss: 0.835797\n",
            "Train Epoch: 24 [260/590]\tloss: 0.772836\n",
            "Train Epoch: 24 [270/590]\tloss: 0.776991\n",
            "Train Epoch: 24 [280/590]\tloss: 0.781549\n",
            "Train Epoch: 24 [290/590]\tloss: 0.785952\n",
            "Train Epoch: 24 [300/590]\tloss: 0.784385\n",
            "Train Epoch: 24 [310/590]\tloss: 0.781011\n",
            "Train Epoch: 24 [320/590]\tloss: 0.776854\n",
            "Train Epoch: 24 [330/590]\tloss: 0.778732\n",
            "Train Epoch: 24 [340/590]\tloss: 0.780219\n",
            "Train Epoch: 24 [350/590]\tloss: 0.791597\n",
            "Train Epoch: 24 [360/590]\tloss: 0.927942\n",
            "Train Epoch: 24 [370/590]\tloss: 0.775260\n",
            "Train Epoch: 24 [380/590]\tloss: 0.770473\n",
            "Train Epoch: 24 [390/590]\tloss: 0.830859\n",
            "Train Epoch: 24 [400/590]\tloss: 0.778930\n",
            "Train Epoch: 24 [410/590]\tloss: 0.796762\n",
            "Train Epoch: 24 [420/590]\tloss: 0.789487\n",
            "Train Epoch: 24 [430/590]\tloss: 0.798900\n",
            "Train Epoch: 24 [440/590]\tloss: 0.781050\n",
            "Train Epoch: 24 [450/590]\tloss: 0.781776\n",
            "Train Epoch: 24 [460/590]\tloss: 0.786739\n",
            "Train Epoch: 24 [470/590]\tloss: 0.787447\n",
            "Train Epoch: 24 [480/590]\tloss: 0.774440\n",
            "Train Epoch: 24 [490/590]\tloss: 0.773155\n",
            "Train Epoch: 24 [500/590]\tloss: 0.771686\n",
            "Train Epoch: 24 [510/590]\tloss: 0.777678\n",
            "Train Epoch: 24 [520/590]\tloss: 0.784715\n",
            "Train Epoch: 24 [530/590]\tloss: 0.773618\n",
            "Train Epoch: 24 [540/590]\tloss: 0.777444\n",
            "Train Epoch: 24 [550/590]\tloss: 0.775085\n",
            "Train Epoch: 24 [560/590]\tloss: 0.782370\n",
            "Train Epoch: 24 [570/590]\tloss: 0.773600\n",
            "Train Epoch: 24 [580/590]\tloss: 0.782809\n",
            "[24]Validation Loss: 0.3508,Accuracy: 92.5676%\n",
            "Train Epoch: 25 [0/590]\tloss: 0.785253\n",
            "Train Epoch: 25 [10/590]\tloss: 0.775309\n",
            "Train Epoch: 25 [20/590]\tloss: 0.884075\n",
            "Train Epoch: 25 [30/590]\tloss: 0.769522\n",
            "Train Epoch: 25 [40/590]\tloss: 0.840546\n",
            "Train Epoch: 25 [50/590]\tloss: 0.939679\n",
            "Train Epoch: 25 [60/590]\tloss: 0.775276\n",
            "Train Epoch: 25 [70/590]\tloss: 0.780619\n",
            "Train Epoch: 25 [80/590]\tloss: 0.779636\n",
            "Train Epoch: 25 [90/590]\tloss: 0.775236\n",
            "Train Epoch: 25 [100/590]\tloss: 0.776702\n",
            "Train Epoch: 25 [110/590]\tloss: 0.776016\n",
            "Train Epoch: 25 [120/590]\tloss: 0.797255\n",
            "Train Epoch: 25 [130/590]\tloss: 0.783106\n",
            "Train Epoch: 25 [140/590]\tloss: 0.778914\n",
            "Train Epoch: 25 [150/590]\tloss: 0.781021\n",
            "Train Epoch: 25 [160/590]\tloss: 0.808888\n",
            "Train Epoch: 25 [170/590]\tloss: 0.770238\n",
            "Train Epoch: 25 [180/590]\tloss: 0.777969\n",
            "Train Epoch: 25 [190/590]\tloss: 0.772014\n",
            "Train Epoch: 25 [200/590]\tloss: 0.774869\n",
            "Train Epoch: 25 [210/590]\tloss: 0.771529\n",
            "Train Epoch: 25 [220/590]\tloss: 0.778097\n",
            "Train Epoch: 25 [230/590]\tloss: 0.827606\n",
            "Train Epoch: 25 [240/590]\tloss: 0.775645\n",
            "Train Epoch: 25 [250/590]\tloss: 0.785284\n",
            "Train Epoch: 25 [260/590]\tloss: 0.772978\n",
            "Train Epoch: 25 [270/590]\tloss: 0.772902\n",
            "Train Epoch: 25 [280/590]\tloss: 0.777022\n",
            "Train Epoch: 25 [290/590]\tloss: 0.779183\n",
            "Train Epoch: 25 [300/590]\tloss: 0.791298\n",
            "Train Epoch: 25 [310/590]\tloss: 0.777836\n",
            "Train Epoch: 25 [320/590]\tloss: 1.055283\n",
            "Train Epoch: 25 [330/590]\tloss: 0.773742\n",
            "Train Epoch: 25 [340/590]\tloss: 0.880014\n",
            "Train Epoch: 25 [350/590]\tloss: 0.778768\n",
            "Train Epoch: 25 [360/590]\tloss: 0.821560\n",
            "Train Epoch: 25 [370/590]\tloss: 0.784172\n",
            "Train Epoch: 25 [380/590]\tloss: 0.771444\n",
            "Train Epoch: 25 [390/590]\tloss: 0.865790\n",
            "Train Epoch: 25 [400/590]\tloss: 0.775361\n",
            "Train Epoch: 25 [410/590]\tloss: 0.776127\n",
            "Train Epoch: 25 [420/590]\tloss: 0.771355\n",
            "Train Epoch: 25 [430/590]\tloss: 0.856736\n",
            "Train Epoch: 25 [440/590]\tloss: 1.179064\n",
            "Train Epoch: 25 [450/590]\tloss: 0.777506\n",
            "Train Epoch: 25 [460/590]\tloss: 0.887878\n",
            "Train Epoch: 25 [470/590]\tloss: 0.781531\n",
            "Train Epoch: 25 [480/590]\tloss: 0.820270\n",
            "Train Epoch: 25 [490/590]\tloss: 0.777406\n",
            "Train Epoch: 25 [500/590]\tloss: 0.775304\n",
            "Train Epoch: 25 [510/590]\tloss: 0.775604\n",
            "Train Epoch: 25 [520/590]\tloss: 0.888002\n",
            "Train Epoch: 25 [530/590]\tloss: 0.778178\n",
            "Train Epoch: 25 [540/590]\tloss: 0.778457\n",
            "Train Epoch: 25 [550/590]\tloss: 0.776643\n",
            "Train Epoch: 25 [560/590]\tloss: 1.106414\n",
            "Train Epoch: 25 [570/590]\tloss: 0.802544\n",
            "Train Epoch: 25 [580/590]\tloss: 1.027789\n",
            "[25]Validation Loss: 0.2609,Accuracy: 95.6081%\n",
            "Train Epoch: 26 [0/590]\tloss: 0.786964\n",
            "Train Epoch: 26 [10/590]\tloss: 0.774178\n",
            "Train Epoch: 26 [20/590]\tloss: 0.781671\n",
            "Train Epoch: 26 [30/590]\tloss: 0.896692\n",
            "Train Epoch: 26 [40/590]\tloss: 0.804564\n",
            "Train Epoch: 26 [50/590]\tloss: 0.774978\n",
            "Train Epoch: 26 [60/590]\tloss: 0.781141\n",
            "Train Epoch: 26 [70/590]\tloss: 0.780364\n",
            "Train Epoch: 26 [80/590]\tloss: 0.779682\n",
            "Train Epoch: 26 [90/590]\tloss: 0.839526\n",
            "Train Epoch: 26 [100/590]\tloss: 0.778751\n",
            "Train Epoch: 26 [110/590]\tloss: 0.774029\n",
            "Train Epoch: 26 [120/590]\tloss: 0.792184\n",
            "Train Epoch: 26 [130/590]\tloss: 0.796976\n",
            "Train Epoch: 26 [140/590]\tloss: 0.780420\n",
            "Train Epoch: 26 [150/590]\tloss: 0.839656\n",
            "Train Epoch: 26 [160/590]\tloss: 0.788672\n",
            "Train Epoch: 26 [170/590]\tloss: 0.775831\n",
            "Train Epoch: 26 [180/590]\tloss: 0.785581\n",
            "Train Epoch: 26 [190/590]\tloss: 0.782021\n",
            "Train Epoch: 26 [200/590]\tloss: 0.771662\n",
            "Train Epoch: 26 [210/590]\tloss: 0.780106\n",
            "Train Epoch: 26 [220/590]\tloss: 0.783567\n",
            "Train Epoch: 26 [230/590]\tloss: 1.296412\n",
            "Train Epoch: 26 [240/590]\tloss: 0.783589\n",
            "Train Epoch: 26 [250/590]\tloss: 0.809595\n",
            "Train Epoch: 26 [260/590]\tloss: 0.779466\n",
            "Train Epoch: 26 [270/590]\tloss: 0.777284\n",
            "Train Epoch: 26 [280/590]\tloss: 0.926142\n",
            "Train Epoch: 26 [290/590]\tloss: 0.789646\n",
            "Train Epoch: 26 [300/590]\tloss: 0.782182\n",
            "Train Epoch: 26 [310/590]\tloss: 0.780897\n",
            "Train Epoch: 26 [320/590]\tloss: 0.775239\n",
            "Train Epoch: 26 [330/590]\tloss: 0.782331\n",
            "Train Epoch: 26 [340/590]\tloss: 0.779062\n",
            "Train Epoch: 26 [350/590]\tloss: 0.779817\n",
            "Train Epoch: 26 [360/590]\tloss: 0.795754\n",
            "Train Epoch: 26 [370/590]\tloss: 0.776885\n",
            "Train Epoch: 26 [380/590]\tloss: 0.778365\n",
            "Train Epoch: 26 [390/590]\tloss: 0.777465\n",
            "Train Epoch: 26 [400/590]\tloss: 0.780820\n",
            "Train Epoch: 26 [410/590]\tloss: 0.778114\n",
            "Train Epoch: 26 [420/590]\tloss: 0.774402\n",
            "Train Epoch: 26 [430/590]\tloss: 0.771726\n",
            "Train Epoch: 26 [440/590]\tloss: 0.769281\n",
            "Train Epoch: 26 [450/590]\tloss: 1.217484\n",
            "Train Epoch: 26 [460/590]\tloss: 0.874543\n",
            "Train Epoch: 26 [470/590]\tloss: 0.774741\n",
            "Train Epoch: 26 [480/590]\tloss: 0.803111\n",
            "Train Epoch: 26 [490/590]\tloss: 0.781684\n",
            "Train Epoch: 26 [500/590]\tloss: 0.820114\n",
            "Train Epoch: 26 [510/590]\tloss: 0.777302\n",
            "Train Epoch: 26 [520/590]\tloss: 0.782735\n",
            "Train Epoch: 26 [530/590]\tloss: 0.774906\n",
            "Train Epoch: 26 [540/590]\tloss: 0.781929\n",
            "Train Epoch: 26 [550/590]\tloss: 0.775457\n",
            "Train Epoch: 26 [560/590]\tloss: 0.830804\n",
            "Train Epoch: 26 [570/590]\tloss: 0.772612\n",
            "Train Epoch: 26 [580/590]\tloss: 0.778600\n",
            "[26]Validation Loss: 0.2739,Accuracy: 94.5946%\n",
            "Train Epoch: 27 [0/590]\tloss: 0.777195\n",
            "Train Epoch: 27 [10/590]\tloss: 0.789703\n",
            "Train Epoch: 27 [20/590]\tloss: 0.803018\n",
            "Train Epoch: 27 [30/590]\tloss: 0.772879\n",
            "Train Epoch: 27 [40/590]\tloss: 0.786789\n",
            "Train Epoch: 27 [50/590]\tloss: 0.777830\n",
            "Train Epoch: 27 [60/590]\tloss: 0.853396\n",
            "Train Epoch: 27 [70/590]\tloss: 0.778973\n",
            "Train Epoch: 27 [80/590]\tloss: 0.774547\n",
            "Train Epoch: 27 [90/590]\tloss: 0.772698\n",
            "Train Epoch: 27 [100/590]\tloss: 0.778805\n",
            "Train Epoch: 27 [110/590]\tloss: 0.893273\n",
            "Train Epoch: 27 [120/590]\tloss: 0.804795\n",
            "Train Epoch: 27 [130/590]\tloss: 0.783735\n",
            "Train Epoch: 27 [140/590]\tloss: 0.776599\n",
            "Train Epoch: 27 [150/590]\tloss: 0.770274\n",
            "Train Epoch: 27 [160/590]\tloss: 0.821302\n",
            "Train Epoch: 27 [170/590]\tloss: 0.774143\n",
            "Train Epoch: 27 [180/590]\tloss: 0.799670\n",
            "Train Epoch: 27 [190/590]\tloss: 0.799832\n",
            "Train Epoch: 27 [200/590]\tloss: 0.772996\n",
            "Train Epoch: 27 [210/590]\tloss: 0.782843\n",
            "Train Epoch: 27 [220/590]\tloss: 0.772393\n",
            "Train Epoch: 27 [230/590]\tloss: 0.770128\n",
            "Train Epoch: 27 [240/590]\tloss: 0.776605\n",
            "Train Epoch: 27 [250/590]\tloss: 0.774405\n",
            "Train Epoch: 27 [260/590]\tloss: 0.774535\n",
            "Train Epoch: 27 [270/590]\tloss: 0.776726\n",
            "Train Epoch: 27 [280/590]\tloss: 0.826500\n",
            "Train Epoch: 27 [290/590]\tloss: 0.784229\n",
            "Train Epoch: 27 [300/590]\tloss: 0.841159\n",
            "Train Epoch: 27 [310/590]\tloss: 0.777263\n",
            "Train Epoch: 27 [320/590]\tloss: 0.778727\n",
            "Train Epoch: 27 [330/590]\tloss: 0.772143\n",
            "Train Epoch: 27 [340/590]\tloss: 0.769498\n",
            "Train Epoch: 27 [350/590]\tloss: 0.777605\n",
            "Train Epoch: 27 [360/590]\tloss: 0.785927\n",
            "Train Epoch: 27 [370/590]\tloss: 0.780358\n",
            "Train Epoch: 27 [380/590]\tloss: 0.770881\n",
            "Train Epoch: 27 [390/590]\tloss: 0.781311\n",
            "Train Epoch: 27 [400/590]\tloss: 0.778604\n",
            "Train Epoch: 27 [410/590]\tloss: 0.770378\n",
            "Train Epoch: 27 [420/590]\tloss: 0.779951\n",
            "Train Epoch: 27 [430/590]\tloss: 0.790878\n",
            "Train Epoch: 27 [440/590]\tloss: 0.860717\n",
            "Train Epoch: 27 [450/590]\tloss: 0.775597\n",
            "Train Epoch: 27 [460/590]\tloss: 0.773878\n",
            "Train Epoch: 27 [470/590]\tloss: 0.796954\n",
            "Train Epoch: 27 [480/590]\tloss: 0.786111\n",
            "Train Epoch: 27 [490/590]\tloss: 0.780314\n",
            "Train Epoch: 27 [500/590]\tloss: 0.788747\n",
            "Train Epoch: 27 [510/590]\tloss: 0.897585\n",
            "Train Epoch: 27 [520/590]\tloss: 0.772285\n",
            "Train Epoch: 27 [530/590]\tloss: 0.778418\n",
            "Train Epoch: 27 [540/590]\tloss: 0.781021\n",
            "Train Epoch: 27 [550/590]\tloss: 0.815028\n",
            "Train Epoch: 27 [560/590]\tloss: 0.772611\n",
            "Train Epoch: 27 [570/590]\tloss: 0.804802\n",
            "Train Epoch: 27 [580/590]\tloss: 0.772040\n",
            "[27]Validation Loss: 0.3103,Accuracy: 94.5946%\n",
            "Train Epoch: 28 [0/590]\tloss: 0.820253\n",
            "Train Epoch: 28 [10/590]\tloss: 0.844486\n",
            "Train Epoch: 28 [20/590]\tloss: 0.776615\n",
            "Train Epoch: 28 [30/590]\tloss: 0.778336\n",
            "Train Epoch: 28 [40/590]\tloss: 0.792524\n",
            "Train Epoch: 28 [50/590]\tloss: 0.778663\n",
            "Train Epoch: 28 [60/590]\tloss: 0.774068\n",
            "Train Epoch: 28 [70/590]\tloss: 0.954113\n",
            "Train Epoch: 28 [80/590]\tloss: 0.780916\n",
            "Train Epoch: 28 [90/590]\tloss: 0.827339\n",
            "Train Epoch: 28 [100/590]\tloss: 0.780437\n",
            "Train Epoch: 28 [110/590]\tloss: 0.773667\n",
            "Train Epoch: 28 [120/590]\tloss: 0.797746\n",
            "Train Epoch: 28 [130/590]\tloss: 0.792465\n",
            "Train Epoch: 28 [140/590]\tloss: 0.775526\n",
            "Train Epoch: 28 [150/590]\tloss: 0.773624\n",
            "Train Epoch: 28 [160/590]\tloss: 0.773975\n",
            "Train Epoch: 28 [170/590]\tloss: 0.792764\n",
            "Train Epoch: 28 [180/590]\tloss: 0.797287\n",
            "Train Epoch: 28 [190/590]\tloss: 0.841476\n",
            "Train Epoch: 28 [200/590]\tloss: 0.784032\n",
            "Train Epoch: 28 [210/590]\tloss: 0.769372\n",
            "Train Epoch: 28 [220/590]\tloss: 0.775758\n",
            "Train Epoch: 28 [230/590]\tloss: 0.771705\n",
            "Train Epoch: 28 [240/590]\tloss: 0.783429\n",
            "Train Epoch: 28 [250/590]\tloss: 0.773378\n",
            "Train Epoch: 28 [260/590]\tloss: 1.206891\n",
            "Train Epoch: 28 [270/590]\tloss: 0.810864\n",
            "Train Epoch: 28 [280/590]\tloss: 0.825496\n",
            "Train Epoch: 28 [290/590]\tloss: 0.777113\n",
            "Train Epoch: 28 [300/590]\tloss: 0.770446\n",
            "Train Epoch: 28 [310/590]\tloss: 0.779249\n",
            "Train Epoch: 28 [320/590]\tloss: 0.769394\n",
            "Train Epoch: 28 [330/590]\tloss: 0.777840\n",
            "Train Epoch: 28 [340/590]\tloss: 0.772400\n",
            "Train Epoch: 28 [350/590]\tloss: 0.791720\n",
            "Train Epoch: 28 [360/590]\tloss: 0.779405\n",
            "Train Epoch: 28 [370/590]\tloss: 0.776262\n",
            "Train Epoch: 28 [380/590]\tloss: 0.793221\n",
            "Train Epoch: 28 [390/590]\tloss: 0.808819\n",
            "Train Epoch: 28 [400/590]\tloss: 0.791372\n",
            "Train Epoch: 28 [410/590]\tloss: 0.775022\n",
            "Train Epoch: 28 [420/590]\tloss: 0.784590\n",
            "Train Epoch: 28 [430/590]\tloss: 0.775554\n",
            "Train Epoch: 28 [440/590]\tloss: 0.813787\n",
            "Train Epoch: 28 [450/590]\tloss: 0.778346\n",
            "Train Epoch: 28 [460/590]\tloss: 0.819701\n",
            "Train Epoch: 28 [470/590]\tloss: 0.780831\n",
            "Train Epoch: 28 [480/590]\tloss: 0.771129\n",
            "Train Epoch: 28 [490/590]\tloss: 0.779170\n",
            "Train Epoch: 28 [500/590]\tloss: 0.778615\n",
            "Train Epoch: 28 [510/590]\tloss: 0.771582\n",
            "Train Epoch: 28 [520/590]\tloss: 0.804239\n",
            "Train Epoch: 28 [530/590]\tloss: 0.777572\n",
            "Train Epoch: 28 [540/590]\tloss: 0.786689\n",
            "Train Epoch: 28 [550/590]\tloss: 0.782478\n",
            "Train Epoch: 28 [560/590]\tloss: 0.988209\n",
            "Train Epoch: 28 [570/590]\tloss: 0.791321\n",
            "Train Epoch: 28 [580/590]\tloss: 0.789904\n",
            "[28]Validation Loss: 0.3695,Accuracy: 91.5541%\n",
            "Train Epoch: 29 [0/590]\tloss: 0.833660\n",
            "Train Epoch: 29 [10/590]\tloss: 0.778479\n",
            "Train Epoch: 29 [20/590]\tloss: 0.781826\n",
            "Train Epoch: 29 [30/590]\tloss: 0.783137\n",
            "Train Epoch: 29 [40/590]\tloss: 0.780486\n",
            "Train Epoch: 29 [50/590]\tloss: 0.770798\n",
            "Train Epoch: 29 [60/590]\tloss: 0.799130\n",
            "Train Epoch: 29 [70/590]\tloss: 0.776994\n",
            "Train Epoch: 29 [80/590]\tloss: 0.831682\n",
            "Train Epoch: 29 [90/590]\tloss: 0.875712\n",
            "Train Epoch: 29 [100/590]\tloss: 0.798920\n",
            "Train Epoch: 29 [110/590]\tloss: 0.795041\n",
            "Train Epoch: 29 [120/590]\tloss: 0.802556\n",
            "Train Epoch: 29 [130/590]\tloss: 0.774159\n",
            "Train Epoch: 29 [140/590]\tloss: 0.868145\n",
            "Train Epoch: 29 [150/590]\tloss: 0.779249\n",
            "Train Epoch: 29 [160/590]\tloss: 0.773929\n",
            "Train Epoch: 29 [170/590]\tloss: 0.789332\n",
            "Train Epoch: 29 [180/590]\tloss: 0.821283\n",
            "Train Epoch: 29 [190/590]\tloss: 0.769121\n",
            "Train Epoch: 29 [200/590]\tloss: 0.780465\n",
            "Train Epoch: 29 [210/590]\tloss: 0.781265\n",
            "Train Epoch: 29 [220/590]\tloss: 0.780842\n",
            "Train Epoch: 29 [230/590]\tloss: 0.806180\n",
            "Train Epoch: 29 [240/590]\tloss: 0.786435\n",
            "Train Epoch: 29 [250/590]\tloss: 0.774268\n",
            "Train Epoch: 29 [260/590]\tloss: 0.770727\n",
            "Train Epoch: 29 [270/590]\tloss: 0.774495\n",
            "Train Epoch: 29 [280/590]\tloss: 0.780796\n",
            "Train Epoch: 29 [290/590]\tloss: 0.778119\n",
            "Train Epoch: 29 [300/590]\tloss: 0.797067\n",
            "Train Epoch: 29 [310/590]\tloss: 0.844378\n",
            "Train Epoch: 29 [320/590]\tloss: 0.776816\n",
            "Train Epoch: 29 [330/590]\tloss: 0.783868\n",
            "Train Epoch: 29 [340/590]\tloss: 0.775529\n",
            "Train Epoch: 29 [350/590]\tloss: 0.770455\n",
            "Train Epoch: 29 [360/590]\tloss: 0.776750\n",
            "Train Epoch: 29 [370/590]\tloss: 0.874956\n",
            "Train Epoch: 29 [380/590]\tloss: 0.806757\n",
            "Train Epoch: 29 [390/590]\tloss: 0.789174\n",
            "Train Epoch: 29 [400/590]\tloss: 0.774318\n",
            "Train Epoch: 29 [410/590]\tloss: 0.771647\n",
            "Train Epoch: 29 [420/590]\tloss: 0.778856\n",
            "Train Epoch: 29 [430/590]\tloss: 0.772576\n",
            "Train Epoch: 29 [440/590]\tloss: 0.791373\n",
            "Train Epoch: 29 [450/590]\tloss: 0.786268\n",
            "Train Epoch: 29 [460/590]\tloss: 0.776961\n",
            "Train Epoch: 29 [470/590]\tloss: 0.777591\n",
            "Train Epoch: 29 [480/590]\tloss: 0.788820\n",
            "Train Epoch: 29 [490/590]\tloss: 0.774116\n",
            "Train Epoch: 29 [500/590]\tloss: 0.771240\n",
            "Train Epoch: 29 [510/590]\tloss: 0.774916\n",
            "Train Epoch: 29 [520/590]\tloss: 0.800762\n",
            "Train Epoch: 29 [530/590]\tloss: 0.773623\n",
            "Train Epoch: 29 [540/590]\tloss: 0.774752\n",
            "Train Epoch: 29 [550/590]\tloss: 0.783783\n",
            "Train Epoch: 29 [560/590]\tloss: 0.991383\n",
            "Train Epoch: 29 [570/590]\tloss: 0.976937\n",
            "Train Epoch: 29 [580/590]\tloss: 0.776816\n",
            "[29]Validation Loss: 0.3766,Accuracy: 93.9189%\n",
            "[FINAL] Test Loss: 0.3477,Accuracy: 92.6174%\n",
            "Best Accuracy:  95.60810810810811\n",
            "Elasped Time: 3h, 181m, 31s\n",
            "time: 3h, 181m, 31s\n"
          ]
        }
      ],
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "train_losses = []  # 훈련 손실을 저장할 목록\n",
        "val_losses = []    # 검증 손실을 저장할 목록\n",
        "val_accuracys = []\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "  train_loss = train(model,train_loader,optimizer,epoch)\n",
        "  val_loss,val_accuracy = evaluate(model,val_loader)\n",
        "\n",
        "# 훈련 및 검증 손실을 목록에 추가\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  # Save best model\n",
        "  if val_accuracy > best:\n",
        "    best = val_accuracy\n",
        "    torch.save(model.state_dict(),\"./best_model.pth\")\n",
        "\n",
        "  val_accuracys.append(val_accuracy)\n",
        "  print(f\"[{epoch}]Validation Loss: {val_loss:.4f},Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "# Test result\n",
        "test_loss,test_accuracy = evaluate(model,test_loader)\n",
        "print(f'[FINAL] Test Loss: {test_loss:.4f},Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "end = time.time()\n",
        "elasped_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \",best)\n",
        "print(\n",
        "    f\"Elasped Time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")\n",
        "print(\n",
        "    f\"time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPbth0JdWdCj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7b29b86-c99e-4d9f-b4ff-7417930fe7e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 이제 손실 값을 플로팅합니다.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# train_loss와 val_loss 텐서를 CPU로 이동하고 NumPy 배열로 변환\n",
        "train_losses = [loss.cpu().detach().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_losses]\n",
        "val_losses = [loss.cpu().detach().numpy() if isinstance(loss, torch.Tensor) else loss for loss in val_losses]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, EPOCH + 1), train_losses, label='train_loss', marker='o')\n",
        "plt.plot(range(1, EPOCH + 1), val_losses, label='val_loss', marker='o')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "val_accuracys = [acc.cpu().detach().numpy() if isinstance(acc, torch.Tensor) else acc for acc in val_accuracys]\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, EPOCH + 1), val_accuracys, label='val_accuracy', marker='o')\n",
        "plt.title('Validation Accuracy Over Epochs')\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}