{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yerimming/gachon/blob/main/CV_AL2_EfficientNet(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBelief optimizer 사용"
      ],
      "metadata": {
        "id": "5IWv29cr4xxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTzysnz787ox",
        "outputId": "a305895c-b167-4a15-b31f-c89add709c55"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ByrrPmg87uL",
        "outputId": "e84b7432-29b3-4559-8932-1c0b40f83da0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=fa3338f2ddc27c50663286fec2db6aa3edf497899549b634f72799782bf3dd4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adabelief-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyyqXOo29o6P",
        "outputId": "0ddb5543-3f0e-4be5-924e-1fa88f8e160b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adabelief-pytorch\n",
            "  Downloading adabelief_pytorch-0.2.1-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from adabelief-pytorch) (2.1.0+cu118)\n",
            "Collecting colorama>=0.4.0 (from adabelief-pytorch)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.10/dist-packages (from adabelief-pytorch) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->adabelief-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->adabelief-pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->adabelief-pytorch) (1.3.0)\n",
            "Installing collected packages: colorama, adabelief-pytorch\n",
            "Successfully installed adabelief-pytorch-0.2.1 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOc0tT3-nv73",
        "outputId": "790dadab-ea54-4869-b4ce-d20304d7fef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image,ImageEnhance\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "from torch.utils.data import ConcatDataset\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from adabelief_pytorch import AdaBelief\n",
        "\n",
        "import re\n",
        "\n",
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KaFgjkFp8tzI"
      },
      "outputs": [],
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "  def __init__(self, transform, mode='train'):\n",
        "    self.transform = transform\n",
        "    self.mode = mode\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/train')\n",
        "    elif self.mode == 'valid':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/valid')\n",
        "    elif self.mode == 'test':\n",
        "      self.image_folder = os.listdir('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets/test')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_folder)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_folder[idx]\n",
        "    img = Image.open(os.path.join('/content/gdrive/MyDrive/CUB_200_2011_repackage_class50/datasets', self.mode, img_path)).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    label = img_path.split('_')[-1].split('.')[0]\n",
        "    label = re.sub(r'\\([^)]*\\)', '', label)\n",
        "    label = int(label)\n",
        "    return (img, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cQGrjNlsWdCh"
      },
      "outputs": [],
      "source": [
        "# Geomentric transform + Visual corruptions\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0, std=1, p=0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() < self.p:\n",
        "            img_array = np.array(img)\n",
        "            noise = np.random.normal(self.mean, self.std, img_array.shape)\n",
        "            noisy_image = np.clip(img_array + noise, 0, 255)  # Clip values to the range [0, 255]\n",
        "            return Image.fromarray(noisy_image.astype(np.uint8))\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std}, p={self.p})'\n",
        "\n",
        "\n",
        "class AdjustContrast(object):\n",
        "    def __init__(self, factor=1.0):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, img):\n",
        "        enhancer = ImageEnhance.Contrast(img)\n",
        "        img = enhancer.enhance(self.factor)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(factor={self.factor})'\n",
        "\n",
        "class AdjustBrightness(object):\n",
        "    def __init__(self, factor=1.0):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, img):\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "        img = enhancer.enhance(self.factor)\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(factor={self.factor})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38vx5jj22neg",
        "outputId": "f3d7b7c3-4ae2-45fc-c5ee-983b9345cc11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset:  4720 296 298\n",
            "Loaded dataloader\n"
          ]
        }
      ],
      "source": [
        "### Data Preprocessing & Data Augmentation ###\n",
        "transforms_train_origin = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    transforms.ToTensor(),])\n",
        "\n",
        "transforms_test = transforms.Compose([\n",
        "    transforms.Resize((448,448)),\n",
        "    transforms.ToTensor(),])\n",
        "\n",
        "# Geomentric transform + Visual corruptions\n",
        "transforms_train_g_v = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    #transforms.RandomResizedCrop(448),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    AddGaussianNoise(mean=0, std=25, p=0.5),  # 가우시안 노이즈를 추가합니다.\n",
        "    AdjustContrast(factor=2.0),  # 대비를 조절합니다.\n",
        "    AdjustBrightness(factor=1.5),  # 밝기를 조절합니다.\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_set_origin = CUB2011(mode='train',\n",
        "                    transform=transforms_train_origin)\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_test)\n",
        "test_set = CUB2011(mode='test',\n",
        "                  transform=transforms_test)\n",
        "\n",
        "train_set_augmented2 = CUB2011(mode='train',transform=transforms_train_g_v) # 2)\n",
        "\n",
        "train_loader = DataLoader(train_set_origin,batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "# 다 합친거\n",
        "train_set_combined = ConcatDataset([train_set_origin,train_set_augmented2])\n",
        "\n",
        "print('Num of each dataset: ',len(train_set_combined),len(val_set),len(test_set))\n",
        "\n",
        "# Dataloader class는 bath기반의 딥러닝모델 학습을 위해서 mini batch를 만들어주는 역할을 한다\n",
        "# dataloader를 통해 dataset의 전체 데이터가 batch size로 나뉘게 된다\n",
        "train_loader = DataLoader(train_set_combined, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "test_loader = DataLoader(test_set,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apDhVk6C2r7R",
        "outputId": "d579dc53-772b-43d6-c515-429a155842a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100%|██████████| 20.4M/20.4M [00:00<00:00, 196MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n",
            "\u001b[31mModifications to default arguments:\n",
            "\u001b[31m                           eps  weight_decouple    rectify\n",
            "-----------------------  -----  -----------------  ---------\n",
            "adabelief-pytorch=0.0.5  1e-08  False              False\n",
            ">=0.1.0 (Current 0.2.0)  1e-16  True               True\n",
            "\u001b[34mSGD better than Adam (e.g. CNN for Image Classification)    Adam better than SGD (e.g. Transformer, GAN)\n",
            "----------------------------------------------------------  ----------------------------------------------\n",
            "Recommended eps = 1e-8                                      Recommended eps = 1e-16\n",
            "\u001b[34mFor a complete table of recommended hyperparameters, see\n",
            "\u001b[34mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
            "\u001b[32mYou can disable the log message by setting \"print_change_log = False\", though it is recommended to keep as a reminder.\n",
            "\u001b[0m\n",
            "Weight decoupling enabled in AdaBelief\n",
            "Rectification enabled in AdaBelief\n",
            "Created a learning model and optimizer\n"
          ]
        }
      ],
      "source": [
        "### Model / Optimizer ###\n",
        "EPOCH = 10\n",
        "lr = 0.0001\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=50)\n",
        "\n",
        "### Tranfer Learning ###\n",
        "'''\n",
        "num_features = model.classifier.in_features\n",
        "model.fc = nn.Linear(num_features,50)\n",
        "'''\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = AdaBelief(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-16, weight_decouple=True, rectify=True)\n",
        "\n",
        "print(\"Created a learning model and optimizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s0gxuQUUZHu_"
      },
      "outputs": [],
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model,train_loader,optimizer,epoch):\n",
        "  model.train()\n",
        "  for i,(image,target) in enumerate(train_loader):\n",
        "    image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "    output = model(image)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = F.cross_entropy(output,target).to(DEVICE)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i%10 ==0:\n",
        "      print(\n",
        "          f'Train Epoch: {epoch} [{i}/{len(train_loader)}]\\tloss: {train_loss.item():6f}')\n",
        "\n",
        "  return train_loss\n",
        "\n",
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for i,(image,target) in enumerate(val_loader):\n",
        "      image,target = image.to(DEVICE),target.to(DEVICE)\n",
        "      output = model(image)\n",
        "\n",
        "      eval_loss += F.cross_entropy(output,target, reduction='sum').item()\n",
        "      pred = output.max(1,keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  eval_loss /= len(val_loader.dataset)\n",
        "  eval_accuracy = 100*correct / len(val_loader.dataset)\n",
        "  return eval_loss,eval_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNhSTX452wyd",
        "outputId": "738fb42a-4d11-4a8e-f4d5-98e17924aecb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/590]\tloss: 3.957516\n",
            "Train Epoch: 0 [10/590]\tloss: 3.991794\n",
            "Train Epoch: 0 [20/590]\tloss: 3.837260\n",
            "Train Epoch: 0 [30/590]\tloss: 3.897763\n",
            "Train Epoch: 0 [40/590]\tloss: 4.062964\n",
            "Train Epoch: 0 [50/590]\tloss: 3.868530\n",
            "Train Epoch: 0 [60/590]\tloss: 3.904178\n",
            "Train Epoch: 0 [70/590]\tloss: 3.862560\n",
            "Train Epoch: 0 [80/590]\tloss: 3.954480\n",
            "Train Epoch: 0 [90/590]\tloss: 3.980075\n",
            "Train Epoch: 0 [100/590]\tloss: 3.826467\n",
            "Train Epoch: 0 [110/590]\tloss: 3.918337\n",
            "Train Epoch: 0 [120/590]\tloss: 3.906948\n",
            "Train Epoch: 0 [130/590]\tloss: 3.921181\n",
            "Train Epoch: 0 [140/590]\tloss: 3.858545\n",
            "Train Epoch: 0 [150/590]\tloss: 3.887399\n",
            "Train Epoch: 0 [160/590]\tloss: 3.918515\n",
            "Train Epoch: 0 [170/590]\tloss: 3.868889\n",
            "Train Epoch: 0 [180/590]\tloss: 3.861762\n",
            "Train Epoch: 0 [190/590]\tloss: 3.850494\n",
            "Train Epoch: 0 [200/590]\tloss: 3.887271\n",
            "Train Epoch: 0 [210/590]\tloss: 3.855783\n",
            "Train Epoch: 0 [220/590]\tloss: 3.852608\n",
            "Train Epoch: 0 [230/590]\tloss: 3.946595\n",
            "Train Epoch: 0 [240/590]\tloss: 3.843124\n",
            "Train Epoch: 0 [250/590]\tloss: 3.806268\n",
            "Train Epoch: 0 [260/590]\tloss: 3.864602\n",
            "Train Epoch: 0 [270/590]\tloss: 3.873092\n",
            "Train Epoch: 0 [280/590]\tloss: 3.801463\n",
            "Train Epoch: 0 [290/590]\tloss: 3.910566\n",
            "Train Epoch: 0 [300/590]\tloss: 3.768310\n",
            "Train Epoch: 0 [310/590]\tloss: 3.826870\n",
            "Train Epoch: 0 [320/590]\tloss: 3.856252\n",
            "Train Epoch: 0 [330/590]\tloss: 3.653943\n",
            "Train Epoch: 0 [340/590]\tloss: 3.806440\n",
            "Train Epoch: 0 [350/590]\tloss: 3.768317\n",
            "Train Epoch: 0 [360/590]\tloss: 3.869795\n",
            "Train Epoch: 0 [370/590]\tloss: 3.629791\n",
            "Train Epoch: 0 [380/590]\tloss: 3.809998\n",
            "Train Epoch: 0 [390/590]\tloss: 3.771590\n",
            "Train Epoch: 0 [400/590]\tloss: 3.686918\n",
            "Train Epoch: 0 [410/590]\tloss: 3.741773\n",
            "Train Epoch: 0 [420/590]\tloss: 3.731597\n",
            "Train Epoch: 0 [430/590]\tloss: 3.666955\n",
            "Train Epoch: 0 [440/590]\tloss: 3.613569\n",
            "Train Epoch: 0 [450/590]\tloss: 3.613883\n",
            "Train Epoch: 0 [460/590]\tloss: 3.729675\n",
            "Train Epoch: 0 [470/590]\tloss: 3.685115\n",
            "Train Epoch: 0 [480/590]\tloss: 3.600945\n",
            "Train Epoch: 0 [490/590]\tloss: 3.694790\n",
            "Train Epoch: 0 [500/590]\tloss: 3.691900\n",
            "Train Epoch: 0 [510/590]\tloss: 3.642632\n",
            "Train Epoch: 0 [520/590]\tloss: 3.515693\n",
            "Train Epoch: 0 [530/590]\tloss: 3.655009\n",
            "Train Epoch: 0 [540/590]\tloss: 3.614461\n",
            "Train Epoch: 0 [550/590]\tloss: 3.382570\n",
            "Train Epoch: 0 [560/590]\tloss: 3.504705\n",
            "Train Epoch: 0 [570/590]\tloss: 3.468537\n",
            "Train Epoch: 0 [580/590]\tloss: 3.438193\n",
            "[0]Validation Loss: 3.0118,Accuracy: 50.0000%\n",
            "Train Epoch: 1 [0/590]\tloss: 3.357147\n",
            "Train Epoch: 1 [10/590]\tloss: 3.292641\n",
            "Train Epoch: 1 [20/590]\tloss: 3.219564\n",
            "Train Epoch: 1 [30/590]\tloss: 3.268338\n",
            "Train Epoch: 1 [40/590]\tloss: 3.004296\n",
            "Train Epoch: 1 [50/590]\tloss: 3.146863\n",
            "Train Epoch: 1 [60/590]\tloss: 3.214774\n",
            "Train Epoch: 1 [70/590]\tloss: 3.057322\n",
            "Train Epoch: 1 [80/590]\tloss: 2.989299\n",
            "Train Epoch: 1 [90/590]\tloss: 3.385459\n",
            "Train Epoch: 1 [100/590]\tloss: 3.107901\n",
            "Train Epoch: 1 [110/590]\tloss: 3.022092\n",
            "Train Epoch: 1 [120/590]\tloss: 2.938166\n",
            "Train Epoch: 1 [130/590]\tloss: 2.924025\n",
            "Train Epoch: 1 [140/590]\tloss: 2.814901\n",
            "Train Epoch: 1 [150/590]\tloss: 2.459208\n",
            "Train Epoch: 1 [160/590]\tloss: 2.589648\n",
            "Train Epoch: 1 [170/590]\tloss: 2.471210\n",
            "Train Epoch: 1 [180/590]\tloss: 2.721722\n",
            "Train Epoch: 1 [190/590]\tloss: 2.781221\n",
            "Train Epoch: 1 [200/590]\tloss: 3.090008\n",
            "Train Epoch: 1 [210/590]\tloss: 2.749293\n",
            "Train Epoch: 1 [220/590]\tloss: 3.031865\n",
            "Train Epoch: 1 [230/590]\tloss: 2.399279\n",
            "Train Epoch: 1 [240/590]\tloss: 2.944638\n",
            "Train Epoch: 1 [250/590]\tloss: 2.675685\n",
            "Train Epoch: 1 [260/590]\tloss: 2.603963\n",
            "Train Epoch: 1 [270/590]\tloss: 2.826704\n",
            "Train Epoch: 1 [280/590]\tloss: 2.466837\n",
            "Train Epoch: 1 [290/590]\tloss: 2.565015\n",
            "Train Epoch: 1 [300/590]\tloss: 2.467618\n",
            "Train Epoch: 1 [310/590]\tloss: 2.021704\n",
            "Train Epoch: 1 [320/590]\tloss: 2.379880\n",
            "Train Epoch: 1 [330/590]\tloss: 2.783798\n",
            "Train Epoch: 1 [340/590]\tloss: 2.464679\n",
            "Train Epoch: 1 [350/590]\tloss: 2.546924\n",
            "Train Epoch: 1 [360/590]\tloss: 1.839620\n",
            "Train Epoch: 1 [370/590]\tloss: 2.684952\n",
            "Train Epoch: 1 [380/590]\tloss: 2.223910\n",
            "Train Epoch: 1 [390/590]\tloss: 2.008225\n",
            "Train Epoch: 1 [400/590]\tloss: 1.970494\n",
            "Train Epoch: 1 [410/590]\tloss: 2.370299\n",
            "Train Epoch: 1 [420/590]\tloss: 1.829725\n",
            "Train Epoch: 1 [430/590]\tloss: 2.809145\n",
            "Train Epoch: 1 [440/590]\tloss: 2.103090\n",
            "Train Epoch: 1 [450/590]\tloss: 1.845064\n",
            "Train Epoch: 1 [460/590]\tloss: 2.308760\n",
            "Train Epoch: 1 [470/590]\tloss: 1.813225\n",
            "Train Epoch: 1 [480/590]\tloss: 1.639939\n",
            "Train Epoch: 1 [490/590]\tloss: 2.132153\n",
            "Train Epoch: 1 [500/590]\tloss: 1.497368\n",
            "Train Epoch: 1 [510/590]\tloss: 1.777191\n",
            "Train Epoch: 1 [520/590]\tloss: 2.123882\n",
            "Train Epoch: 1 [530/590]\tloss: 2.033944\n",
            "Train Epoch: 1 [540/590]\tloss: 1.979925\n",
            "Train Epoch: 1 [550/590]\tloss: 2.125155\n",
            "Train Epoch: 1 [560/590]\tloss: 1.963526\n",
            "Train Epoch: 1 [570/590]\tloss: 2.015881\n",
            "Train Epoch: 1 [580/590]\tloss: 1.867632\n",
            "[1]Validation Loss: 1.1286,Accuracy: 77.3649%\n",
            "Train Epoch: 2 [0/590]\tloss: 1.862769\n",
            "Train Epoch: 2 [10/590]\tloss: 1.845215\n",
            "Train Epoch: 2 [20/590]\tloss: 1.926771\n",
            "Train Epoch: 2 [30/590]\tloss: 1.862049\n",
            "Train Epoch: 2 [40/590]\tloss: 1.482182\n",
            "Train Epoch: 2 [50/590]\tloss: 1.174201\n",
            "Train Epoch: 2 [60/590]\tloss: 1.966515\n",
            "Train Epoch: 2 [70/590]\tloss: 1.109519\n",
            "Train Epoch: 2 [80/590]\tloss: 1.342977\n",
            "Train Epoch: 2 [90/590]\tloss: 1.385912\n",
            "Train Epoch: 2 [100/590]\tloss: 1.484477\n",
            "Train Epoch: 2 [110/590]\tloss: 1.439059\n",
            "Train Epoch: 2 [120/590]\tloss: 1.322030\n",
            "Train Epoch: 2 [130/590]\tloss: 1.413280\n",
            "Train Epoch: 2 [140/590]\tloss: 1.530129\n",
            "Train Epoch: 2 [150/590]\tloss: 1.082447\n",
            "Train Epoch: 2 [160/590]\tloss: 1.173123\n",
            "Train Epoch: 2 [170/590]\tloss: 1.085427\n",
            "Train Epoch: 2 [180/590]\tloss: 1.769579\n",
            "Train Epoch: 2 [190/590]\tloss: 2.100126\n",
            "Train Epoch: 2 [200/590]\tloss: 1.343014\n",
            "Train Epoch: 2 [210/590]\tloss: 1.072412\n",
            "Train Epoch: 2 [220/590]\tloss: 1.462859\n",
            "Train Epoch: 2 [230/590]\tloss: 1.526704\n",
            "Train Epoch: 2 [240/590]\tloss: 1.931761\n",
            "Train Epoch: 2 [250/590]\tloss: 1.355967\n",
            "Train Epoch: 2 [260/590]\tloss: 1.900029\n",
            "Train Epoch: 2 [270/590]\tloss: 1.334456\n",
            "Train Epoch: 2 [280/590]\tloss: 1.272362\n",
            "Train Epoch: 2 [290/590]\tloss: 0.970263\n",
            "Train Epoch: 2 [300/590]\tloss: 1.036909\n",
            "Train Epoch: 2 [310/590]\tloss: 1.255707\n",
            "Train Epoch: 2 [320/590]\tloss: 1.118982\n",
            "Train Epoch: 2 [330/590]\tloss: 0.824042\n",
            "Train Epoch: 2 [340/590]\tloss: 1.064958\n",
            "Train Epoch: 2 [350/590]\tloss: 1.797044\n",
            "Train Epoch: 2 [360/590]\tloss: 1.354264\n",
            "Train Epoch: 2 [370/590]\tloss: 1.882708\n",
            "Train Epoch: 2 [380/590]\tloss: 1.066665\n",
            "Train Epoch: 2 [390/590]\tloss: 1.045925\n",
            "Train Epoch: 2 [400/590]\tloss: 0.936783\n",
            "Train Epoch: 2 [410/590]\tloss: 0.969714\n",
            "Train Epoch: 2 [420/590]\tloss: 0.664022\n",
            "Train Epoch: 2 [430/590]\tloss: 1.325133\n",
            "Train Epoch: 2 [440/590]\tloss: 0.597701\n",
            "Train Epoch: 2 [450/590]\tloss: 0.964175\n",
            "Train Epoch: 2 [460/590]\tloss: 0.745418\n",
            "Train Epoch: 2 [470/590]\tloss: 1.023763\n",
            "Train Epoch: 2 [480/590]\tloss: 0.963658\n",
            "Train Epoch: 2 [490/590]\tloss: 1.469299\n",
            "Train Epoch: 2 [500/590]\tloss: 1.413296\n",
            "Train Epoch: 2 [510/590]\tloss: 0.973047\n",
            "Train Epoch: 2 [520/590]\tloss: 0.876001\n",
            "Train Epoch: 2 [530/590]\tloss: 0.655900\n",
            "Train Epoch: 2 [540/590]\tloss: 0.813681\n",
            "Train Epoch: 2 [550/590]\tloss: 0.829541\n",
            "Train Epoch: 2 [560/590]\tloss: 1.227384\n",
            "Train Epoch: 2 [570/590]\tloss: 1.702202\n",
            "Train Epoch: 2 [580/590]\tloss: 1.488190\n",
            "[2]Validation Loss: 0.5235,Accuracy: 87.5000%\n",
            "Train Epoch: 3 [0/590]\tloss: 1.113530\n",
            "Train Epoch: 3 [10/590]\tloss: 0.691584\n",
            "Train Epoch: 3 [20/590]\tloss: 0.937887\n",
            "Train Epoch: 3 [30/590]\tloss: 0.583360\n",
            "Train Epoch: 3 [40/590]\tloss: 1.134579\n",
            "Train Epoch: 3 [50/590]\tloss: 0.906884\n",
            "Train Epoch: 3 [60/590]\tloss: 1.007823\n",
            "Train Epoch: 3 [70/590]\tloss: 0.673653\n",
            "Train Epoch: 3 [80/590]\tloss: 0.624401\n",
            "Train Epoch: 3 [90/590]\tloss: 1.246965\n",
            "Train Epoch: 3 [100/590]\tloss: 0.447888\n",
            "Train Epoch: 3 [110/590]\tloss: 1.788493\n",
            "Train Epoch: 3 [120/590]\tloss: 0.580146\n",
            "Train Epoch: 3 [130/590]\tloss: 0.542594\n",
            "Train Epoch: 3 [140/590]\tloss: 0.732181\n",
            "Train Epoch: 3 [150/590]\tloss: 0.744932\n",
            "Train Epoch: 3 [160/590]\tloss: 1.018450\n",
            "Train Epoch: 3 [170/590]\tloss: 0.526565\n",
            "Train Epoch: 3 [180/590]\tloss: 1.063859\n",
            "Train Epoch: 3 [190/590]\tloss: 0.353981\n",
            "Train Epoch: 3 [200/590]\tloss: 0.541878\n",
            "Train Epoch: 3 [210/590]\tloss: 1.008036\n",
            "Train Epoch: 3 [220/590]\tloss: 1.045349\n",
            "Train Epoch: 3 [230/590]\tloss: 0.528480\n",
            "Train Epoch: 3 [240/590]\tloss: 0.874681\n",
            "Train Epoch: 3 [250/590]\tloss: 0.596409\n",
            "Train Epoch: 3 [260/590]\tloss: 0.480300\n",
            "Train Epoch: 3 [270/590]\tloss: 0.404313\n",
            "Train Epoch: 3 [280/590]\tloss: 0.652355\n",
            "Train Epoch: 3 [290/590]\tloss: 1.061814\n",
            "Train Epoch: 3 [300/590]\tloss: 1.065748\n",
            "Train Epoch: 3 [310/590]\tloss: 1.108114\n",
            "Train Epoch: 3 [320/590]\tloss: 1.001571\n",
            "Train Epoch: 3 [330/590]\tloss: 0.351999\n",
            "Train Epoch: 3 [340/590]\tloss: 1.013577\n",
            "Train Epoch: 3 [350/590]\tloss: 0.421784\n",
            "Train Epoch: 3 [360/590]\tloss: 0.352184\n",
            "Train Epoch: 3 [370/590]\tloss: 0.948801\n",
            "Train Epoch: 3 [380/590]\tloss: 0.401776\n",
            "Train Epoch: 3 [390/590]\tloss: 0.574267\n",
            "Train Epoch: 3 [400/590]\tloss: 0.852793\n",
            "Train Epoch: 3 [410/590]\tloss: 0.529864\n",
            "Train Epoch: 3 [420/590]\tloss: 0.818020\n",
            "Train Epoch: 3 [430/590]\tloss: 0.792009\n",
            "Train Epoch: 3 [440/590]\tloss: 0.530604\n",
            "Train Epoch: 3 [450/590]\tloss: 0.644126\n",
            "Train Epoch: 3 [460/590]\tloss: 0.780485\n",
            "Train Epoch: 3 [470/590]\tloss: 0.759613\n",
            "Train Epoch: 3 [480/590]\tloss: 1.584522\n",
            "Train Epoch: 3 [490/590]\tloss: 0.234069\n",
            "Train Epoch: 3 [500/590]\tloss: 0.748122\n",
            "Train Epoch: 3 [510/590]\tloss: 0.360634\n",
            "Train Epoch: 3 [520/590]\tloss: 0.606928\n",
            "Train Epoch: 3 [530/590]\tloss: 1.036149\n",
            "Train Epoch: 3 [540/590]\tloss: 0.723030\n",
            "Train Epoch: 3 [550/590]\tloss: 1.106658\n",
            "Train Epoch: 3 [560/590]\tloss: 0.422007\n",
            "Train Epoch: 3 [570/590]\tloss: 1.140756\n",
            "Train Epoch: 3 [580/590]\tloss: 0.597043\n",
            "[3]Validation Loss: 0.3586,Accuracy: 87.8378%\n",
            "Train Epoch: 4 [0/590]\tloss: 0.539567\n",
            "Train Epoch: 4 [10/590]\tloss: 0.383259\n",
            "Train Epoch: 4 [20/590]\tloss: 1.105353\n",
            "Train Epoch: 4 [30/590]\tloss: 0.185400\n",
            "Train Epoch: 4 [40/590]\tloss: 1.115103\n",
            "Train Epoch: 4 [50/590]\tloss: 0.584542\n",
            "Train Epoch: 4 [60/590]\tloss: 0.571657\n",
            "Train Epoch: 4 [70/590]\tloss: 0.436909\n",
            "Train Epoch: 4 [80/590]\tloss: 1.236128\n",
            "Train Epoch: 4 [90/590]\tloss: 0.931825\n",
            "Train Epoch: 4 [100/590]\tloss: 0.453405\n",
            "Train Epoch: 4 [110/590]\tloss: 0.571483\n",
            "Train Epoch: 4 [120/590]\tloss: 0.377664\n",
            "Train Epoch: 4 [130/590]\tloss: 0.279354\n",
            "Train Epoch: 4 [140/590]\tloss: 0.818834\n",
            "Train Epoch: 4 [150/590]\tloss: 0.718065\n",
            "Train Epoch: 4 [160/590]\tloss: 0.229634\n",
            "Train Epoch: 4 [170/590]\tloss: 0.897519\n",
            "Train Epoch: 4 [180/590]\tloss: 0.707139\n",
            "Train Epoch: 4 [190/590]\tloss: 0.525507\n",
            "Train Epoch: 4 [200/590]\tloss: 0.579575\n",
            "Train Epoch: 4 [210/590]\tloss: 0.362855\n",
            "Train Epoch: 4 [220/590]\tloss: 0.274709\n",
            "Train Epoch: 4 [230/590]\tloss: 0.868662\n",
            "Train Epoch: 4 [240/590]\tloss: 1.973207\n",
            "Train Epoch: 4 [250/590]\tloss: 0.375582\n",
            "Train Epoch: 4 [260/590]\tloss: 0.626471\n",
            "Train Epoch: 4 [270/590]\tloss: 0.592542\n",
            "Train Epoch: 4 [280/590]\tloss: 0.708215\n",
            "Train Epoch: 4 [290/590]\tloss: 0.244553\n",
            "Train Epoch: 4 [300/590]\tloss: 0.332298\n",
            "Train Epoch: 4 [310/590]\tloss: 0.686997\n",
            "Train Epoch: 4 [320/590]\tloss: 0.660943\n",
            "Train Epoch: 4 [330/590]\tloss: 0.645869\n",
            "Train Epoch: 4 [340/590]\tloss: 0.699611\n",
            "Train Epoch: 4 [350/590]\tloss: 0.383103\n",
            "Train Epoch: 4 [360/590]\tloss: 0.481576\n",
            "Train Epoch: 4 [370/590]\tloss: 0.871019\n",
            "Train Epoch: 4 [380/590]\tloss: 0.378532\n",
            "Train Epoch: 4 [390/590]\tloss: 0.764661\n",
            "Train Epoch: 4 [400/590]\tloss: 0.186276\n",
            "Train Epoch: 4 [410/590]\tloss: 0.580742\n",
            "Train Epoch: 4 [420/590]\tloss: 0.427596\n",
            "Train Epoch: 4 [430/590]\tloss: 0.321257\n",
            "Train Epoch: 4 [440/590]\tloss: 0.243282\n",
            "Train Epoch: 4 [450/590]\tloss: 0.422202\n",
            "Train Epoch: 4 [460/590]\tloss: 0.512180\n",
            "Train Epoch: 4 [470/590]\tloss: 1.107194\n",
            "Train Epoch: 4 [480/590]\tloss: 0.359798\n",
            "Train Epoch: 4 [490/590]\tloss: 0.431851\n",
            "Train Epoch: 4 [500/590]\tloss: 0.331139\n",
            "Train Epoch: 4 [510/590]\tloss: 0.692996\n",
            "Train Epoch: 4 [520/590]\tloss: 0.185955\n",
            "Train Epoch: 4 [530/590]\tloss: 0.583976\n",
            "Train Epoch: 4 [540/590]\tloss: 0.535101\n",
            "Train Epoch: 4 [550/590]\tloss: 0.750671\n",
            "Train Epoch: 4 [560/590]\tloss: 0.229114\n",
            "Train Epoch: 4 [570/590]\tloss: 0.506278\n",
            "Train Epoch: 4 [580/590]\tloss: 0.702864\n",
            "[4]Validation Loss: 0.3191,Accuracy: 90.8784%\n",
            "Train Epoch: 5 [0/590]\tloss: 0.120970\n",
            "Train Epoch: 5 [10/590]\tloss: 0.613837\n",
            "Train Epoch: 5 [20/590]\tloss: 0.359039\n",
            "Train Epoch: 5 [30/590]\tloss: 0.804590\n",
            "Train Epoch: 5 [40/590]\tloss: 0.571418\n",
            "Train Epoch: 5 [50/590]\tloss: 0.302799\n",
            "Train Epoch: 5 [60/590]\tloss: 0.175636\n",
            "Train Epoch: 5 [70/590]\tloss: 0.303705\n",
            "Train Epoch: 5 [80/590]\tloss: 1.069851\n",
            "Train Epoch: 5 [90/590]\tloss: 0.527980\n",
            "Train Epoch: 5 [100/590]\tloss: 0.750457\n",
            "Train Epoch: 5 [110/590]\tloss: 0.188167\n",
            "Train Epoch: 5 [120/590]\tloss: 0.757721\n",
            "Train Epoch: 5 [130/590]\tloss: 0.750875\n",
            "Train Epoch: 5 [140/590]\tloss: 0.247662\n",
            "Train Epoch: 5 [150/590]\tloss: 0.622399\n",
            "Train Epoch: 5 [160/590]\tloss: 0.212603\n",
            "Train Epoch: 5 [170/590]\tloss: 0.053857\n",
            "Train Epoch: 5 [180/590]\tloss: 0.105854\n",
            "Train Epoch: 5 [190/590]\tloss: 0.404829\n",
            "Train Epoch: 5 [200/590]\tloss: 0.148974\n",
            "Train Epoch: 5 [210/590]\tloss: 0.962087\n",
            "Train Epoch: 5 [220/590]\tloss: 0.346688\n",
            "Train Epoch: 5 [230/590]\tloss: 0.720326\n",
            "Train Epoch: 5 [240/590]\tloss: 0.698542\n",
            "Train Epoch: 5 [250/590]\tloss: 0.282779\n",
            "Train Epoch: 5 [260/590]\tloss: 0.273091\n",
            "Train Epoch: 5 [270/590]\tloss: 0.296571\n",
            "Train Epoch: 5 [280/590]\tloss: 0.492659\n",
            "Train Epoch: 5 [290/590]\tloss: 0.802434\n",
            "Train Epoch: 5 [300/590]\tloss: 0.255170\n",
            "Train Epoch: 5 [310/590]\tloss: 0.167597\n",
            "Train Epoch: 5 [320/590]\tloss: 0.117008\n",
            "Train Epoch: 5 [330/590]\tloss: 0.251989\n",
            "Train Epoch: 5 [340/590]\tloss: 0.113437\n",
            "Train Epoch: 5 [350/590]\tloss: 0.256211\n",
            "Train Epoch: 5 [360/590]\tloss: 0.446109\n",
            "Train Epoch: 5 [370/590]\tloss: 0.820510\n",
            "Train Epoch: 5 [380/590]\tloss: 0.228270\n",
            "Train Epoch: 5 [390/590]\tloss: 0.574698\n",
            "Train Epoch: 5 [400/590]\tloss: 0.252933\n",
            "Train Epoch: 5 [410/590]\tloss: 0.133917\n",
            "Train Epoch: 5 [420/590]\tloss: 0.222195\n",
            "Train Epoch: 5 [430/590]\tloss: 0.325702\n",
            "Train Epoch: 5 [440/590]\tloss: 0.432789\n",
            "Train Epoch: 5 [450/590]\tloss: 0.273540\n",
            "Train Epoch: 5 [460/590]\tloss: 0.686289\n",
            "Train Epoch: 5 [470/590]\tloss: 0.398993\n",
            "Train Epoch: 5 [480/590]\tloss: 0.109581\n",
            "Train Epoch: 5 [490/590]\tloss: 0.206293\n",
            "Train Epoch: 5 [500/590]\tloss: 0.413229\n",
            "Train Epoch: 5 [510/590]\tloss: 0.298792\n",
            "Train Epoch: 5 [520/590]\tloss: 0.116315\n",
            "Train Epoch: 5 [530/590]\tloss: 0.137234\n",
            "Train Epoch: 5 [540/590]\tloss: 0.070284\n",
            "Train Epoch: 5 [550/590]\tloss: 0.467413\n",
            "Train Epoch: 5 [560/590]\tloss: 0.095711\n",
            "Train Epoch: 5 [570/590]\tloss: 0.306944\n",
            "Train Epoch: 5 [580/590]\tloss: 0.283928\n",
            "[5]Validation Loss: 0.3510,Accuracy: 89.5270%\n",
            "Train Epoch: 6 [0/590]\tloss: 0.124969\n",
            "Train Epoch: 6 [10/590]\tloss: 0.145404\n",
            "Train Epoch: 6 [20/590]\tloss: 0.466253\n",
            "Train Epoch: 6 [30/590]\tloss: 0.412347\n",
            "Train Epoch: 6 [40/590]\tloss: 0.500954\n",
            "Train Epoch: 6 [50/590]\tloss: 0.357223\n",
            "Train Epoch: 6 [60/590]\tloss: 0.233978\n",
            "Train Epoch: 6 [70/590]\tloss: 0.284917\n",
            "Train Epoch: 6 [80/590]\tloss: 0.261559\n",
            "Train Epoch: 6 [90/590]\tloss: 0.346555\n",
            "Train Epoch: 6 [100/590]\tloss: 0.212369\n",
            "Train Epoch: 6 [110/590]\tloss: 0.609625\n",
            "Train Epoch: 6 [120/590]\tloss: 0.297388\n",
            "Train Epoch: 6 [130/590]\tloss: 0.875756\n",
            "Train Epoch: 6 [140/590]\tloss: 0.282734\n",
            "Train Epoch: 6 [150/590]\tloss: 0.237720\n",
            "Train Epoch: 6 [160/590]\tloss: 0.075419\n",
            "Train Epoch: 6 [170/590]\tloss: 0.252991\n",
            "Train Epoch: 6 [180/590]\tloss: 0.464861\n",
            "Train Epoch: 6 [190/590]\tloss: 0.265354\n",
            "Train Epoch: 6 [200/590]\tloss: 0.218121\n",
            "Train Epoch: 6 [210/590]\tloss: 0.110603\n",
            "Train Epoch: 6 [220/590]\tloss: 0.121523\n",
            "Train Epoch: 6 [230/590]\tloss: 0.216948\n",
            "Train Epoch: 6 [240/590]\tloss: 0.317186\n",
            "Train Epoch: 6 [250/590]\tloss: 0.516065\n",
            "Train Epoch: 6 [260/590]\tloss: 0.542504\n",
            "Train Epoch: 6 [270/590]\tloss: 0.041061\n",
            "Train Epoch: 6 [280/590]\tloss: 0.088182\n",
            "Train Epoch: 6 [290/590]\tloss: 0.743982\n",
            "Train Epoch: 6 [300/590]\tloss: 0.219047\n",
            "Train Epoch: 6 [310/590]\tloss: 0.490112\n",
            "Train Epoch: 6 [320/590]\tloss: 0.155729\n",
            "Train Epoch: 6 [330/590]\tloss: 0.354377\n",
            "Train Epoch: 6 [340/590]\tloss: 0.280902\n",
            "Train Epoch: 6 [350/590]\tloss: 0.042049\n",
            "Train Epoch: 6 [360/590]\tloss: 0.877394\n",
            "Train Epoch: 6 [370/590]\tloss: 0.145708\n",
            "Train Epoch: 6 [380/590]\tloss: 0.345459\n",
            "Train Epoch: 6 [390/590]\tloss: 0.343538\n",
            "Train Epoch: 6 [400/590]\tloss: 0.348014\n",
            "Train Epoch: 6 [410/590]\tloss: 0.073610\n",
            "Train Epoch: 6 [420/590]\tloss: 0.638444\n",
            "Train Epoch: 6 [430/590]\tloss: 0.178588\n",
            "Train Epoch: 6 [440/590]\tloss: 0.105425\n",
            "Train Epoch: 6 [450/590]\tloss: 0.261962\n",
            "Train Epoch: 6 [460/590]\tloss: 0.057955\n",
            "Train Epoch: 6 [470/590]\tloss: 0.198414\n",
            "Train Epoch: 6 [480/590]\tloss: 0.207126\n",
            "Train Epoch: 6 [490/590]\tloss: 0.130364\n",
            "Train Epoch: 6 [500/590]\tloss: 0.225129\n",
            "Train Epoch: 6 [510/590]\tloss: 0.436862\n",
            "Train Epoch: 6 [520/590]\tloss: 0.041710\n",
            "Train Epoch: 6 [530/590]\tloss: 0.456449\n",
            "Train Epoch: 6 [540/590]\tloss: 0.163178\n",
            "Train Epoch: 6 [550/590]\tloss: 0.074547\n",
            "Train Epoch: 6 [560/590]\tloss: 0.442792\n",
            "Train Epoch: 6 [570/590]\tloss: 0.387824\n",
            "Train Epoch: 6 [580/590]\tloss: 0.193733\n",
            "[6]Validation Loss: 0.3820,Accuracy: 91.2162%\n",
            "Train Epoch: 7 [0/590]\tloss: 0.298820\n",
            "Train Epoch: 7 [10/590]\tloss: 0.184569\n",
            "Train Epoch: 7 [20/590]\tloss: 0.183151\n",
            "Train Epoch: 7 [30/590]\tloss: 0.154475\n",
            "Train Epoch: 7 [40/590]\tloss: 0.285731\n",
            "Train Epoch: 7 [50/590]\tloss: 0.063432\n",
            "Train Epoch: 7 [60/590]\tloss: 0.193959\n",
            "Train Epoch: 7 [70/590]\tloss: 0.058468\n",
            "Train Epoch: 7 [80/590]\tloss: 0.289247\n",
            "Train Epoch: 7 [90/590]\tloss: 0.908868\n",
            "Train Epoch: 7 [100/590]\tloss: 0.159759\n",
            "Train Epoch: 7 [110/590]\tloss: 0.480063\n",
            "Train Epoch: 7 [120/590]\tloss: 0.091893\n",
            "Train Epoch: 7 [130/590]\tloss: 0.053884\n",
            "Train Epoch: 7 [140/590]\tloss: 0.139792\n",
            "Train Epoch: 7 [150/590]\tloss: 0.104371\n",
            "Train Epoch: 7 [160/590]\tloss: 0.248458\n",
            "Train Epoch: 7 [170/590]\tloss: 0.272700\n",
            "Train Epoch: 7 [180/590]\tloss: 0.420816\n",
            "Train Epoch: 7 [190/590]\tloss: 0.411081\n",
            "Train Epoch: 7 [200/590]\tloss: 0.394503\n",
            "Train Epoch: 7 [210/590]\tloss: 0.352002\n",
            "Train Epoch: 7 [220/590]\tloss: 0.531120\n",
            "Train Epoch: 7 [230/590]\tloss: 0.125655\n",
            "Train Epoch: 7 [240/590]\tloss: 0.188958\n",
            "Train Epoch: 7 [250/590]\tloss: 0.190961\n",
            "Train Epoch: 7 [260/590]\tloss: 0.346552\n",
            "Train Epoch: 7 [270/590]\tloss: 0.038079\n",
            "Train Epoch: 7 [280/590]\tloss: 0.029916\n",
            "Train Epoch: 7 [290/590]\tloss: 0.408431\n",
            "Train Epoch: 7 [300/590]\tloss: 0.879643\n",
            "Train Epoch: 7 [310/590]\tloss: 0.041420\n",
            "Train Epoch: 7 [320/590]\tloss: 0.038710\n",
            "Train Epoch: 7 [330/590]\tloss: 0.373204\n",
            "Train Epoch: 7 [340/590]\tloss: 0.094444\n",
            "Train Epoch: 7 [350/590]\tloss: 0.129463\n",
            "Train Epoch: 7 [360/590]\tloss: 0.154102\n",
            "Train Epoch: 7 [370/590]\tloss: 0.012869\n",
            "Train Epoch: 7 [380/590]\tloss: 0.965547\n",
            "Train Epoch: 7 [390/590]\tloss: 0.194358\n",
            "Train Epoch: 7 [400/590]\tloss: 0.515760\n",
            "Train Epoch: 7 [410/590]\tloss: 0.320288\n",
            "Train Epoch: 7 [420/590]\tloss: 0.031984\n",
            "Train Epoch: 7 [430/590]\tloss: 0.018668\n",
            "Train Epoch: 7 [440/590]\tloss: 0.116892\n",
            "Train Epoch: 7 [450/590]\tloss: 0.508279\n",
            "Train Epoch: 7 [460/590]\tloss: 0.408540\n",
            "Train Epoch: 7 [470/590]\tloss: 0.113160\n",
            "Train Epoch: 7 [480/590]\tloss: 0.361860\n",
            "Train Epoch: 7 [490/590]\tloss: 0.463276\n",
            "Train Epoch: 7 [500/590]\tloss: 0.726182\n",
            "Train Epoch: 7 [510/590]\tloss: 0.313630\n",
            "Train Epoch: 7 [520/590]\tloss: 0.372637\n",
            "Train Epoch: 7 [530/590]\tloss: 0.281748\n",
            "Train Epoch: 7 [540/590]\tloss: 0.061023\n",
            "Train Epoch: 7 [550/590]\tloss: 0.082018\n",
            "Train Epoch: 7 [560/590]\tloss: 0.156531\n",
            "Train Epoch: 7 [570/590]\tloss: 0.706097\n",
            "Train Epoch: 7 [580/590]\tloss: 0.503982\n",
            "[7]Validation Loss: 0.2746,Accuracy: 91.8919%\n",
            "Train Epoch: 8 [0/590]\tloss: 0.644232\n",
            "Train Epoch: 8 [10/590]\tloss: 0.513772\n",
            "Train Epoch: 8 [20/590]\tloss: 0.090626\n",
            "Train Epoch: 8 [30/590]\tloss: 0.073328\n",
            "Train Epoch: 8 [40/590]\tloss: 0.098578\n",
            "Train Epoch: 8 [50/590]\tloss: 0.106370\n",
            "Train Epoch: 8 [60/590]\tloss: 0.305151\n",
            "Train Epoch: 8 [70/590]\tloss: 0.086362\n",
            "Train Epoch: 8 [80/590]\tloss: 0.047576\n",
            "Train Epoch: 8 [90/590]\tloss: 0.122465\n",
            "Train Epoch: 8 [100/590]\tloss: 0.130765\n",
            "Train Epoch: 8 [110/590]\tloss: 0.139266\n",
            "Train Epoch: 8 [120/590]\tloss: 0.752257\n",
            "Train Epoch: 8 [130/590]\tloss: 0.211186\n",
            "Train Epoch: 8 [140/590]\tloss: 0.280299\n",
            "Train Epoch: 8 [150/590]\tloss: 0.166266\n",
            "Train Epoch: 8 [160/590]\tloss: 0.079361\n",
            "Train Epoch: 8 [170/590]\tloss: 0.234840\n",
            "Train Epoch: 8 [180/590]\tloss: 0.020012\n",
            "Train Epoch: 8 [190/590]\tloss: 0.072057\n",
            "Train Epoch: 8 [200/590]\tloss: 0.073970\n",
            "Train Epoch: 8 [210/590]\tloss: 0.230924\n",
            "Train Epoch: 8 [220/590]\tloss: 0.196186\n",
            "Train Epoch: 8 [230/590]\tloss: 0.964512\n",
            "Train Epoch: 8 [240/590]\tloss: 1.187780\n",
            "Train Epoch: 8 [250/590]\tloss: 0.371627\n",
            "Train Epoch: 8 [260/590]\tloss: 0.259854\n",
            "Train Epoch: 8 [270/590]\tloss: 0.100335\n",
            "Train Epoch: 8 [280/590]\tloss: 0.172694\n",
            "Train Epoch: 8 [290/590]\tloss: 0.161921\n",
            "Train Epoch: 8 [300/590]\tloss: 0.044571\n",
            "Train Epoch: 8 [310/590]\tloss: 0.170358\n",
            "Train Epoch: 8 [320/590]\tloss: 0.087467\n",
            "Train Epoch: 8 [330/590]\tloss: 0.012738\n",
            "Train Epoch: 8 [340/590]\tloss: 0.506443\n",
            "Train Epoch: 8 [350/590]\tloss: 0.112227\n",
            "Train Epoch: 8 [360/590]\tloss: 0.204916\n",
            "Train Epoch: 8 [370/590]\tloss: 0.279010\n",
            "Train Epoch: 8 [380/590]\tloss: 0.017290\n",
            "Train Epoch: 8 [390/590]\tloss: 0.124647\n",
            "Train Epoch: 8 [400/590]\tloss: 0.017672\n",
            "Train Epoch: 8 [410/590]\tloss: 0.070528\n",
            "Train Epoch: 8 [420/590]\tloss: 0.110846\n",
            "Train Epoch: 8 [430/590]\tloss: 0.133556\n",
            "Train Epoch: 8 [440/590]\tloss: 0.099737\n",
            "Train Epoch: 8 [450/590]\tloss: 0.233576\n",
            "Train Epoch: 8 [460/590]\tloss: 0.296081\n",
            "Train Epoch: 8 [470/590]\tloss: 0.151187\n",
            "Train Epoch: 8 [480/590]\tloss: 0.221427\n",
            "Train Epoch: 8 [490/590]\tloss: 0.213197\n",
            "Train Epoch: 8 [500/590]\tloss: 0.208814\n",
            "Train Epoch: 8 [510/590]\tloss: 0.031469\n",
            "Train Epoch: 8 [520/590]\tloss: 0.225376\n",
            "Train Epoch: 8 [530/590]\tloss: 0.300071\n",
            "Train Epoch: 8 [540/590]\tloss: 0.468674\n",
            "Train Epoch: 8 [550/590]\tloss: 0.067323\n",
            "Train Epoch: 8 [560/590]\tloss: 0.122443\n",
            "Train Epoch: 8 [570/590]\tloss: 0.088581\n",
            "Train Epoch: 8 [580/590]\tloss: 0.081562\n",
            "[8]Validation Loss: 0.2982,Accuracy: 91.8919%\n",
            "Train Epoch: 9 [0/590]\tloss: 0.032632\n",
            "Train Epoch: 9 [10/590]\tloss: 0.020346\n",
            "Train Epoch: 9 [20/590]\tloss: 0.225636\n",
            "Train Epoch: 9 [30/590]\tloss: 0.296652\n",
            "Train Epoch: 9 [40/590]\tloss: 0.630617\n",
            "Train Epoch: 9 [50/590]\tloss: 0.102804\n",
            "Train Epoch: 9 [60/590]\tloss: 0.268315\n",
            "Train Epoch: 9 [70/590]\tloss: 0.249901\n",
            "Train Epoch: 9 [80/590]\tloss: 0.113711\n",
            "Train Epoch: 9 [90/590]\tloss: 0.017591\n",
            "Train Epoch: 9 [100/590]\tloss: 0.052033\n",
            "Train Epoch: 9 [110/590]\tloss: 0.133707\n",
            "Train Epoch: 9 [120/590]\tloss: 0.125551\n",
            "Train Epoch: 9 [130/590]\tloss: 0.021353\n",
            "Train Epoch: 9 [140/590]\tloss: 0.207868\n",
            "Train Epoch: 9 [150/590]\tloss: 0.025822\n",
            "Train Epoch: 9 [160/590]\tloss: 0.144238\n",
            "Train Epoch: 9 [170/590]\tloss: 0.439107\n",
            "Train Epoch: 9 [180/590]\tloss: 0.013507\n",
            "Train Epoch: 9 [190/590]\tloss: 0.754363\n",
            "Train Epoch: 9 [200/590]\tloss: 0.489972\n",
            "Train Epoch: 9 [210/590]\tloss: 0.205182\n",
            "Train Epoch: 9 [220/590]\tloss: 0.279901\n",
            "Train Epoch: 9 [230/590]\tloss: 0.200386\n",
            "Train Epoch: 9 [240/590]\tloss: 0.128300\n",
            "Train Epoch: 9 [250/590]\tloss: 0.269804\n",
            "Train Epoch: 9 [260/590]\tloss: 0.545333\n",
            "Train Epoch: 9 [270/590]\tloss: 0.246343\n",
            "Train Epoch: 9 [280/590]\tloss: 0.419197\n",
            "Train Epoch: 9 [290/590]\tloss: 0.153836\n",
            "Train Epoch: 9 [300/590]\tloss: 0.103132\n",
            "Train Epoch: 9 [310/590]\tloss: 0.445939\n",
            "Train Epoch: 9 [320/590]\tloss: 0.111681\n",
            "Train Epoch: 9 [330/590]\tloss: 0.017339\n",
            "Train Epoch: 9 [340/590]\tloss: 0.238610\n",
            "Train Epoch: 9 [350/590]\tloss: 0.109814\n",
            "Train Epoch: 9 [360/590]\tloss: 0.346043\n",
            "Train Epoch: 9 [370/590]\tloss: 0.039123\n",
            "Train Epoch: 9 [380/590]\tloss: 0.369242\n",
            "Train Epoch: 9 [390/590]\tloss: 0.134546\n",
            "Train Epoch: 9 [400/590]\tloss: 0.014701\n",
            "Train Epoch: 9 [410/590]\tloss: 0.077858\n",
            "Train Epoch: 9 [420/590]\tloss: 0.023833\n",
            "Train Epoch: 9 [430/590]\tloss: 0.061994\n",
            "Train Epoch: 9 [440/590]\tloss: 0.114540\n",
            "Train Epoch: 9 [450/590]\tloss: 0.226023\n",
            "Train Epoch: 9 [460/590]\tloss: 0.081310\n",
            "Train Epoch: 9 [470/590]\tloss: 0.018413\n",
            "Train Epoch: 9 [480/590]\tloss: 0.138542\n",
            "Train Epoch: 9 [490/590]\tloss: 0.074958\n",
            "Train Epoch: 9 [500/590]\tloss: 0.258365\n",
            "Train Epoch: 9 [510/590]\tloss: 0.231671\n",
            "Train Epoch: 9 [520/590]\tloss: 0.160123\n",
            "Train Epoch: 9 [530/590]\tloss: 0.024245\n",
            "Train Epoch: 9 [540/590]\tloss: 0.202902\n",
            "Train Epoch: 9 [550/590]\tloss: 0.067149\n",
            "Train Epoch: 9 [560/590]\tloss: 0.134419\n",
            "Train Epoch: 9 [570/590]\tloss: 0.088812\n",
            "Train Epoch: 9 [580/590]\tloss: 0.032468\n",
            "[9]Validation Loss: 0.2727,Accuracy: 91.8919%\n",
            "[FINAL] Test Loss: 0.2980,Accuracy: 93.6242%\n",
            "Best Accuracy:  91.89189189189189\n",
            "Elasped Time: 0h, 42m, 30s\n",
            "time: 0h, 42m, 30s\n"
          ]
        }
      ],
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "train_losses = []  # 훈련 손실을 저장할 목록\n",
        "val_losses = []    # 검증 손실을 저장할 목록\n",
        "val_accuracys = []\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "  train_loss = train(model,train_loader,optimizer,epoch)\n",
        "  val_loss,val_accuracy = evaluate(model,val_loader)\n",
        "\n",
        "# 훈련 및 검증 손실을 목록에 추가\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  # Save best model\n",
        "  if val_accuracy > best:\n",
        "    best = val_accuracy\n",
        "    torch.save(model.state_dict(),\"./best_model.pth\")\n",
        "\n",
        "  val_accuracys.append(val_accuracy)\n",
        "  print(f\"[{epoch}]Validation Loss: {val_loss:.4f},Accuracy: {val_accuracy:.4f}%\")\n",
        "\n",
        "# Test result\n",
        "test_loss,test_accuracy = evaluate(model,test_loader)\n",
        "print(f'[FINAL] Test Loss: {test_loss:.4f},Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "end = time.time()\n",
        "elasped_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \",best)\n",
        "print(\n",
        "    f\"Elasped Time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")\n",
        "print(\n",
        "    f\"time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vPbth0JdWdCj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "6e4d1cc8-3e3a-489b-ee05-c07201513333"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9e32b6060570>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train_loss와 val_loss 텐서를 CPU로 이동하고 NumPy 배열로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ],
      "source": [
        "# 이제 손실 값을 플로팅합니다.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# train_loss와 val_loss 텐서를 CPU로 이동하고 NumPy 배열로 변환\n",
        "train_losses = [loss.cpu().detach().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_losses]\n",
        "val_losses = [loss.cpu().detach().numpy() if isinstance(loss, torch.Tensor) else loss for loss in val_losses]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, EPOCH + 1), train_losses, label='train_loss', marker='o')\n",
        "plt.plot(range(1, EPOCH + 1), val_losses, label='val_loss', marker='o')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "val_accuracys = [acc.cpu().detach().numpy() if isinstance(acc, torch.Tensor) else acc for acc in val_accuracys]\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, EPOCH + 1), val_accuracys, label='val_accuracy', marker='o')\n",
        "plt.title('Validation Accuracy Over Epochs')\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}